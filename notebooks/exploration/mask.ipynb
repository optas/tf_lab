{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tflearn.layers.conv import conv_1d\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_points = 2048\n",
    "pc_dim = 3\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_points, pc_dim])\n",
    "y = tf.placeholder(tf.float32, [None, n_points, pc_dim])\n",
    "merged_points = tf.concat([x, y], axis=2)\n",
    "\n",
    "batch_size = tf.shape(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_10:0' shape=(?, 2048, 2048) dtype=float32>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment_feat = conv_1d(merged_points, nb_filter=n_points, filter_size=1, strides=1)\n",
    "# tf.nn.softmax(alignment_feat)\n",
    "align_loc = tf.cast(tf.argmax(alignment_feat, axis=1), tf.int32) # TODO verify axis\n",
    "\n",
    "row_idx = tf.range(batch_size, dtype=tf.int32)\n",
    "row_idx = tf.reshape(tf.tile(row_idx, [n_points]), [n_points, -1])\n",
    "row_idx = tf.transpose(row_idx)\n",
    "\n",
    "coords = tf.stack([row_idx, align_loc], axis=2)\n",
    "aligned_y = tf.gather_nd(y, coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'GatherNd_9:0' shape=(?, 2048, 3) dtype=float32>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'Conv1D/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_1/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_1/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_2/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_2/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_3/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_3/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_4/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_4/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_5/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_5/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_6/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_6/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_7/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_7/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_8/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_8/b:0' shape=(2048,) dtype=float32_ref>\"] and loss Tensor(\"L2Loss_7:0\", shape=(), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-d168a4698f07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0maligned_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/orions4-zfs/projects/optas/Virt_Env/tf_1.3/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    320\u001b[0m           \u001b[0;34m\"No gradients provided for any variable, check your graph for ops\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m           \u001b[0;34m\" that do not support gradients, between variables %s and loss %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m           ([str(v) for _, v in grads_and_vars], loss))\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'Conv1D/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_1/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_1/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_2/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_2/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_3/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_3/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_4/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_4/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_5/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_5/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_6/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_6/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_7/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_7/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_8/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_8/b:0' shape=(2048,) dtype=float32_ref>\"] and loss Tensor(\"L2Loss_7:0\", shape=(), dtype=float32)."
     ]
    }
   ],
   "source": [
    "loss = tf.nn.l2_loss(x-aligned_y)\n",
    "step = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'Conv1D/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_1/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_1/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_2/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_2/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_3/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_3/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_4/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_4/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_5/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_5/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_6/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_6/b:0' shape=(2048,) dtype=float32_ref>\"] and loss Tensor(\"L2Loss_2:0\", shape=(), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-d168a4698f07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0maligned_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/orions4-zfs/projects/optas/Virt_Env/tf_1.3/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    320\u001b[0m           \u001b[0;34m\"No gradients provided for any variable, check your graph for ops\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m           \u001b[0;34m\" that do not support gradients, between variables %s and loss %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m           ([str(v) for _, v in grads_and_vars], loss))\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'Conv1D/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_1/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_1/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_2/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_2/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_3/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_3/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_4/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_4/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_5/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_5/b:0' shape=(2048,) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_6/W:0' shape=(1, 1, 6, 2048) dtype=float32_ref>\", \"<tf.Variable 'Conv1D_6/b:0' shape=(2048,) dtype=float32_ref>\"] and loss Tensor(\"L2Loss_2:0\", shape=(), dtype=float32)."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sub:0' shape=(?, 2048, 3) dtype=float32>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  3.00000000e+01,   3.10000000e+01,   3.20000000e+01],\n",
       "        [  6.00000000e+01,   6.10000000e+01,   6.20000000e+01],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   2.00000000e+00],\n",
       "        ..., \n",
       "        [  6.12000000e+03,   6.12100000e+03,   6.12200000e+03],\n",
       "        [  6.12300000e+03,   6.12400000e+03,   6.12500000e+03],\n",
       "        [  6.12600000e+03,   6.12700000e+03,   6.12800000e+03]],\n",
       "\n",
       "       [[  6.14400000e+03,   6.14500000e+03,   6.14600000e+03],\n",
       "        [  6.14700000e+03,   6.14800000e+03,   6.14900000e+03],\n",
       "        [  6.15000000e+03,   6.15100000e+03,   6.15200000e+03],\n",
       "        ..., \n",
       "        [  1.22790000e+04,   1.22800000e+04,   1.22810000e+04],\n",
       "        [  1.22820000e+04,   1.22830000e+04,   1.22840000e+04],\n",
       "        [  1.22850000e+04,   1.22860000e+04,   1.22870000e+04]]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch_size = 2\n",
    "x_batch = np.random.random((test_batch_size, n_points, pc_dim))\n",
    "y_batch = np.random.random((test_batch_size, n_points, pc_dim))\n",
    "\n",
    "x_batch = np.arange(len(x_batch.flatten())).reshape(test_batch_size, n_points, 3)\n",
    "\n",
    "test_order = np.hstack([[10, 20, 0, 5, 100], np.arange((n_points)-5), np.arange(n_points)])\n",
    "test_order = test_order.reshape(test_batch_size, -1)\n",
    "\n",
    "feed_dict = {x:x_batch, y:y_batch, align_loc:test_order}\n",
    "\n",
    "sess.run(aligned_x, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def max_response_coords(batch_size, feat_dim, max_index):\n",
    "    row_idx = tf.range(batch_size, dtype=tf.int32)\n",
    "    row_idx = tf.reshape(tf.tile(row_idx, [feat_dim]), [feat_dim, -1])\n",
    "    row_idx = tf.transpose(row_idx)\n",
    "    # print row_idx.eval()\n",
    "    col_idx = tf.range(feat_dim, dtype=tf.int32)\n",
    "    col_idx = tf.reshape(tf.tile(col_idx, [batch_size]), [batch_size, -1])\n",
    "    coords = tf.transpose(tf.stack([row_idx, col_idx, max_index]))\n",
    "    # print coords.eval()\n",
    "    return coords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
