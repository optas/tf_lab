{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 0\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook.gpu_utils import setup_one_gpu\n",
    "GPU = 0\n",
    "setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "import numpy as np\n",
    "from general_tools.notebook.tf import reset_tf_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGG_MEAN = [123.68, 116.78, 103.94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_images(directory, in_view='image_p020_t337_r005'):\n",
    "    \"\"\"\n",
    "    Get all the images and labels in directory/label/model_name/view.png\n",
    "    \"\"\"\n",
    "    labels = os.listdir(directory)\n",
    "    files_and_labels = []\n",
    "    for label in labels:\n",
    "        for f in os.listdir(os.path.join(directory, label)):\n",
    "            files_and_labels.append((os.path.join(directory, label, f, in_view + '.png'), label))\n",
    "\n",
    "    filenames, labels = zip(*files_and_labels)\n",
    "    filenames = list(filenames)\n",
    "    labels = list(labels)\n",
    "    unique_labels = list(set(labels))\n",
    "\n",
    "    label_to_int = {}\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        label_to_int[label] = i\n",
    "\n",
    "    labels = [label_to_int[l] for l in labels]\n",
    "    \n",
    "    rids = np.random.choice(np.arange(len(labels)), 1000, replace=False)    \n",
    "    return (np.array(filenames)[rids]).tolist(), (np.array(labels)[rids]).tolist()\n",
    "    return filenames, labels\n",
    "\n",
    "def check_accuracy(sess, correct_prediction, is_training, dataset_init_op):\n",
    "    \"\"\"\n",
    "    Check the accuracy of the model on either train or val (depending on dataset_init_op).\n",
    "    \"\"\"\n",
    "    # Initialize the correct dataset\n",
    "    sess.run(dataset_init_op)\n",
    "    num_correct, num_samples = 0, 0\n",
    "    while True:\n",
    "        try:\n",
    "            correct_pred = sess.run(correct_prediction, {is_training: False})\n",
    "            num_correct += correct_pred.sum()\n",
    "            num_samples += correct_pred.shape[0]\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "    # Return the fraction of datapoints that were correctly classified\n",
    "    acc = float(num_correct) / num_samples\n",
    "    return acc\n",
    "\n",
    "def training_preprocess(image, label):\n",
    "    ''' Preprocessing (for training)\n",
    "        # (3) Take a random 224x224 crop to the scaled image\n",
    "        # (4) Horizontally flip the image with probability 1/2\n",
    "        # (5) Substract the per color mean `VGG_MEAN`\n",
    "        # Note: we don't normalize the data here, as VGG was trained without normalization\n",
    "    '''\n",
    "    crop_image = tf.random_crop(image, [224, 224, 3])\n",
    "    flip_image = tf.image.random_flip_left_right(crop_image)\n",
    "    means = tf.reshape(tf.constant(VGG_MEAN), [1, 1, 3])\n",
    "    centered_image = flip_image - means\n",
    "    return centered_image, label\n",
    "\n",
    "\n",
    "def val_preprocess(image, label):\n",
    "    ''' Preprocessing (for validation)\n",
    "    Take a central 224x224 crop to the scaled image\n",
    "    Substract the per color mean `VGG_MEAN`\n",
    "    # Note: we don't normalize the data here, as VGG was trained without normalization\n",
    "    '''\n",
    "    crop_image = tf.image.resize_image_with_crop_or_pad(image, 224, 224)    # (3)\n",
    "    means = tf.reshape(tf.constant(VGG_MEAN), [1, 1, 3])\n",
    "    centered_image = crop_image - means                                     # (4)\n",
    "    return centered_image, label\n",
    "\n",
    "def _parse_function(filename, label):\n",
    "    ''' # Standard preprocessing for VGG on ImageNet taken from here:\n",
    "        # https://github.com/tensorflow/models/blob/master/research/slim/preprocessing/vgg_preprocessing.py\n",
    "        # Also see the VGG paper for more details: https://arxiv.org/pdf/1409.1556.pdf\n",
    "        # Preprocessing (for both training and validation):\n",
    "        # (1) Decode the image from PNG format\n",
    "        # (2) Resize the image so its smaller side is 256 pixels long\n",
    "        '''\n",
    "    image_string = tf.read_file(filename)\n",
    "    image_decoded = tf.image.decode_png(image_string, channels=3)\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "\n",
    "    smallest_side = 256.0\n",
    "    height, width = tf.shape(image)[0], tf.shape(image)[1]\n",
    "    height = tf.to_float(height)\n",
    "    width = tf.to_float(width)\n",
    "\n",
    "    scale = tf.cond(tf.greater(height, width),\n",
    "                    lambda: smallest_side / width,\n",
    "                    lambda: smallest_side / height)\n",
    "    new_height = tf.to_int32(height * scale)\n",
    "    new_width = tf.to_int32(width * scale)\n",
    "\n",
    "    resized_image = tf.image.resize_images(image, [new_height, new_width])\n",
    "    return resized_image, label\n",
    "\n",
    "def make_dataset(filenames, labels, preprocess_f, shuffle=True):\n",
    "    filenames = tf.constant(filenames)\n",
    "    labels = tf.constant(labels)\n",
    "    dataset = tf.contrib.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(_parse_function, num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "    dataset = dataset.map(preprocess_f, num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=10000)  # don't forget to shuffle\n",
    "    batched_dataset = dataset.batch(args.batch_size)\n",
    "    return batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VGG_Finetuner(object):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        \n",
    "        train_filenames, train_labels = list_images(args.train_dir)\n",
    "    \n",
    "        n_classes = len(set(train_labels))\n",
    "\n",
    "        batched_train_dataset = make_dataset(train_filenames, train_labels, training_preprocess)\n",
    "        \n",
    "        # Now we define an iterator that can operator on either dataset.\n",
    "        # The iterator can be reinitialized by calling:\n",
    "        #     - sess.run(train_init_op) for 1 epoch on the training set\n",
    "        #     - sess.run(val_init_op)   for 1 epoch on the valiation set\n",
    "        # Once this is done, we don't need to feed any value for images and labels\n",
    "        # as they are automatically pulled out from the iterator queues.\n",
    "        # A reinitializable iterator is defined by its structure. We could use the\n",
    "        # `output_types` and `output_shapes` properties of either `train_dataset`\n",
    "        # or `validation_dataset` here, because they are compatible.\n",
    "        self.iterator = tf.contrib.data.Iterator.from_structure(batched_train_dataset.output_types,\n",
    "                                                           batched_train_dataset.output_shapes)\n",
    "        self.images, self.labels = self.iterator.get_next()\n",
    "        \n",
    "        self.train_init_op = self.iterator.make_initializer(batched_train_dataset)\n",
    "        \n",
    "        self.define_model(self.images, n_classes)\n",
    "        self.create_optimizer()\n",
    "        \n",
    "        # Evaluation metrics\n",
    "        prediction = tf.to_int32(tf.argmax(self.logits, 1))\n",
    "        self.correct_prediction = tf.equal(prediction, self.labels)\n",
    "        accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "        self.saver = tf.train.Saver(tf.global_variables(), max_to_keep=None)\n",
    "    \n",
    "        # Launch the session\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        self.sess = tf.Session(config=config)\n",
    "        self.init_fn(self.sess)  # load the pretrained weights\n",
    "        self.sess.run(self.fc8_init)  # initialize the new fc8 layer\n",
    "\n",
    "\n",
    "    def define_model(self, images, n_classes):\n",
    "        '''\n",
    "        # ---------------------------------------------------------------------\n",
    "        # For this example, we'll use VGG-16 pretrained on ImageNet. We will remove the\n",
    "        # last fully connected layer (fc8) and replace it with our own, with an\n",
    "        # output size n_classes.\n",
    "        # We will first train the last layer for a few epochs.\n",
    "        # Then we will train the entire model on our dataset for a few epochs.\n",
    "        # Get the pretrained model, specifying the num_classes argument to create a new\n",
    "        # fully connected replacing the last one, called \"vgg_16/fc8\"\n",
    "        # Each model has a different architecture, so \"vgg_16/fc8\" will change in another model.\n",
    "        # Here, logits gives us directly the predicted scores we wanted from the images.\n",
    "        # We pass a scope to initialize \"vgg_16/fc8\" weights with he_initializer\n",
    "        '''\n",
    "        self.is_training = tf.placeholder(tf.bool)\n",
    "        vgg = tf.contrib.slim.nets.vgg\n",
    "        with slim.arg_scope(vgg.vgg_arg_scope(weight_decay=args.weight_decay)):\n",
    "            self.logits, self.end_points = vgg.vgg_16(self.images, num_classes=n_classes, is_training=self.is_training,\n",
    "                               dropout_keep_prob=args.dropout_keep_prob)\n",
    "\n",
    "        # Specify where the model checkpoint is (pretrained weights).\n",
    "        model_path = args.model_path\n",
    "        assert(os.path.isfile(model_path))\n",
    "\n",
    "        # Restore only the layers up to fc7 (included)\n",
    "        # Calling function `init_fn(sess)` will load all the pretrained weights.\n",
    "        variables_to_restore = tf.contrib.framework.get_variables_to_restore(exclude=['vgg_16/fc8'])\n",
    "        self.init_fn = tf.contrib.framework.assign_from_checkpoint_fn(model_path, variables_to_restore)\n",
    "\n",
    "        # Initialization operation from scratch for the new \"fc8\" layers\n",
    "        # `get_variables` will only return the variables whose name starts with the given pattern\n",
    "        self.fc8_variables = tf.contrib.framework.get_variables('vgg_16/fc8')\n",
    "        self.fc8_init = tf.variables_initializer(self.fc8_variables)\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Using tf.losses, any loss is added to the tf.GraphKeys.LOSSES collection\n",
    "        # We can then call the total loss easily\n",
    "        tf.losses.sparse_softmax_cross_entropy(labels=self.labels, logits=self.logits)\n",
    "        self.loss = tf.losses.get_total_loss()\n",
    "\n",
    "    def create_optimizer(self):\n",
    "        # First we want to train only the reinitialized last layer fc8 for a few epochs.\n",
    "        # We run minimize the loss only with respect to the fc8 variables (weight and bias).\n",
    "        self.fc8_optimizer = tf.train.GradientDescentOptimizer(args.learning_rate1)\n",
    "        self.fc8_train_op = self.fc8_optimizer.minimize(self.loss, var_list=self.fc8_variables)\n",
    "\n",
    "        # Then we want to finetune the entire model for a few epochs.\n",
    "        # We run minimize the loss only with respect to all the variables.\n",
    "        self.full_optimizer = tf.train.GradientDescentOptimizer(args.learning_rate2)\n",
    "        self.full_train_op = self.full_optimizer.minimize(self.loss)\n",
    "\n",
    "    def train_last_layer(self, n_epochs):\n",
    "        for epoch in range(n_epochs):\n",
    "            # Run an epoch over the training data.\n",
    "            print('Starting epoch %d / %d' % (epoch + 1, n_epochs))\n",
    "            # Here we initialize the iterator with the training set.\n",
    "            # This means that we can go through an entire epoch until the iterator becomes empty.\n",
    "            self.sess.run(self.train_init_op)\n",
    "            while True:\n",
    "                try:\n",
    "                    _ = self.sess.run(self.fc8_train_op, {self.is_training: True})\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "            # Check accuracy on the train sets every epoch.\n",
    "            train_acc = check_accuracy(self.sess, self.correct_prediction, self.is_training, self.train_init_op)\n",
    "            print('Train accuracy: %f' % train_acc)\n",
    "\n",
    "    def train_all_layers(self, n_epochs):\n",
    "        for epoch in range(n_epochs):\n",
    "            print('Starting epoch %d / %d' % (epoch + 1, n_epochs))\n",
    "            self.sess.run(self.train_init_op)\n",
    "            while True:\n",
    "                try:\n",
    "                    _ = self.sess.run(self.full_train_op, {self.is_training: True})\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "            # Check accuracy on the train and val sets every epoch\n",
    "            train_acc = check_accuracy(self.sess, self.correct_prediction, self.is_training, self.train_init_op)\n",
    "            print('Train accuracy: %f' % train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = Args()\n",
    "args.train_dir = '/scr/optas/DATA/Meshes/Shape_Net_Core/2015_Summer_OUT/Images/'\n",
    "args.model_path = '/orions4-zfs/projects/optas/DATA/NN/vgg16_pretrained/vgg_16.ckpt'\n",
    "args.batch_size = 64\n",
    "args.num_workers = 10\n",
    "args.learning_rate1 = 1e-3\n",
    "args.learning_rate2 = 1e-5\n",
    "args.weight_decay = 5e-4\n",
    "args.dropout_keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /orions4-zfs/projects/optas/DATA/NN/vgg16_pretrained/vgg_16.ckpt\n"
     ]
    }
   ],
   "source": [
    "reset_tf_graph()\n",
    "vgg_ft = VGG_Finetuner(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 1\n",
      "Train accuracy: 0.855000\n"
     ]
    }
   ],
   "source": [
    "vgg_ft.train_last_layer(10)\n",
    "vgg_ft.train_all_layers(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_on_test(self, test_dir):\n",
    "    filenames, labels = list_images(test_dir)\n",
    "    \n",
    "    \n",
    "    batched_test_dataset = make_dataset(filenames, labels, val_preprocess, shuffle=False)        \n",
    "    self.test_init_op = self.iterator.make_initializer(batched_test_dataset)\n",
    "    \n",
    "    self.sess.run(self.test_init_op)\n",
    "\n",
    "    l = self.labels\n",
    "    f = self.end_points['vgg_16/fc7']\n",
    "    all_f = []\n",
    "    all_l = []\n",
    "    while True:\n",
    "        try:\n",
    "            b = self.sess.run([f, l], {self.is_training: False})\n",
    "            all_f.append(b[0])\n",
    "            all_l.append(b[1])\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    assert(np.all(np.hstack(all_l) == labels))\n",
    "    all_f = np.squeeze(np.vstack(all_f))\n",
    "    return filenames, all_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fnames, features = predict_on_test(vgg_ft, args.train_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
