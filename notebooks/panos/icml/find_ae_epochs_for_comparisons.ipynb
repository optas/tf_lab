{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "### For an AE which was the epoch that it achieved the lowest training loss? -best                  ###\n",
    "### For the collection of the AEs, when it achieved the lowest of the worst performing ae? -max_min ###\n",
    "### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 0\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook.gpu_utils import setup_one_gpu\n",
    "GPU = 0\n",
    "setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from general_tools.notebook.tf import reset_tf_graph\n",
    "from general_tools.in_out.basics import pickle_data\n",
    "\n",
    "import tf_lab.point_clouds.in_out as pio\n",
    "\n",
    "from tf_lab.point_clouds.in_out import PointCloudDataSet, write_model_ids_of_datasets\n",
    "from tf_lab.point_clouds.point_net_ae import PointNetAutoEncoder\n",
    "from tf_lab.point_clouds.autoencoder import Configuration as Conf\n",
    "import tf_lab.point_clouds.encoders_decoders as enc_dec\n",
    "\n",
    "\n",
    "from tf_lab.autopredictors.scripts.helper import shape_net_category_to_synth_id\n",
    "\n",
    "\n",
    "from tf_lab.autopredictors.plotting import plot_original_pclouds_vs_reconstructed, \\\n",
    "                                           plot_train_val_test_curves, plot_reconstructions_at_epoch\n",
    "\n",
    "\n",
    "from tf_lab.autopredictors.evaluate import eval_model, read_saved_epochs\n",
    "                                                  \n",
    "\n",
    "from general_tools.in_out.basics import create_dir, delete_files_in_directory, files_in_subdirs\n",
    "from general_tools.simpletons import select_first_last_and_k\n",
    "from geo_tool import Point_Cloud\n",
    "\n",
    "from tf_lab.nips.data_sets.shape_net import pc_loader as sn_pc_loader\n",
    "from tf_lab.nips.helper import center_pclouds_in_unit_sphere\n",
    "from tf_lab.icml.ae_farm_helper import EMD_Stats, Chamfer_Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class_name = 'chair'\n",
    "ae_loss = 'emd'\n",
    "n_pc_samples = 2048\n",
    "top_data_dir = '/orions4-zfs/projects/lins2/Panos_Space/DATA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6778 files containing complete point clouds were found.\n"
     ]
    }
   ],
   "source": [
    "# Load Raw Point-Clouds of class\n",
    "pclouds_path = osp.join(top_data_dir, 'Point_Clouds/Shape_Net/Core/from_manifold_meshes/centered/', str(n_pc_samples))\n",
    "syn_id = shape_net_category_to_synth_id()[class_name]\n",
    "pclouds_path = osp.join(pclouds_path, syn_id)\n",
    "file_names = pio.load_filenames_of_input_data(pclouds_path, '.ply')\n",
    "pclouds, model_ids, syn_ids = pio.load_crude_point_clouds(file_names=file_names, n_threads=50, loader=sn_pc_loader)\n",
    "print '%d files containing complete point clouds were found.' % (len(pclouds), )\n",
    "train_data = PointCloudDataSet(pclouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "ae_farm_chair_conv_arch_18_2048pts_emd\n",
      "Model restored in epoch 910.\n",
      "Model restored in epoch 920.\n",
      "Model restored in epoch 930.\n",
      "Model restored in epoch 940.\n",
      "Model restored in epoch 950.\n",
      "Model restored in epoch 960.\n",
      "Model restored in epoch 970.\n",
      "Model restored in epoch 980.\n",
      "Model restored in epoch 990.\n",
      "Model restored in epoch 1000.\n"
     ]
    }
   ],
   "source": [
    "# CONVOLUTIONAL ARCHS\n",
    "if ae_loss == 'emd':\n",
    "    experiment_stats = EMD_Stats\n",
    "else:\n",
    "    experiment_stats = Chamfer_Stats\n",
    "\n",
    "ae_ids = experiment_stats.experiments_ids\n",
    "\n",
    "losses = dict()\n",
    "for ae_id in ae_ids:\n",
    "    ae_name = '_'.join(['ae_farm', class_name, 'conv_arch', str(ae_id), str(n_pc_samples) + 'pts', ae_loss])\n",
    "    train_dir = osp.join(top_data_dir, 'OUT/icml/nn_models/ae_farming', ae_name)\n",
    "    conf = Conf.load(osp.join(train_dir, 'configuration'))\n",
    "    bneck = conf.encoder_args['n_filters'][-1]\n",
    "    print bneck \n",
    "    assert(experiment_stats.experiment_id_to_bneck[ae_id] == bneck)\n",
    "    saved_epochs = read_saved_epochs(conf.train_dir)\n",
    "    reset_tf_graph()\n",
    "    ae = PointNetAutoEncoder(ae_name, conf)    \n",
    "    print ae_name\n",
    "    losses[ae_name] = []\n",
    "    for epoch in saved_epochs:\n",
    "        ae.restore_model(conf.train_dir, epoch, verbose=True)\n",
    "        loss_at_epoch = ae.evaluate(train_data, conf)[1]\n",
    "        losses[ae_name].append((epoch, loss_at_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Model restored in epoch 910.\n",
      "Model restored in epoch 920.\n",
      "Model restored in epoch 930.\n",
      "Model restored in epoch 940.\n",
      "Model restored in epoch 950.\n",
      "Model restored in epoch 960.\n",
      "Model restored in epoch 970.\n",
      "Model restored in epoch 980.\n",
      "Model restored in epoch 990.\n",
      "Model restored in epoch 1000.\n"
     ]
    }
   ],
   "source": [
    "# MLP ARCHS\n",
    "losses = dict()\n",
    "ae_id = 6\n",
    "ae_name = '_'.join(['ae_farm', class_name, 'mlp_arch', str(ae_id), str(n_pc_samples) + 'pts', ae_loss])\n",
    "train_dir = osp.join(top_data_dir, 'OUT/icml/nn_models/ae_farming', ae_name)\n",
    "conf = Conf.load(osp.join(train_dir, 'configuration'))\n",
    "bneck = conf.encoder_args['n_filters'][-1]\n",
    "print bneck \n",
    "\n",
    "saved_epochs = read_saved_epochs(conf.train_dir)\n",
    "reset_tf_graph()\n",
    "ae = PointNetAutoEncoder(ae_name, conf)    \n",
    "\n",
    "losses[ae_name] = []\n",
    "\n",
    "for epoch in saved_epochs[-10:]:\n",
    "    ae.restore_model(conf.train_dir, epoch, verbose=True)\n",
    "    loss_at_epoch = ae.evaluate(train_data, conf)[1]\n",
    "    losses[ae_name].append((epoch, loss_at_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108.468496492 990\n"
     ]
    }
   ],
   "source": [
    "epochs_ = [l[0] for l in losses[ae_name]]\n",
    "losses_ = [l[1] for l in losses[ae_name]]\n",
    "repo = np.argmin(losses_)\n",
    "print losses_[repo], epochs_[repo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64.51379999885097,\n",
       " 64.359766247913385,\n",
       " 64.501950304217658,\n",
       " 64.561083617200538,\n",
       " 64.202133845072922,\n",
       " 64.381325347756317,\n",
       " 64.16416609677708,\n",
       " 64.375140158888797,\n",
       " 63.921085462347882,\n",
       " 64.227192599290092]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prefix = 'ae_farm_chair_conv_arch_'\n",
    "postfix = '_2048pts_' + ae_loss\n",
    "ae_tag_to_id = lambda ae_name: int(ae_name[len(prefix):-len(postfix)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 (990, 50.992049003639345)\n",
      "64 (940, 54.250119469024398)\n",
      "128 (990, 51.128213850366365)\n",
      "32 (960, 56.104974105668369)\n",
      "256 (980, 51.021433926219608)\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "for ae_example in losses.keys():\n",
    "    ae_id = ae_tag_to_id(ae_example)\n",
    "    bneck = experiment_stats.experiment_id_to_bneck[ae_id]\n",
    "    losses[ae_example].sort(key=operator.itemgetter(1))\n",
    "    print bneck, losses[ae_example][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 260 56.4351911322\n",
      "64 590 56.1521346463\n",
      "128 290 56.2572510551\n",
      "32 960 56.1049741057\n",
      "256 290 56.3530345713\n"
     ]
    }
   ],
   "source": [
    "worst_of_best_value = 56.104974105668369\n",
    "for ae_example in losses.keys():\n",
    "    ae_id = ae_tag_to_id(ae_example)\n",
    "    bneck = experiment_stats.experiment_id_to_bneck[ae_id]\n",
    "    l_ae_sorted = np.array([pair[1] for pair in losses[ae_example]])\n",
    "    loc = np.searchsorted(l_ae_sorted, worst_of_best_value)\n",
    "    epoch_ae_sorted = np.array([pair[0] for pair in losses[ae_example]])\n",
    "    print bneck, epoch_ae_sorted[loc], l_ae_sorted[loc]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
