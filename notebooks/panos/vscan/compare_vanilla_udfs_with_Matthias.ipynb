{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orions4-zfs/projects/lins2/Panos_Space/Git_Repos/geo_tool/solids/mesh.py:26: UserWarning: Mayavi library was not found. Some graphics utilities will be disabled.\n",
      "  warnings.warn('Mayavi library was not found. Some graphics utilities will be disabled.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "    \n",
    "from tf_lab.fundamentals.utils import set_visible_GPUs, reset_tf_graph\n",
    "\n",
    "import tf_lab.point_clouds.in_out as pio\n",
    "from tf_lab.point_clouds.in_out import PointCloudDataSet, write_model_ids_of_datasets\n",
    "from tf_lab.point_clouds.point_net_ae import PointNetAutoEncoder\n",
    "from tf_lab.point_clouds.autoencoder import Configuration as Conf\n",
    "import tf_lab.point_clouds.encoders_decoders as enc_dec\n",
    "\n",
    "\n",
    "import tf_lab.autopredictors.scripts.virt_scan_data as vscan\n",
    "\n",
    "from tf_lab.autopredictors.scripts.helper import shape_net_category_to_synth_id, points_extension, \\\n",
    "                                                 shape_net_core_synth_id_to_category\n",
    "\n",
    "from tf_lab.autopredictors.scripts import minhyuk_data\n",
    "\n",
    "from tf_lab.autopredictors.plotting import plot_original_pclouds_vs_reconstructed, \\\n",
    "                                           plot_train_val_test_curves, plot_reconstructions_at_epoch\n",
    "        \n",
    "from tf_lab.autopredictors.evaluate import eval_model, read_saved_epochs, accuracy_of_completion, \\\n",
    "                                           coverage_of_completion, save_reconstructions, \\\n",
    "                                           save_pc_prediction_stats\n",
    "                                                  \n",
    "\n",
    "from general_tools.in_out.basics import create_dir, delete_files_in_directory, files_in_subdirs\n",
    "from general_tools.simpletons import select_first_last_and_k\n",
    "from geo_tool import Point_Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l1_loss_comparison_like_Angela(gt_df, pred_df, unknown_space_mask, ignore_range=None):\n",
    "    if ignore_range is not None:\n",
    "        close_enough_mask = np.logical_or(pred_df < ignore_range, gt_df < ignore_range)\n",
    "    else:\n",
    "        close_enough_mask = np.ones(pred_df.shape, dtype=np.bool)\n",
    "\n",
    "    total_mask = close_enough_mask * unknown_space_mask\n",
    "    return np.sum(np.abs(gt_df - pred_df) * total_mask) / np.sum(total_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tf_lab.autopredictors.scripts.fsdf_bin_parser import fsdf_bin_parser\n",
    "from tf_lab.autopredictors.scripts.virt_scan_data import load_signed_distance_field\n",
    "                    \n",
    "top_our_out_dir = '/orions4-zfs/projects/lins2/Lin_Virtual/Data/Output/PC2DF_All/Chair/'\n",
    "sdf_top_dir = '/orions4-zfs/projects/lins2/Panos_Space/DATA/From_Matthias/shapenet_dim32_sdf/03001627'\n",
    "matthias_output = '/orions4-zfs/projects/lins2/Panos_Space/DATA/From_Matthias/predictions-test-small/epn/test/03001627/'\n",
    "\n",
    "matthias_end = '.fsdf.bin'\n",
    "matthias_preds = [f for f in files_in_subdirs(matthias_output, matthias_end + '$')]\n",
    "n_examples = len(matthias_preds)\n",
    "\n",
    "total_l1 = np.zeros((n_examples, 2))\n",
    "total_l1_with_unknown_mask = np.zeros((n_examples, 2))\n",
    "total_l1_with_unknown_mask_range_3 = np.zeros((n_examples, 2))\n",
    "\n",
    "for i, m_pred_file in enumerate(matthias_preds):\n",
    "    model_name = m_pred_file.split('/')[-1][:-len(matthias_end)]\n",
    "    tokens = model_name.split('_')\n",
    "    model_name = tokens[0]\n",
    "    scan_id = tokens[2]    \n",
    "    our_pred_file = osp.join(top_our_out_dir, model_name + '___' + scan_id + '___pred_df.txt')\n",
    "    gt_file = osp.join(top_our_out_dir, model_name + '___' + scan_id + '___gt_df.txt')\n",
    "    matthias_prediction = fsdf_bin_parser(m_pred_file)\n",
    "    our_pred_udf = np.loadtxt(our_pred_file).reshape(32, 32, 32)\n",
    "    gt_udf = np.loadtxt(gt_file).reshape(32, 32, 32)\n",
    "    \n",
    "    total_l1[i, 0] = np.mean(np.abs(gt_udf - our_pred_udf))\n",
    "    total_l1[i, 1] = np.mean(np.abs(gt_udf - matthias_prediction))\n",
    "    \n",
    "    sdf_values, unknown_space_mask = load_signed_distance_field(osp.join(sdf_top_dir, model_name + '__' + scan_id + '__.sdf') )\n",
    "    \n",
    "    total_l1_with_unknown_mask[i, 0] = l1_loss_comparison_like_Angela(gt_udf, our_pred_udf, unknown_space_mask)\n",
    "    total_l1_with_unknown_mask[i, 1] = l1_loss_comparison_like_Angela(gt_udf, matthias_prediction, unknown_space_mask)\n",
    "    \n",
    "    total_l1_with_unknown_mask_range_3[i, 0] = l1_loss_comparison_like_Angela(gt_udf, our_pred_udf, unknown_space_mask, 3.0)\n",
    "    total_l1_with_unknown_mask_range_3[i, 1] = l1_loss_comparison_like_Angela(gt_udf, matthias_prediction, unknown_space_mask, 3.0)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.120854030851 0.129558540507\n",
      "0.105813762648 0.112270658599\n",
      "0.130946168334 0.158681399643\n",
      "0.0943373778443 0.106144282691\n",
      "0.0813965311335 0.0889047503149\n",
      "0.100880606212 0.124777818535\n"
     ]
    }
   ],
   "source": [
    "evaluator = np.mean\n",
    "\n",
    "print evaluator(total_l1[:,0]), evaluator(total_l1[:,1])\n",
    "print evaluator(total_l1_with_unknown_mask[:,0]), evaluator(total_l1_with_unknown_mask[:,1])\n",
    "print evaluator(total_l1_with_unknown_mask_range_3[:,0]), evaluator(total_l1_with_unknown_mask_range_3[:,1])\n",
    "\n",
    "\n",
    "evaluator = np.median\n",
    "\n",
    "print evaluator(total_l1[:,0]), evaluator(total_l1[:,1])\n",
    "print evaluator(total_l1_with_unknown_mask[:,0]), evaluator(total_l1_with_unknown_mask[:,1])\n",
    "print evaluator(total_l1_with_unknown_mask_range_3[:,0]), evaluator(total_l1_with_unknown_mask_range_3[:,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
