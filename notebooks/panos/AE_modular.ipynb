{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoders on PointClouds - Modular Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orions4-zfs/projects/lins2/Lin_Space/Git_Repos/geo_tool/solids/mesh.py:25: UserWarning: Mayavi library was not found. Some graphics utilities will be disabled.\n",
      "  warnings.warn('Mayavi library was not found. Some graphics utilities will be disabled.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tf_lab.point_clouds.in_out as pio\n",
    "from tf_lab.point_clouds.in_out import PointCloudDataSet\n",
    "\n",
    "from tf_lab.point_clouds.point_net_ae import PointNetAutoEncoder\n",
    "from tf_lab.point_clouds.point_net_ae import Configuration as PN_Conf\n",
    "\n",
    "# import tf_lab.point_clouds.various_encoders_decoders as enc_dec\n",
    "# import tf_lab.models.point_net_based_AE as pnAE\n",
    "\n",
    "from general_tools.in_out import create_dir\n",
    "from geo_tool import Point_Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/orions4-zfs/projects/lins2/Panos_Space/DATA/OUT/models/scratch'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_path = '/Users/optas/DATA/Point_Clouds/Shape_Net_Core/from_manifold_meshes/1024/03001627'\n",
    "# train_dir = '/Users/optas/DATA/Neural_Nets/Models/Point_Cloud_AE/'\n",
    "\n",
    "data_path = '/orions4-zfs/projects/lins2/Panos_Space/DATA/ShapeNetPointClouds/from_manifold_meshes/1024/03001627/'\n",
    "train_dir = '/orions4-zfs/projects/lins2/Panos_Space/DATA/OUT/models/'\n",
    "\n",
    "experiment_name = 'scratch'\n",
    "train_dir = osp.join(train_dir, experiment_name)\n",
    "\n",
    "create_dir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6778 files containing  point clouds were found.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-705a22402826>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m                                                                    \u001b[0mvalidate_perc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                                                    \u001b[0mtest_perc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                                                                    seed=seed)\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# train_data = PointCloudDataSet(train_data_[0], labels=train_data_[1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/orions4-zfs/projects/lins2/Lin_Space/Git_Repos/tf_lab/point_clouds/in_out.pyc\u001b[0m in \u001b[0;36mtrain_validate_test_split\u001b[1;34m(arrays, train_perc, validate_perc, test_perc, shuffle, seed)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m                 \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "file_names = pio.load_filenames_of_input_data(data_path)\n",
    "\n",
    "\n",
    "pclouds, model_names = pio.load_crude_point_clouds(file_names=file_names, n_threads=11)\n",
    "\n",
    "\n",
    "train_data_, val_data_, test_data_ = pio.train_validate_test_split([pclouds, model_names],\n",
    "                                                                   train_perc=0.8,\n",
    "                                                                   validate_perc=0.1,\n",
    "                                                                   test_perc=0.1,\n",
    "                                                                   seed=seed)\n",
    "\n",
    "# train_data = PointCloudDataSet(train_data_[0], labels=train_data_[1])\n",
    "# val_data = PointCloudDataSet(val_data_[0], labels=val_data_[1])\n",
    "# test_data = PointCloudDataSet(test_data_[0], labels=test_data_[1])\n",
    "\n",
    "# train_data = PointCloudDataSet(train_data_, noise={'frac':0.20, 'filler':0.0})\n",
    "# val_data = PointCloudDataSet(val_data_, noise={'frac':0.20, 'filler':0.0})\n",
    "# test_data = PointCloudDataSet(test_data_, noise={'frac':0.20, 'filler':0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<code object load_crude_point_clouds at 0x7f0ce7111730, file \"/orions4-zfs/projects/lins2/Lin_Space/Git_Repos/tf_lab/point_clouds/in_out.py\", line 22>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pio.load_crude_point_clouds.__code__\n",
    "\n",
    "# model_names\n",
    "\n",
    "\n",
    "\n",
    "# names_sorted = np.array([model_names[k] for k in sorted(model_names.keys())], dtype=object)\n",
    "\n",
    "# train_data_, val_data_, test_data_ = pio.train_validate_test_split([all_pclouds, names_sorted],\n",
    "#                                                                    train_perc=0.8,\n",
    "#                                                                    validate_perc=0.1,\n",
    "#                                                                    test_perc=0.1,\n",
    "#                                                                    seed=seed)\n",
    "\n",
    "# print test_data_[0].shape\n",
    "# print test_data_[1].shape\n",
    "\n",
    "# train_data = PointCloudDataSet(train_data_[0], labels=train_data_[1])\n",
    "\n",
    "# pc, lab, _ = train_data.next_batch(4)\n",
    "# print lab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', '0001', 'training time (minutes)=', '0.0721', 'loss=', '0.015513058')\n",
      "('Epoch:', '0002', 'training time (minutes)=', '0.0539', 'loss=', '0.014662071')\n",
      "('Epoch:', '0003', 'training time (minutes)=', '0.0536', 'loss=', '0.014524366')\n",
      "('Epoch:', '0004', 'training time (minutes)=', '0.0540', 'loss=', '0.014451731')\n",
      "('Epoch:', '0005', 'training time (minutes)=', '0.0575', 'loss=', '0.014400056')\n",
      "('Epoch:', '0006', 'training time (minutes)=', '0.0583', 'loss=', '0.014354029')\n",
      "('Epoch:', '0007', 'training time (minutes)=', '0.0545', 'loss=', '0.014311319')\n",
      "('Epoch:', '0008', 'training time (minutes)=', '0.0540', 'loss=', '0.014274926')\n",
      "('Epoch:', '0009', 'training time (minutes)=', '0.0543', 'loss=', '0.014242324')\n",
      "('Epoch:', '0010', 'training time (minutes)=', '0.0544', 'loss=', '0.014217878')\n",
      "('Epoch:', '0011', 'training time (minutes)=', '0.0543', 'loss=', '0.014188154')\n",
      "('Epoch:', '0012', 'training time (minutes)=', '0.0543', 'loss=', '0.014156700')\n",
      "('Epoch:', '0013', 'training time (minutes)=', '0.0542', 'loss=', '0.014137931')\n",
      "('Epoch:', '0014', 'training time (minutes)=', '0.0546', 'loss=', '0.014105842')\n",
      "('Epoch:', '0015', 'training time (minutes)=', '0.0543', 'loss=', '0.014083956')\n",
      "('Epoch:', '0016', 'training time (minutes)=', '0.0550', 'loss=', '0.014062934')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 0.015513058284441923, 4.325829029083252),\n",
       " (2, 0.014662070718776036, 3.231682062149048),\n",
       " (3, 0.01452436573748439, 3.2152631282806396),\n",
       " (4, 0.014451730546173795, 3.2403531074523926),\n",
       " (5, 0.014400056161233859, 3.4529199600219727),\n",
       " (6, 0.014354029416048219, 3.497802972793579),\n",
       " (7, 0.014311318907790518, 3.271981954574585),\n",
       " (8, 0.01427492623413291, 3.239827871322632),\n",
       " (9, 0.014242323967748462, 3.256922960281372),\n",
       " (10, 0.014217877897994105, 3.263293981552124),\n",
       " (11, 0.01418815357301288, 3.258782148361206),\n",
       " (12, 0.014156700008827162, 3.2559449672698975),\n",
       " (13, 0.014137931140586459, 3.25374698638916),\n",
       " (14, 0.014105841572434261, 3.277963161468506),\n",
       " (15, 0.01408395581153596, 3.2599499225616455),\n",
       " (16, 0.01406293435922628, 3.297757148742676)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "\n",
    "conf = PN_Conf(n_input = [1024, 3],\n",
    "               training_epochs = 16,\n",
    "               batch_size = 20,\n",
    "               loss = 'l2',\n",
    "               train_dir = train_dir,\n",
    "               loss_display_step = 1,               \n",
    "               saver_step = 2,\n",
    "               saver_max_to_keep = 5,\n",
    "               learning_rate = 0.0002,\n",
    "               denoising = False\n",
    "              )\n",
    "\n",
    "reset_graph()\n",
    "ae = PointNetAutoEncoder(experiment_name, conf)\n",
    "ae.train(train_data, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored in epoch 64.\n",
      "('Epoch:', '0065', 'training time (minutes)=', '0.0642', 'loss=', '0.012697512')\n",
      "('Epoch:', '0066', 'training time (minutes)=', '0.0626', 'loss=', '0.012667810')\n",
      "('Epoch:', '0067', 'training time (minutes)=', '0.0625', 'loss=', '0.012652160')\n",
      "('Epoch:', '0068', 'training time (minutes)=', '0.0626', 'loss=', '0.012629045')\n",
      "('Epoch:', '0069', 'training time (minutes)=', '0.0622', 'loss=', '0.012612440')\n",
      "('Epoch:', '0070', 'training time (minutes)=', '0.0625', 'loss=', '0.012593937')\n",
      "('Epoch:', '0071', 'training time (minutes)=', '0.0626', 'loss=', '0.012568735')\n",
      "('Epoch:', '0072', 'training time (minutes)=', '0.0627', 'loss=', '0.012553152')\n",
      "('Epoch:', '0073', 'training time (minutes)=', '0.0632', 'loss=', '0.012539009')\n",
      "('Epoch:', '0074', 'training time (minutes)=', '0.0625', 'loss=', '0.012519164')\n",
      "('Epoch:', '0075', 'training time (minutes)=', '0.0632', 'loss=', '0.012494665')\n",
      "('Epoch:', '0076', 'training time (minutes)=', '0.0634', 'loss=', '0.012475728')\n",
      "('Epoch:', '0077', 'training time (minutes)=', '0.0633', 'loss=', '0.012460683')\n",
      "('Epoch:', '0078', 'training time (minutes)=', '0.0630', 'loss=', '0.012438881')\n",
      "('Epoch:', '0079', 'training time (minutes)=', '0.0627', 'loss=', '0.012421082')\n",
      "('Epoch:', '0080', 'training time (minutes)=', '0.0628', 'loss=', '0.012400298')\n",
      "('Epoch:', '0081', 'training time (minutes)=', '0.0633', 'loss=', '0.012386377')\n",
      "('Epoch:', '0082', 'training time (minutes)=', '0.0632', 'loss=', '0.012367646')\n",
      "('Epoch:', '0083', 'training time (minutes)=', '0.0635', 'loss=', '0.012354695')\n",
      "('Epoch:', '0084', 'training time (minutes)=', '0.0627', 'loss=', '0.012331194')\n",
      "('Epoch:', '0085', 'training time (minutes)=', '0.0633', 'loss=', '0.012311639')\n",
      "('Epoch:', '0086', 'training time (minutes)=', '0.0629', 'loss=', '0.012297716')\n",
      "('Epoch:', '0087', 'training time (minutes)=', '0.0632', 'loss=', '0.012287205')\n",
      "('Epoch:', '0088', 'training time (minutes)=', '0.0635', 'loss=', '0.012271602')\n",
      "('Epoch:', '0089', 'training time (minutes)=', '0.0633', 'loss=', '0.012247314')\n",
      "('Epoch:', '0090', 'training time (minutes)=', '0.0632', 'loss=', '0.012229361')\n",
      "('Epoch:', '0091', 'training time (minutes)=', '0.0631', 'loss=', '0.012217501')\n",
      "('Epoch:', '0092', 'training time (minutes)=', '0.0633', 'loss=', '0.012199909')\n",
      "('Epoch:', '0093', 'training time (minutes)=', '0.0630', 'loss=', '0.012184622')\n",
      "('Epoch:', '0094', 'training time (minutes)=', '0.0635', 'loss=', '0.012169400')\n",
      "('Epoch:', '0095', 'training time (minutes)=', '0.0633', 'loss=', '0.012152422')\n",
      "('Epoch:', '0096', 'training time (minutes)=', '0.0626', 'loss=', '0.012142048')\n",
      "('Epoch:', '0097', 'training time (minutes)=', '0.0633', 'loss=', '0.012125635')\n",
      "('Epoch:', '0098', 'training time (minutes)=', '0.0628', 'loss=', '0.012110480')\n",
      "('Epoch:', '0099', 'training time (minutes)=', '0.0631', 'loss=', '0.012097493')\n",
      "('Epoch:', '0100', 'training time (minutes)=', '0.0633', 'loss=', '0.012081730')\n",
      "('Epoch:', '0101', 'training time (minutes)=', '0.0633', 'loss=', '0.012061247')\n",
      "('Epoch:', '0102', 'training time (minutes)=', '0.0631', 'loss=', '0.012048547')\n",
      "('Epoch:', '0103', 'training time (minutes)=', '0.0630', 'loss=', '0.012034280')\n",
      "('Epoch:', '0104', 'training time (minutes)=', '0.0633', 'loss=', '0.012025942')\n",
      "('Epoch:', '0105', 'training time (minutes)=', '0.0629', 'loss=', '0.012007147')\n",
      "('Epoch:', '0106', 'training time (minutes)=', '0.0636', 'loss=', '0.011999951')\n",
      "('Epoch:', '0107', 'training time (minutes)=', '0.0633', 'loss=', '0.011981220')\n",
      "('Epoch:', '0108', 'training time (minutes)=', '0.0627', 'loss=', '0.011964423')\n",
      "('Epoch:', '0109', 'training time (minutes)=', '0.0635', 'loss=', '0.011955404')\n",
      "('Epoch:', '0110', 'training time (minutes)=', '0.0630', 'loss=', '0.011941144')\n",
      "('Epoch:', '0111', 'training time (minutes)=', '0.0634', 'loss=', '0.011929243')\n",
      "('Epoch:', '0112', 'training time (minutes)=', '0.0635', 'loss=', '0.011918706')\n",
      "('Epoch:', '0113', 'training time (minutes)=', '0.0633', 'loss=', '0.011907804')\n",
      "('Epoch:', '0114', 'training time (minutes)=', '0.0634', 'loss=', '0.011892052')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(65, 0.012697511844034564, 3.8490238189697266),\n",
       " (66, 0.01266780976769669, 3.758256196975708),\n",
       " (67, 0.01265215964444889, 3.7483510971069336),\n",
       " (68, 0.012629044785188353, 3.7576589584350586),\n",
       " (69, 0.012612440221259074, 3.7304580211639404),\n",
       " (70, 0.012593936511896194, 3.752977132797241),\n",
       " (71, 0.012568735400716537, 3.7530291080474854),\n",
       " (72, 0.012553151861877899, 3.7635409832000732),\n",
       " (73, 0.01253900887286531, 3.7946090698242188),\n",
       " (74, 0.012519164330487541, 3.7474780082702637),\n",
       " (75, 0.012494664749206212, 3.7915070056915283),\n",
       " (76, 0.012475727888930768, 3.8038361072540283),\n",
       " (77, 0.01246068272327255, 3.7994539737701416),\n",
       " (78, 0.012438881025405607, 3.777522087097168),\n",
       " (79, 0.012421081602106015, 3.761646032333374),\n",
       " (80, 0.012400297908545421, 3.769214153289795),\n",
       " (81, 0.012386376969516277, 3.8005449771881104),\n",
       " (82, 0.012367646017445189, 3.7930490970611572),\n",
       " (83, 0.01235469466425836, 3.808253049850464),\n",
       " (84, 0.012331194096550731, 3.762901782989502),\n",
       " (85, 0.0123116389927334, 3.796673059463501),\n",
       " (86, 0.0122977163766363, 3.7749509811401367),\n",
       " (87, 0.012287205315411531, 3.791416883468628),\n",
       " (88, 0.012271601782348762, 3.8115949630737305),\n",
       " (89, 0.012247313545996192, 3.799118995666504),\n",
       " (90, 0.012229360712217889, 3.7921481132507324),\n",
       " (91, 0.012217500690384544, 3.788548231124878),\n",
       " (92, 0.012199909051680917, 3.797408103942871),\n",
       " (93, 0.012184622371053784, 3.7796781063079834),\n",
       " (94, 0.012169399755797262, 3.8123779296875),\n",
       " (95, 0.012152421989261664, 3.7977020740509033),\n",
       " (96, 0.012142048292961727, 3.757755994796753),\n",
       " (97, 0.012125634956018951, 3.7987771034240723),\n",
       " (98, 0.012110479787761875, 3.770059823989868),\n",
       " (99, 0.012097492638796678, 3.7862250804901123),\n",
       " (100, 0.01208173012106621, 3.795254945755005),\n",
       " (101, 0.012061247065993253, 3.7962019443511963),\n",
       " (102, 0.012048547382971677, 3.786998987197876),\n",
       " (103, 0.012034280400901922, 3.779716968536377),\n",
       " (104, 0.012025941706286585, 3.796070098876953),\n",
       " (105, 0.01200714663385905, 3.7744650840759277),\n",
       " (106, 0.011999951118802673, 3.815423011779785),\n",
       " (107, 0.011981219850563034, 3.79636287689209),\n",
       " (108, 0.011964423279535726, 3.764676809310913),\n",
       " (109, 0.011955403911836473, 3.812833786010742),\n",
       " (110, 0.011941144046995693, 3.782827138900757),\n",
       " (111, 0.011929243442179752, 3.8023171424865723),\n",
       " (112, 0.011918706334852425, 3.8092100620269775),\n",
       " (113, 0.011907804176568766, 3.7982470989227295),\n",
       " (114, 0.01189205161127437, 3.804255962371826)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "ae = PointNetAutoEncoder(experiment_name, conf)\n",
    "ae.restore_model(conf.train_dir, 64)\n",
    "conf.training_epochs = 50\n",
    "conf.loss = 'Chamfer'\n",
    "ae.train(train_data, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
