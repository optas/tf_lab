{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 1\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook.gpu_utils import setup_one_gpu\n",
    "GPU = 1\n",
    "setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orions4-zfs/projects/lins2/Panos_Space/Git_Repos/geo_tool/solids/mesh.py:26: UserWarning: Mayavi library was not found. Some graphics utilities will be disabled.\n",
      "  warnings.warn('Mayavi library was not found. Some graphics utilities will be disabled.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from general_tools.notebook.tf import reset_tf_graph\n",
    "\n",
    "import tf_lab.point_clouds.in_out as pio\n",
    "\n",
    "from tf_lab.point_clouds.in_out import PointCloudDataSet, write_model_ids_of_datasets\n",
    "from tf_lab.point_clouds.point_net_ae import PointNetAutoEncoder\n",
    "from tf_lab.point_clouds.autoencoder import Configuration as Conf\n",
    "import tf_lab.point_clouds.encoders_decoders as enc_dec\n",
    "\n",
    "\n",
    "from tf_lab.autopredictors.scripts.helper import shape_net_category_to_synth_id\n",
    "\n",
    "\n",
    "from tf_lab.autopredictors.plotting import plot_original_pclouds_vs_reconstructed, \\\n",
    "                                           plot_train_val_test_curves, plot_reconstructions_at_epoch\n",
    "\n",
    "\n",
    "from tf_lab.autopredictors.evaluate import eval_model, read_saved_epochs\n",
    "                                                  \n",
    "\n",
    "from general_tools.in_out.basics import create_dir, delete_files_in_directory, files_in_subdirs\n",
    "from general_tools.simpletons import select_first_last_and_k\n",
    "from geo_tool import Point_Cloud\n",
    "\n",
    "from tf_lab.nips.shape_net import pc_loader as sn_pc_loader\n",
    "from tf_lab.nips.helper import center_pclouds_in_unit_sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me the class type.\n",
      "car\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/orions4-zfs/projects/lins2/Panos_Space/DATA/OUT/models/nips/vanilla_ae/car_conv_arch_1_2048pts_emd'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_pc_samples = 2048\n",
    "do_training = True\n",
    "first_time_running = True\n",
    "load_model = False\n",
    "load_epoch = None\n",
    "seed = 42\n",
    "\n",
    "max_training_epochs = 1000\n",
    "loss = 'emd'\n",
    "\n",
    "class_name = raw_input('Give me the class type.\\n').lower()\n",
    "syn_id = shape_net_category_to_synth_id()[class_name]\n",
    "\n",
    "experiment_name = class_name + '_' + 'conv_arch_1_' + str(n_pc_samples) +  'pts_' + loss\n",
    "\n",
    "\n",
    "top_data_dir = '/orions4-zfs/projects/lins2/Panos_Space/DATA/'\n",
    "train_dir = osp.join(top_data_dir, 'OUT/models/nips/vanilla_ae/')\n",
    "train_dir = osp.join(train_dir, experiment_name)\n",
    "create_dir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7497 files containing complete point clouds were found.\n"
     ]
    }
   ],
   "source": [
    "# Load Raw Point-Clouds of class\n",
    "pclouds_path = osp.join(top_data_dir, 'Point_Clouds/Shape_Net/Core/from_manifold_meshes/centered/', str(n_pc_samples))\n",
    "pclouds_path = osp.join(pclouds_path, syn_id)\n",
    "file_names = pio.load_filenames_of_input_data(pclouds_path, '.ply')\n",
    "pclouds, model_ids, syn_ids = pio.load_crude_point_clouds(file_names=file_names, n_threads=50, loader=sn_pc_loader)\n",
    "print '%d files containing complete point clouds were found.' % (len(pclouds), )\n",
    "\n",
    "train_data = PointCloudDataSet(pclouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if n_pc_samples == 2048:\n",
    "    encoder_args = {'n_filters': [128, 128, 256, 512],\n",
    "                    'filter_sizes' :[40, 20, 10, 10],\n",
    "                    'strides': [1, 2, 2, 1]}\n",
    "else:\n",
    "    assert(False)\n",
    "    \n",
    "if load_model:\n",
    "    conf = Conf.load(osp.join(train_dir, 'configuration'))\n",
    "    print conf\n",
    "else:\n",
    "    n_input = [n_pc_samples, 3]\n",
    "\n",
    "    decoder_args = {'layer_sizes': [1024, 2048, np.prod(n_input)]}\n",
    "\n",
    "    conf = Conf(\n",
    "                n_input = n_input,\n",
    "                training_epochs = max_training_epochs,\n",
    "                batch_size = 50,\n",
    "                loss = loss,\n",
    "                denoising = False,\n",
    "                train_dir = train_dir,\n",
    "                loss_display_step = 1,\n",
    "                saver_step = 10,\n",
    "                learning_rate = 0.0005,\n",
    "                z_rotate = False, \n",
    "                encoder = enc_dec.encoder_with_convs_and_symmetry,\n",
    "                encoder_args = encoder_args,\n",
    "                decoder = enc_dec.decoder_with_fc_only,\n",
    "                decoder_args = decoder_args,        \n",
    "               )\n",
    "\n",
    "    conf.experiment_name = experiment_name\n",
    "    conf.save(osp.join(conf.train_dir, 'configuration'))\n",
    "    conf.allow_gpu_growth = False\n",
    "    \n",
    "reset_tf_graph()\n",
    "ae = PointNetAutoEncoder(experiment_name, conf)\n",
    "\n",
    "if load_model:\n",
    "\n",
    "    if load_epoch is None: # load last saved.\n",
    "        saved_epochs = read_saved_epochs(conf.train_dir)\n",
    "        load_epoch = saved_epochs[-1]\n",
    "        \n",
    "    ae.restore_model(conf.train_dir, load_epoch, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', '0001', 'training time (minutes)=', '0.5103', 'loss=', '152.791702731')\n",
      "INFO:tensorflow:/orions4-zfs/projects/lins2/Panos_Space/DATA/OUT/models/nips/vanilla_ae/car_conv_arch_1_2048pts_emd/models.ckpt-1 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0002', 'training time (minutes)=', '0.4929', 'loss=', '121.165645113')\n",
      "('Epoch:', '0003', 'training time (minutes)=', '0.5061', 'loss=', '110.724114796')\n",
      "('Epoch:', '0004', 'training time (minutes)=', '0.5106', 'loss=', '105.153600040')\n",
      "('Epoch:', '0005', 'training time (minutes)=', '0.5072', 'loss=', '98.628666001')\n",
      "('Epoch:', '0006', 'training time (minutes)=', '0.5100', 'loss=', '95.269238824')\n",
      "('Epoch:', '0007', 'training time (minutes)=', '0.5083', 'loss=', '92.058676598')\n",
      "('Epoch:', '0008', 'training time (minutes)=', '0.5082', 'loss=', '87.727121136')\n",
      "('Epoch:', '0009', 'training time (minutes)=', '0.5106', 'loss=', '84.847292241')\n",
      "('Epoch:', '0010', 'training time (minutes)=', '0.5110', 'loss=', '83.418689139')\n",
      "INFO:tensorflow:/orions4-zfs/projects/lins2/Panos_Space/DATA/OUT/models/nips/vanilla_ae/car_conv_arch_1_2048pts_emd/models.ckpt-10 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0011', 'training time (minutes)=', '0.5062', 'loss=', '82.135846541')\n",
      "('Epoch:', '0012', 'training time (minutes)=', '0.5110', 'loss=', '80.502128755')\n",
      "('Epoch:', '0013', 'training time (minutes)=', '0.5071', 'loss=', '79.561617038')\n",
      "('Epoch:', '0014', 'training time (minutes)=', '0.5112', 'loss=', '78.157169368')\n",
      "('Epoch:', '0015', 'training time (minutes)=', '0.5075', 'loss=', '77.402401201')\n",
      "('Epoch:', '0016', 'training time (minutes)=', '0.5122', 'loss=', '76.176090625')\n",
      "('Epoch:', '0017', 'training time (minutes)=', '0.5093', 'loss=', '75.787455616')\n",
      "('Epoch:', '0018', 'training time (minutes)=', '0.5111', 'loss=', '74.748607712')\n",
      "('Epoch:', '0019', 'training time (minutes)=', '0.5106', 'loss=', '74.411643982')\n",
      "('Epoch:', '0020', 'training time (minutes)=', '0.5110', 'loss=', '74.166465452')\n",
      "INFO:tensorflow:/orions4-zfs/projects/lins2/Panos_Space/DATA/OUT/models/nips/vanilla_ae/car_conv_arch_1_2048pts_emd/models.ckpt-20 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0021', 'training time (minutes)=', '0.5027', 'loss=', '73.210089306')\n",
      "('Epoch:', '0022', 'training time (minutes)=', '0.5076', 'loss=', '72.702022220')\n",
      "('Epoch:', '0023', 'training time (minutes)=', '0.5074', 'loss=', '72.687037065')\n",
      "('Epoch:', '0024', 'training time (minutes)=', '0.5075', 'loss=', '71.722436790')\n",
      "('Epoch:', '0025', 'training time (minutes)=', '0.5101', 'loss=', '71.916297708')\n",
      "('Epoch:', '0026', 'training time (minutes)=', '0.5080', 'loss=', '71.073565694')\n",
      "('Epoch:', '0027', 'training time (minutes)=', '0.5075', 'loss=', '70.804046836')\n",
      "('Epoch:', '0028', 'training time (minutes)=', '0.5100', 'loss=', '70.525559649')\n",
      "('Epoch:', '0029', 'training time (minutes)=', '0.5066', 'loss=', '69.713514290')\n",
      "('Epoch:', '0030', 'training time (minutes)=', '0.5090', 'loss=', '69.497013220')\n",
      "INFO:tensorflow:/orions4-zfs/projects/lins2/Panos_Space/DATA/OUT/models/nips/vanilla_ae/car_conv_arch_1_2048pts_emd/models.ckpt-30 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0031', 'training time (minutes)=', '0.5034', 'loss=', '69.441884034')\n",
      "('Epoch:', '0032', 'training time (minutes)=', '0.5102', 'loss=', '69.332530438')\n",
      "('Epoch:', '0033', 'training time (minutes)=', '0.5078', 'loss=', '68.930806819')\n",
      "('Epoch:', '0034', 'training time (minutes)=', '0.5109', 'loss=', '68.525627699')\n",
      "('Epoch:', '0035', 'training time (minutes)=', '0.5073', 'loss=', '67.823662214')\n",
      "('Epoch:', '0036', 'training time (minutes)=', '0.5087', 'loss=', '67.629745176')\n",
      "('Epoch:', '0037', 'training time (minutes)=', '0.5083', 'loss=', '67.953896414')\n",
      "('Epoch:', '0038', 'training time (minutes)=', '0.5072', 'loss=', '67.492579057')\n",
      "('Epoch:', '0039', 'training time (minutes)=', '0.5081', 'loss=', '67.176842376')\n",
      "('Epoch:', '0040', 'training time (minutes)=', '0.5084', 'loss=', '66.909271445')\n",
      "INFO:tensorflow:/orions4-zfs/projects/lins2/Panos_Space/DATA/OUT/models/nips/vanilla_ae/car_conv_arch_1_2048pts_emd/models.ckpt-40 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0041', 'training time (minutes)=', '0.5034', 'loss=', '66.651237590')\n",
      "('Epoch:', '0042', 'training time (minutes)=', '0.5103', 'loss=', '65.870499963')\n",
      "('Epoch:', '0043', 'training time (minutes)=', '0.5076', 'loss=', '66.095648465')\n",
      "('Epoch:', '0044', 'training time (minutes)=', '0.5095', 'loss=', '66.492665464')\n",
      "('Epoch:', '0045', 'training time (minutes)=', '0.5090', 'loss=', '65.764342647')\n",
      "('Epoch:', '0046', 'training time (minutes)=', '0.5106', 'loss=', '65.299944756')\n",
      "('Epoch:', '0047', 'training time (minutes)=', '0.5103', 'loss=', '64.896804579')\n",
      "('Epoch:', '0048', 'training time (minutes)=', '0.5090', 'loss=', '65.131619754')\n",
      "('Epoch:', '0049', 'training time (minutes)=', '0.5094', 'loss=', '64.652386761')\n",
      "('Epoch:', '0050', 'training time (minutes)=', '0.5078', 'loss=', '64.710469547')\n",
      "INFO:tensorflow:/orions4-zfs/projects/lins2/Panos_Space/DATA/OUT/models/nips/vanilla_ae/car_conv_arch_1_2048pts_emd/models.ckpt-50 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0051', 'training time (minutes)=', '0.5055', 'loss=', '64.699002208')\n",
      "('Epoch:', '0052', 'training time (minutes)=', '0.5086', 'loss=', '64.060725167')\n",
      "('Epoch:', '0053', 'training time (minutes)=', '0.5106', 'loss=', '64.145046900')\n",
      "('Epoch:', '0054', 'training time (minutes)=', '0.5082', 'loss=', '63.620858365')\n",
      "('Epoch:', '0055', 'training time (minutes)=', '0.5078', 'loss=', '63.158207580')\n",
      "('Epoch:', '0056', 'training time (minutes)=', '0.5099', 'loss=', '62.987695297')\n",
      "('Epoch:', '0057', 'training time (minutes)=', '0.5074', 'loss=', '62.996184688')\n",
      "('Epoch:', '0058', 'training time (minutes)=', '0.5110', 'loss=', '63.244279797')\n",
      "('Epoch:', '0059', 'training time (minutes)=', '0.5077', 'loss=', '62.299715209')\n",
      "('Epoch:', '0060', 'training time (minutes)=', '0.5109', 'loss=', '62.091306136')\n",
      "INFO:tensorflow:/orions4-zfs/projects/lins2/Panos_Space/DATA/OUT/models/nips/vanilla_ae/car_conv_arch_1_2048pts_emd/models.ckpt-60 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0061', 'training time (minutes)=', '0.5070', 'loss=', '62.235845911')\n",
      "('Epoch:', '0062', 'training time (minutes)=', '0.5108', 'loss=', '62.449771292')\n",
      "('Epoch:', '0063', 'training time (minutes)=', '0.5109', 'loss=', '62.407045044')\n",
      "('Epoch:', '0064', 'training time (minutes)=', '0.5105', 'loss=', '61.730152028')\n",
      "('Epoch:', '0065', 'training time (minutes)=', '0.5108', 'loss=', '61.159547307')\n",
      "('Epoch:', '0066', 'training time (minutes)=', '0.5105', 'loss=', '61.599850059')\n",
      "('Epoch:', '0067', 'training time (minutes)=', '0.5110', 'loss=', '61.529951697')\n",
      "('Epoch:', '0068', 'training time (minutes)=', '0.5101', 'loss=', '61.133388980')\n"
     ]
    }
   ],
   "source": [
    "if do_training:\n",
    "    training_stats = []\n",
    "    training_stats.append(ae.train(train_data, conf))    \n",
    "    with open(osp.join(conf.train_dir, 'train_stats.txt'), 'a') as fout:\n",
    "        np.savetxt(fout, np.array(training_stats)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot Some feed-reconstruction pairs.\n",
    "feed = train_data.next_batch(1)[0]\n",
    "rec = ae.reconstruct(feed)[0]\n",
    "Point_Cloud(feed[0]).plot();\n",
    "Point_Cloud(rec[0]).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
