{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 1\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook import gpu_utils\n",
    "GPU = 1\n",
    "gpu_utils.setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orions4-zfs/projects/lins2/Panos_Space/Git_Repos/geo_tool/solids/mesh.py:26: UserWarning: Mayavi library was not found. Some graphics utilities will be disabled.\n",
      "  warnings.warn('Mayavi library was not found. Some graphics utilities will be disabled.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import hmean\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from general_tools.notebook.tf import reset_tf_graph\n",
    "\n",
    "import tf_lab.point_clouds.in_out as pio\n",
    "from tf_lab.point_clouds.in_out import PointCloudDataSet, write_model_ids_of_datasets\n",
    "from tf_lab.point_clouds.point_net_ae import PointNetAutoEncoder\n",
    "from tf_lab.point_clouds.autoencoder import Configuration as Conf\n",
    "import tf_lab.point_clouds.encoders_decoders as enc_dec\n",
    "\n",
    "\n",
    "from tf_lab.autopredictors.scripts.helper import shape_net_category_to_synth_id, points_extension, \\\n",
    "                                                 shape_net_core_synth_id_to_category\n",
    "\n",
    "\n",
    "from tf_lab.autopredictors.plotting import plot_original_pclouds_vs_reconstructed, \\\n",
    "                                           plot_train_val_test_curves, plot_reconstructions_at_epoch\n",
    "        \n",
    "from tf_lab.autopredictors.evaluate import eval_model, read_saved_epochs, accuracy_of_completion, \\\n",
    "                                           coverage_of_completion, save_reconstructions, \\\n",
    "                                           save_pc_prediction_stats, save_stats_of_multi_class_experiments, \\\n",
    "                                           paper_pc_completion_experiment_id_best_epoch\n",
    "                                                  \n",
    "from tf_lab.autopredictors.exploration import latent_embedding_of_entire_dataset, \\\n",
    "                                              embedding_of_entire_dataset_at_tensor\n",
    "\n",
    "from general_tools.in_out.basics import create_dir, delete_files_in_directory, files_in_subdirs\n",
    "from general_tools.simpletons import select_first_last_and_k\n",
    "from geo_tool import Point_Cloud\n",
    "\n",
    "from tf_lab.nips.data_sets.model_net import pc_loader, classes_to_integers\n",
    "from tf_lab.nips.helper import center_pclouds_in_unit_sphere, average_per_class, zero_mean_half_sphere\n",
    "\n",
    "from tf_lab.point_clouds.encoders_decoders import decoder_with_fc_only\n",
    "from tf_lab.point_clouds.encoders_decoders import encoder_with_convs_and_symmetry\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_pc_samples = 2048\n",
    "put_in_usphere = True\n",
    "\n",
    "model_net = '40'\n",
    "\n",
    "# experiment_name = 'wu_classes_rotated_mlp_arch_2048pts_chamfer'\n",
    "experiment_name ='all_snc_rotated_conv_arch_2048pts_chamfer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              allow_gpu_growth: False\n",
      "                    batch_size: 50\n",
      "                 consistent_io: None\n",
      "                         debug: False\n",
      "                       decoder: decoder_with_fc_only\n",
      "                  decoder_args: {'layer_sizes': [1024, 2048, 6144]}\n",
      "                       encoder: encoder_with_convs_and_symmetry\n",
      "                  encoder_args: {'filter_sizes': [40, 20, 10, 10], 'n_filters': [128, 128, 256, 512], 'strides': [1, 2, 2, 1]}\n",
      "               experiment_name: all_snc_rotated_conv_arch_2048pts_chamfer\n",
      "                 gauss_augment: None\n",
      "                  is_denoising: False\n",
      "               latent_vs_recon: 1.0\n",
      "                 learning_rate: 0.0005\n",
      "                          loss: chamfer\n",
      "             loss_display_step: 1\n",
      "                       n_input: [2048, 3]\n",
      "                      n_output: [2048, 3]\n",
      "                           n_z: None\n",
      "             saver_max_to_keep: None\n",
      "                    saver_step: 10\n",
      "                     train_dir: /orions4-zfs/projects/lins2/Panos_Space/DATA/OUT/models/nips/vanilla_ae/all_snc_rotated_conv_arch_2048pts_chamfer\n",
      "               training_epochs: 2000\n",
      "                      z_rotate: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_data_dir = '/orions4-zfs/projects/lins2/Panos_Space/DATA/'\n",
    "train_dir = osp.join(top_data_dir, 'OUT/models/nips/vanilla_ae/')\n",
    "train_dir = osp.join(train_dir, experiment_name)\n",
    "\n",
    "conf = Conf.load(osp.join(train_dir, 'configuration'))\n",
    "print conf\n",
    "conf.n_output = conf.n_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored in epoch 340.\n"
     ]
    }
   ],
   "source": [
    "reset_tf_graph()\n",
    "ae = PointNetAutoEncoder(experiment_name, conf)\n",
    "saved_epochs = read_saved_epochs(conf.train_dir)\n",
    "last_epoch = saved_epochs[-1]\n",
    "ae.restore_model(conf.train_dir, last_epoch, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_net_dir = '/orions4-zfs/projects/lins2/Panos_Space/DATA/Point_Clouds/Model_Net_' + model_net +  '/from_manifold/' \n",
    "model_net_dir = osp.join(model_net_dir, str(n_pc_samples))\n",
    "\n",
    "search_pattern = '(.*)train(.*)\\.ply$'\n",
    "train_pc_files = [f for f in files_in_subdirs(model_net_dir, search_pattern)]\n",
    "\n",
    "search_pattern = '(.*)test(.*)\\.ply$'\n",
    "test_pc_files = [f for f in files_in_subdirs(model_net_dir, search_pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9841 pclouds were loaded. They belong in 40 shape-classes.\n",
      "2467 pclouds were loaded. They belong in 40 shape-classes.\n"
     ]
    }
   ],
   "source": [
    "pc, model_names, labels = pio.load_crude_point_clouds(train_pc_files, loader=pc_loader, n_threads=10, verbose=True)\n",
    "\n",
    "if put_in_usphere:\n",
    "#     pc = center_pclouds_in_unit_sphere(pc)\n",
    "    pc = zero_mean_half_sphere(pc)\n",
    "    \n",
    "train_data = PointCloudDataSet(pc, labels=labels)\n",
    "\n",
    "pc, model_names, labels = pio.load_crude_point_clouds(test_pc_files, loader=pc_loader, n_threads=10, verbose=True)\n",
    "\n",
    "if put_in_usphere:\n",
    "#     pc = center_pclouds_in_unit_sphere(pc)\n",
    "    pc = zero_mean_half_sphere(pc)\n",
    "    \n",
    "test_data = PointCloudDataSet(pc, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_feed, train_latent, train_classes = latent_embedding_of_entire_dataset(train_data, ae, conf)\n",
    "cids = classes_to_integers(int(model_net), train_classes)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.7, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=2.0, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=0.7, loss='squared_hinge', intercept_scaling=2.0, dual=False)\n",
    "lsvc.fit(train_latent, cids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86218078638\n",
      "0.810570073439\n"
     ]
    }
   ],
   "source": [
    "test_feed, test_latent, test_classes = latent_embedding_of_entire_dataset(test_data, ae, conf)\n",
    "cids_ = classes_to_integers(int(model_net), test_classes)[1]\n",
    "print lsvc.score(test_latent, cids_)\n",
    "print average_per_class(lsvc, test_latent, cids_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9841, 1536)\n"
     ]
    }
   ],
   "source": [
    "[n.name for n in ae.graph.get_operations()]\n",
    "\n",
    "code_tr_0 = embedding_of_entire_dataset_at_tensor(train_data, ae, conf, 'all_snc_2048pts_chamfer_1/decoder_fc_0/BiasAdd:0')[1]\n",
    "code_te_0 = embedding_of_entire_dataset_at_tensor(test_data, ae, conf, 'all_snc_2048pts_chamfer_1/decoder_fc_0/BiasAdd:0')[1]\n",
    "\n",
    "\n",
    "multi_feat_tr = np.hstack((code_tr_0, train_latent))\n",
    "print multi_feat_tr.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
