{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 3\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook.gpu_utils import setup_one_gpu\n",
    "GPU = 3\n",
    "setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orions4-zfs/projects/lins2/Panos_Space/Git_Repos/geo_tool/solids/mesh.py:26: UserWarning: Mayavi library was not found. Some graphics utilities will be disabled.\n",
      "  warnings.warn('Mayavi library was not found. Some graphics utilities will be disabled.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tf_lab.point_clouds.in_out as pio\n",
    "from tf_lab.point_clouds.in_out import PointCloudDataSet, write_model_ids_of_datasets\n",
    "from tf_lab.point_clouds.point_net_ae import PointNetAutoEncoder\n",
    "from tf_lab.point_clouds.autoencoder import Configuration as Conf\n",
    "\n",
    "from tf_lab.autopredictors.scripts.helper import shape_net_category_to_synth_id\n",
    "\n",
    "from general_tools.notebook.tf import reset_tf_graph                                                  \n",
    "from general_tools.in_out.basics import create_dir, delete_files_in_directory, files_in_subdirs\n",
    "from general_tools.simpletons import select_first_last_and_k, indices_in_iterable\n",
    "\n",
    "from geo_tool import Point_Cloud\n",
    "\n",
    "from tf_lab.nips.shape_net import pc_loader as sn_pc_loader\n",
    "\n",
    "from tf_lab.autopredictors.exploration import latent_embedding_of_entire_dataset\n",
    "\n",
    "from tf_lab.autopredictors.evaluate import eval_model, read_saved_epochs\n",
    "\n",
    "from tf_lab.nips.evaluate_gan import entropy_of_occupancy_grid, point_cloud_distances,\\\n",
    "                                     jensen_shannon_divergence, sample_pclouds_distances\n",
    "\n",
    "from general_tools.strings import trim_content_after_last_dot\n",
    "\n",
    "from general_tools.plotting import stack_images_in_square_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_pc_samples = 2048\n",
    "seed = 42\n",
    "voxel_resolution = 32\n",
    "np.random.seed(seed)\n",
    "save_figs = False\n",
    "cmp_with_noise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load Ground-Truth Data\n",
    "in_f = '/orions4-zfs/projects/lins2/Panos_Space/DATA/NIPS/our_samples/gt_all_chair.npz'\n",
    "gt_data = np.load(in_f)\n",
    "gt_data = gt_data[gt_data.keys()[0]]\n",
    "_, gt_grid_var = entropy_of_occupancy_grid(gt_data, voxel_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TESTING RANDOM NOISE\n",
    "# Chairs 32 voxel-resolution: Gauss = 0.36, Uni=0.38\n",
    "if cmp_with_noise:\n",
    "    import scipy.stats as stats\n",
    "    lower, upper = -0.5, 0.5\n",
    "    mu, sigma = 0, 1\n",
    "    # X = stats.truncnorm((lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "    # size = (len(gt_data), n_pc_samples, 3)\n",
    "    # random_pcs = X.rvs(np.prod(size))\n",
    "    # random_pcs = random_pcs.reshape(size)\n",
    "    random_pcs = np.random.uniform(low=-0.5, high=0.5, size=(len(gt_data), n_pc_samples, 3))\n",
    "    ## for i, pc in enumerate(random_pcs):\n",
    "    ##     random_pcs[i] = Point_Cloud(pc).center_axis()[0].points\n",
    "    \n",
    "    _, bline_grid_var = entropy_of_occupancy_grid(random_pcs, voxel_resolution)\n",
    "    print jensen_shannon_divergence(bline_grid_var, gt_grid_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 2048, 3)\n",
      "-0.418762 0.40793\n",
      "removed 0\n"
     ]
    }
   ],
   "source": [
    "# LOAD (Synthetic) Point-Cloud Data\n",
    "# exp_name = 'ae_trained_200eps_512gen_ae_emd_1c_gan_chair_2048_pts_epoch_9'\n",
    "exp_name = 'v0_raw_gan_chair_2048_pts_epoch_30'\n",
    "\n",
    "in_f = '/orions4-zfs/projects/lins2/Panos_Space/DATA/NIPS/our_samples/'\n",
    "in_f = osp.join(in_f, exp_name + '.npz')\n",
    "# in_f = '/orions4-zfs/projects/lins2/Panos_Space/DATA/NIPS/mit_3dgan_1K_synthetic_samples/point_clouds/2048/chair.npz'\n",
    "top_fig_dir = '/orions4-zfs/projects/lins2/Panos_Space/DATA/NIPS/Images/'\n",
    "\n",
    "syn_data = np.load(in_f)\n",
    "syn_data = syn_data[syn_data.keys()[0]]\n",
    "\n",
    "look_only = len(syn_data)\n",
    "# look_only = 1000 # speed up\n",
    "syn_data = syn_data[:look_only]\n",
    "\n",
    "print syn_data.shape\n",
    "print np.min(syn_data), np.max(syn_data)\n",
    "\n",
    "## One way to push syn_data in u-cube\n",
    "cleaner =[]\n",
    "rem = 0\n",
    "for i in syn_data:\n",
    "    if max(abs(np.max(i)), abs(np.min(i))) <= 0.5:\n",
    "#         cleaner.append(Point_Cloud(i).center_axis()[0].points)\n",
    "        cleaner.append(i)\n",
    "    else:\n",
    "        rem += 1\n",
    "print 'removed', rem\n",
    "syn_data = np.array(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pclouds = syn_data.copy()\n",
    "\n",
    "pclouds = pclouds - np.expand_dims(np.mean(pclouds, axis=1), 1)\n",
    "dist = np.max(np.sqrt(np.sum(pclouds ** 2, axis=2)), 1)\n",
    "dist = np.expand_dims(np.expand_dims(dist, 1), 2)\n",
    "pclouds = pclouds / dist\n",
    "\n",
    "mentropy, sd_grid_var = entropy_of_occupancy_grid(pclouds, voxel_resolution)\n",
    "print mentropy\n",
    "print jensen_shannon_divergence(gt_grid_var, sd_grid_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4327.09487915 4346.75127869\n"
     ]
    }
   ],
   "source": [
    "pclouds = syn_data.copy()\n",
    "\n",
    "pclouds = pclouds - np.expand_dims(np.mean(pclouds, axis=1), 1)\n",
    "dist = np.max(np.sqrt(np.sum(pclouds ** 2, axis=2)), 1)\n",
    "dist = np.expand_dims(np.expand_dims(dist, 1), 2)\n",
    "pclouds = pclouds / dist\n",
    "\n",
    "all_dists = sample_pclouds_distances(pclouds, 30, 100, 'emd')\n",
    "print np.median(all_dists), np.mean(all_dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Pairwise Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0480847\n"
     ]
    }
   ],
   "source": [
    "# check_data = pclouds\n",
    "# distance_type = 'chamfer'\n",
    "# all_dists = point_cloud_distances(check_data, 10, distance_type)\n",
    "print np.median(all_dists)\n",
    "\n",
    "# plt.hist(all_dists)[2]\n",
    "# plt.xlabel(distance_type + ' pairwise distances')\n",
    "# plt.ylabel('Histogram')\n",
    "# if save_figs:\n",
    "#     plt.savefig(trim_content_after_last_dot(in_f) + '_dist_hist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Plotting data in grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "create_dir('images_' + exp_name)\n",
    "size = 100\n",
    "rids = np.random.choice(range(len(syn_data)), size=size, replace=False)\n",
    "plt.ioff()\n",
    "\n",
    "for i in range(size):\n",
    "    fig = Point_Cloud(syn_data[rids[i]]).plot(show=False, show_axis=False, azim=290, in_u_sphere=True, s=20);\n",
    "    fig.savefig(osp.join('images_' + exp_name, 'sample_' +str(i)))\n",
    "    plt.close()    \n",
    "\n",
    "file_names = glob.glob('images_' + exp_name +'/*.png')\n",
    "stack_images_in_square_grid(file_names, save_file= exp_name + '_BIG.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
