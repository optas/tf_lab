{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 0\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook.gpu_utils import setup_one_gpu\n",
    "GPU = 0\n",
    "setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from language_3d_io import GeoWordsDataSet\n",
    "from general_tools.notebook.tf import reset_tf_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from general_tools.in_out.basics import unpickle_data\n",
    "from tflearn.layers.core import fully_connected\n",
    "from tf_lab.point_clouds.encoders_decoders import decoder_with_fc_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tf_lab.rnn import deep_lstm, length_of_sequence, last_relevant_rnn_output, get_state_variables,\\\n",
    "                       get_state_update_op, get_state_reset_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 384\n",
    "n_layers = 1\n",
    "frame_size = 100\n",
    "n_classes = 3\n",
    "batch_size = 40\n",
    "max_steps = 30\n",
    "geo_feat_size = 128 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "training_data = unpickle_data('train_100_close.pkl').next()\n",
    "test_data = unpickle_data('test_40_close.pkl').next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reset_tf_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.float32, [None, max_steps, frame_size])\n",
    "\n",
    "input_geometry = tf.placeholder(tf.float32, [None, geo_feat_size])\n",
    "\n",
    "target = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "dropout_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "deep_lstm_model = deep_lstm(n_layers, n_hidden, dropout_prob)\n",
    "\n",
    "len_seq = length_of_sequence(input_sequence)\n",
    "\n",
    "states = get_state_variables(batch_size, deep_lstm_model)\n",
    "\n",
    "# Unroll the LSTM\n",
    "\n",
    "# # tf.nn.dynamic_rnn returns the output activations and last hidden state.\n",
    "# # The output will be of size batch_size x max_step x n_hidden, \n",
    "# # but with the last being zero vectors for sequences shorter than the maximum length.\n",
    "# # The final_state contains the last state (batch_size x n_hidden) of each layer of the stacked-deep-rnn.\n",
    "rnn_outputs, last_states = tf.nn.dynamic_rnn(deep_lstm_model, input_sequence, dtype=tf.float32, sequence_length=len_seq,\\\n",
    "                                            initial_state=states)\n",
    "\n",
    "reset_states_with_zero = get_state_reset_op(states, deep_lstm_model, batch_size)\n",
    "reset_h_with_geo = states[0][1].assign(input_geometry)\n",
    "\n",
    "rnn_out = last_relevant_rnn_output(rnn_outputs, len_seq)\n",
    "input_to_decoder = rnn_out \n",
    "# input_to_decoder = tf.concat(1, [rnn_out, input_geometry])\n",
    "# input_to_decoder = tf.concat(1, [joint_last_state, input_geometry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logits = decoder_with_fc_only(input_to_decoder, layer_sizes=[100, n_classes])\n",
    "\n",
    "prediction = tf.argmax(logits, axis=1)\n",
    "\n",
    "target_ = tf.argmax(target, axis=1)\n",
    "\n",
    "correct_pred = tf.equal(prediction, target_)\n",
    "\n",
    "avg_accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cost(output, target):\n",
    "    # Compute cross entropy for each frame.\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(output, target)\n",
    "    return tf.reduce_mean(cross_entropy)\n",
    "\n",
    "def optimizer_step(loss, learning_rate=0.003):\n",
    "    opt = tf.train.AdamOptimizer(learning_rate)\n",
    "    grad_params = opt.compute_gradients(loss)\n",
    "    capped_gp = [(tf.clip_by_value(grad, -5., 5.), param) for grad, param in grad_params]\n",
    "    return opt.apply_gradients(capped_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "problem_loss = cost(logits, target)\n",
    "problem_opt_step = optimizer_step(problem_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gpu_config = tf.ConfigProto()\n",
    "gpu_config.gpu_options.allow_growth = True\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (1.1874086161454518, 0.33333334202567738)\n",
      "2 (1.1097140808900197, 0.3395833472410838)\n",
      "3 (1.1027159988880157, 0.38958333432674408)\n",
      "4 (1.069871614376704, 0.43125000596046448)\n",
      "5 (1.0402942001819611, 0.45625000695387524)\n",
      "6 (0.98660088578859961, 0.48958333084980649)\n",
      "7 (0.95301790535449982, 0.51458333929379785)\n",
      "8 (0.89520235359668732, 0.55833335469166434)\n",
      "9 (0.78936024010181427, 0.62083334724108374)\n",
      "10 (0.73291848599910736, 0.6583333512147268)\n",
      "11 (0.71659406522909797, 0.69375000894069672)\n",
      "12 (0.53863394260406494, 0.7520833512147268)\n",
      "13 (0.46037585039933521, 0.81250002483526862)\n",
      "14 (0.42878260587652522, 0.83333336313565576)\n",
      "15 (0.37416063994169235, 0.85416668156782782)\n",
      "16 (0.38217221821347874, 0.83333335320154822)\n",
      "17 (0.35676431655883789, 0.84375003476937616)\n",
      "18 (0.31641138717532158, 0.86458335816860199)\n",
      "19 (0.27267804990212124, 0.90000002086162567)\n",
      "20 (0.19544699477652708, 0.91875000298023224)\n",
      "21 (0.12822379606465498, 0.95208333432674408)\n",
      "22 (0.11543917004019022, 0.9583333283662796)\n",
      "23 (0.1464964885575076, 0.94583334028720856)\n",
      "24 (0.11262156162410975, 0.95833331346511841)\n",
      "25 (0.076508215318123504, 0.96874999006589257)\n",
      "26 (0.046312717061179377, 0.98333332935969031)\n",
      "27 (0.0342206092706571, 0.98541665573914849)\n",
      "28 (0.057010717845211424, 0.97708331048488617)\n",
      "29 (0.075125282940765217, 0.97499999900658929)\n",
      "30 (0.11233266334359844, 0.96249999602635705)\n"
     ]
    }
   ],
   "source": [
    "dropout_pr = 0.5\n",
    "display_step = 1\n",
    "stats = []\n",
    "\n",
    "batches_for_epoch = training_data.num_examples / batch_size\n",
    "\n",
    "sess = tf.Session(config=gpu_config)\n",
    "sess.run(init)\n",
    "sess.run(reset_states_with_zero)\n",
    "\n",
    "for epoch in range(30):\n",
    "    epoch_loss = 0\n",
    "    epoch_perf = 0    \n",
    "\n",
    "    for _ in range(batches_for_epoch):    \n",
    "        words_i, geo_i, labels_i = training_data.next_batch(batch_size)\n",
    "        \n",
    "        feed_dict = {input_sequence: words_i,\n",
    "                     target: labels_i,\n",
    "                     input_geometry: geo_i,\n",
    "                     dropout_prob: dropout_pr}\n",
    "        \n",
    "        sess.run([reset_h_with_geo], feed_dict=feed_dict)\n",
    "        _, step_loss, step_perf = sess.run([problem_opt_step, problem_loss, avg_accuracy], feed_dict=feed_dict)\n",
    "        \n",
    "        epoch_loss += step_loss\n",
    "        epoch_perf += step_perf\n",
    "    \n",
    "    epoch_loss /= batches_for_epoch\n",
    "    epoch_perf /= batches_for_epoch\n",
    "    if epoch % display_step == 0 :\n",
    "        stats.append((epoch_loss, epoch_perf))\n",
    "        print epoch + 1, stats[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.5297815799713135, 0.47499999403953552)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_model_with_test_data(test_data, batch_size):\n",
    "\n",
    "    batches_for_epoch = test_data.num_examples / batch_size\n",
    "    sess.run(reset_states_with_zero)\n",
    "\n",
    "    loss = 0\n",
    "    perf = 0\n",
    "    \n",
    "    for _ in range(batches_for_epoch):\n",
    "        words_i, geo_i, labels_i = test_data.next_batch(batch_size)\n",
    "        \n",
    "        feed_dict = {input_sequence: words_i,\n",
    "                     target: labels_i,\n",
    "                     input_geometry: geo_i,\n",
    "                     dropout_prob: 0.0}\n",
    "        \n",
    "        sess.run([reset_h_with_geo], feed_dict=feed_dict)\n",
    "        step_loss, step_perf = sess.run([problem_loss, avg_accuracy], feed_dict=feed_dict)        \n",
    "        loss += step_loss\n",
    "        perf += step_perf\n",
    "    return loss, perf\n",
    "\n",
    "try_model_with_test_data(test_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.049107  ,  1.08360004, -0.96898001, ..., -0.35431999,\n",
       "         0.46728   ,  0.34469   ],\n",
       "       [-0.59596997, -0.022     ,  0.55533999, ...,  0.042286  ,\n",
       "        -0.3973    ,  0.42844   ],\n",
       "       [ 0.21253   , -0.094895  ,  0.53437001, ...,  0.29701   ,\n",
       "        -0.12437   ,  0.20121001],\n",
       "       ..., \n",
       "       [ 1.0632    , -0.028459  , -0.46533999, ...,  0.039003  ,\n",
       "        -1.03390002, -0.52419001],\n",
       "       [ 0.31733   , -0.20597   ,  0.13283999, ...,  0.65559   ,\n",
       "        -0.70892   ,  0.13138001],\n",
       "       [-1.00580001, -0.53103   , -0.15195   , ...,  0.20653   ,\n",
       "         0.26804   , -0.95627999]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained word-embedding.\n",
    "vocab_size = int(4e5)\n",
    "embedding_dim = 100\n",
    "\n",
    "word_embedding = tf.Variable(tf.constant(0.0, shape=[vocab_size, embedding_dim]), trainable=False, name=\"word_embedding\")\n",
    "embedding_placeholder = tf.placeholder(tf.float32, [vocab_size, embedding_dim])\n",
    "embedding_init = word_embedding.assign(embedding_placeholder)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(embedding_init, feed_dict={embedding_placeholder: lala})\n",
    "\n",
    "def embedding_dictionary_to_matrix(in_dict):\n",
    "    return np.array(in_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def last_hidden_states(output):\n",
    "    hidden_states = []\n",
    "    for i in range(len(output)):\n",
    "        hidden_states.append(final_state[i].h)\n",
    "\n",
    "    if len(hidden_states) > 1:\n",
    "        joint_last_state = tf.concat_v2(hidden_states, axis=1)\n",
    "    else:\n",
    "        joint_last_state = hidden_states[0]\n",
    "    return hidden_states\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
