{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from toy_seq_data import ToySequenceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def deep_lstm(n_layers, n_hidden, dropout_prob=None):\n",
    "    cells = []\n",
    "    for _ in range(n_layers):\n",
    "        cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden,  state_is_tuple=True)\n",
    "#         if dropout_prob is not None:\n",
    "#             cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=1.0 - dropout_prob)\n",
    "        cells.append(cell)\n",
    "\n",
    "    model = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'Mnist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e5e2574765fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'Mnist'"
     ]
    }
   ],
   "source": [
    "import sets\n",
    "\n",
    "sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def length_of_sequence(sequence):\n",
    "    '''Input: (Tensor) batch size x max length x features\n",
    "     Returns: the length of each sequence in the batch.\n",
    "     Precondition: Each sequence with smaller length that max length, is padded with zeros.'''\n",
    "    \n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "    length = tf.reduce_sum(used, 1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def last_relevant_rnn_output(output, length):\n",
    "    '''Returns for a batch of output tensors of a dynamic_rnn those corresponding to the last non-padded input/output.\n",
    "    Notes:\n",
    "    In numpy this would just be output[:, length - 1], but we need the indexing to be part of the compute graph.\n",
    "    Works likes this: we flatten the output tensor to shape: frames in all examples x output size. \n",
    "    Then we construct an index into that by creating a tensor with the start indices for each example \n",
    "    tf.range(0, batch_size) * max_length and add the individual sequence lengths to it. \n",
    "    tf.gather() then performs the actual indexing. \n",
    "    '''\n",
    "    batch_size = tf.shape(output)[0]\n",
    "    max_length = tf.shape(output)[1]\n",
    "    out_size = int(output.get_shape()[2])\n",
    "    index = tf.range(0, batch_size) * max_length + (length - 1)\n",
    "    flat = tf.reshape(output, [-1, out_size])\n",
    "    relevant = tf.gather(flat, index)\n",
    "    return relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 64\n",
    "n_layers = 1\n",
    "max_steps = 20\n",
    "step_feat_size = 1\n",
    "\n",
    "n_classes = 2\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.nn_ops.softmax>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.float32, [None, max_steps, step_feat_size])\n",
    "target = tf.placeholder(tf.float32, [None, n_classes])\n",
    "dropout_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "deep_lstm_model = deep_lstm(n_layers, n_hidden, dropout_prob)\n",
    "\n",
    "len_seq = length_of_sequence(input_sequence)\n",
    "\n",
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(deep_lstm_model, input_sequence, dtype=tf.float32,\n",
    "                                             sequence_length=len_seq,\n",
    "                                            )\n",
    "\n",
    "# tf.nn.dynamic_rnn returns the output activations and last hidden state.\n",
    "# The output will be of size batch_size x max_step x n_hidden, \n",
    "# but with the last being zero vectors for sequences shorter than the maximum length.\n",
    "\n",
    "# The final_state contains the last state (batch_size x n_hidden) of each layer of the stacked-deep-rnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tflearn.layers.core import fully_connected\n",
    "from tf_lab.point_clouds.encoders_decoders import decoder_with_fc_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hidden_states = []\n",
    "for i in range(n_layers):\n",
    "    hidden_states.append(final_state[i].h)\n",
    "\n",
    "if len(hidden_states) > 1:\n",
    "    joint_last_state = tf.concat_v2(hidden_states, axis=1)\n",
    "else:\n",
    "    joint_last_state = hidden_states[0]\n",
    "\n",
    "logits = decoder_with_fc_only(joint_last_state, layer_sizes=[100, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn_out = last_relevant_rnn_output(rnn_outputs, len_seq)\n",
    "logits = fully_connected(rnn_out, n_classes)\n",
    "# logits = decoder_with_fc_only(rnn_out, layer_sizes=[100, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cost(output, target):\n",
    "    # Compute cross entropy for each frame.\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(output, target)\n",
    "    return tf.reduce_mean(cross_entropy)\n",
    "\n",
    "def optimizer(loss, learning_rate=0.01):\n",
    "    #     return tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orions4-zfs/projects/lins2/.local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "problem_loss = cost(logits, target)\n",
    "problem_opt = optimizer(problem_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_config = tf.ConfigProto()\n",
    "gpu_config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(logits, axis=1)\n",
    "target_ = tf.argmax(target, axis=1)\n",
    "correct_pred = tf.equal(prediction, target_)\n",
    "avg_accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset = ToySequenceData(n_samples=1000, max_seq_len=max_steps)\n",
    "testset = ToySequenceData(n_samples=500, max_seq_len=max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69247603, 0.60000002]\n",
      "[0.69221574, 0.60000002]\n",
      "[0.69291306, 0.56666672]\n",
      "[0.69210947, 0.5]\n",
      "[0.69337285, 0.50000006]\n",
      "[0.69379842, 0.43333334]\n",
      "[0.69386315, 0.40000004]\n",
      "[0.69238019, 0.53333336]\n",
      "[0.69246966, 0.53333336]\n",
      "[0.69267613, 0.4666667]\n",
      "[0.69253957, 0.56666672]\n",
      "[0.69441462, 0.40000004]\n",
      "[0.69281912, 0.56666672]\n",
      "[0.69438434, 0.40000004]\n",
      "[0.6932888, 0.4333334]\n",
      "[0.69542336, 0.33333334]\n",
      "[0.69294322, 0.5]\n",
      "[0.69315046, 0.5]\n",
      "[0.69350481, 0.53333336]\n",
      "[0.6914407, 0.53333336]\n",
      "[0.69225413, 0.53333336]\n",
      "[0.69650996, 0.36666667]\n",
      "[0.69497085, 0.40000004]\n",
      "[0.69397378, 0.43333337]\n",
      "[0.69505823, 0.30000001]\n",
      "[0.69320393, 0.53333336]\n",
      "[0.69266295, 0.56666672]\n",
      "[0.69138348, 0.66666675]\n",
      "[0.69269013, 0.4666667]\n",
      "[0.69409978, 0.43333337]\n",
      "[0.69506001, 0.43333334]\n",
      "[0.69462091, 0.43333334]\n",
      "[0.69453275, 0.40000004]\n",
      "[0.69086921, 0.70000005]\n",
      "[0.69322658, 0.43333337]\n",
      "[0.69256854, 0.5]\n",
      "[0.69114733, 0.56666672]\n",
      "[0.69463456, 0.43333334]\n",
      "[0.68961269, 0.70000005]\n",
      "[0.69183868, 0.56666672]\n",
      "[0.69362593, 0.50000006]\n",
      "[0.69581175, 0.30000001]\n",
      "[0.69463027, 0.50000006]\n",
      "[0.69332647, 0.4666667]\n",
      "[0.69348186, 0.4666667]\n",
      "[0.69173485, 0.53333342]\n",
      "[0.69244236, 0.53333342]\n",
      "[0.69441503, 0.4333334]\n",
      "[0.69144833, 0.53333336]\n",
      "[0.69266194, 0.4666667]\n",
      "[0.69121301, 0.63333338]\n",
      "[0.69134057, 0.63333338]\n",
      "[0.69299418, 0.53333336]\n",
      "[0.69377363, 0.43333334]\n",
      "[0.69263905, 0.5]\n",
      "[0.69346249, 0.40000004]\n",
      "[0.69261402, 0.53333342]\n",
      "[0.69318885, 0.4666667]\n",
      "[0.69498348, 0.30000001]\n",
      "[0.6954602, 0.36666667]\n",
      "[0.69053614, 0.70000005]\n",
      "[0.69287229, 0.46666673]\n",
      "[0.6935972, 0.5]\n",
      "[0.69406784, 0.53333342]\n",
      "[0.69478846, 0.33333337]\n",
      "[0.69343996, 0.40000004]\n",
      "[0.69233406, 0.56666672]\n",
      "[0.69138777, 0.60000008]\n",
      "[0.69067752, 0.63333338]\n",
      "[0.69206893, 0.56666672]\n",
      "[0.69390559, 0.50000006]\n",
      "[0.69291228, 0.53333342]\n",
      "[0.69322771, 0.5]\n",
      "[0.6949203, 0.36666667]\n",
      "[0.69384766, 0.4666667]\n",
      "[0.69266319, 0.4666667]\n",
      "[0.6934768, 0.5]\n",
      "[0.69425911, 0.4666667]\n",
      "[0.6929819, 0.4666667]\n",
      "[0.69378912, 0.43333337]\n",
      "[0.6924991, 0.60000002]\n",
      "[0.69555748, 0.40000004]\n",
      "[0.69503272, 0.40000004]\n",
      "[0.69395268, 0.40000004]\n",
      "[0.69301486, 0.53333336]\n",
      "[0.69366729, 0.4666667]\n",
      "[0.69520515, 0.36666667]\n",
      "[0.69378912, 0.43333337]\n",
      "[0.69415623, 0.4333334]\n",
      "[0.69542646, 0.30000001]\n",
      "[0.69303197, 0.50000006]\n",
      "[0.69516486, 0.40000004]\n",
      "[0.69270343, 0.50000006]\n",
      "[0.69154942, 0.56666672]\n",
      "[0.69560802, 0.36666673]\n",
      "[0.69443488, 0.43333334]\n",
      "[0.69151425, 0.60000002]\n",
      "[0.69295061, 0.5]\n",
      "[0.69315267, 0.40000004]\n",
      "[0.69078195, 0.60000002]\n",
      "[0.69276941, 0.53333336]\n",
      "[0.69410455, 0.40000004]\n",
      "[0.69176108, 0.60000002]\n",
      "[0.6923703, 0.56666672]\n",
      "[0.69351494, 0.40000004]\n",
      "[0.69388133, 0.43333337]\n",
      "[0.69111013, 0.66666669]\n",
      "[0.69362783, 0.50000006]\n",
      "[0.69434148, 0.4666667]\n",
      "[0.69200099, 0.56666672]\n",
      "[0.69188178, 0.53333336]\n",
      "[0.69427127, 0.33333337]\n",
      "[0.69329953, 0.5]\n",
      "[0.69785255, 0.16666669]\n",
      "[0.69311869, 0.40000004]\n",
      "[0.694278, 0.4666667]\n",
      "[0.69401765, 0.43333337]\n",
      "[0.69312978, 0.43333337]\n",
      "[0.69355822, 0.50000006]\n",
      "[0.6933254, 0.4333334]\n",
      "[0.69258797, 0.60000002]\n",
      "[0.69333595, 0.36666673]\n",
      "[0.69092011, 0.63333338]\n",
      "[0.69310546, 0.43333337]\n",
      "[0.6927706, 0.53333336]\n",
      "[0.69168162, 0.53333342]\n",
      "[0.69439685, 0.43333334]\n",
      "[0.69468188, 0.3666667]\n",
      "[0.69227171, 0.56666672]\n",
      "[0.69411999, 0.5]\n",
      "[0.69429129, 0.4666667]\n",
      "[0.69579041, 0.33333337]\n",
      "[0.6933589, 0.5]\n",
      "[0.69318867, 0.53333336]\n",
      "[0.69103324, 0.66666675]\n",
      "[0.69422317, 0.4666667]\n",
      "[0.69153416, 0.66666675]\n",
      "[0.6939261, 0.56666672]\n",
      "[0.69165784, 0.60000002]\n",
      "[0.69453776, 0.43333337]\n",
      "[0.69328457, 0.5]\n",
      "[0.69554484, 0.30000001]\n",
      "[0.69205308, 0.53333336]\n",
      "[0.69387627, 0.4333334]\n",
      "[0.69584036, 0.33333337]\n",
      "[0.6924715, 0.53333342]\n",
      "[0.69259274, 0.5]\n",
      "[0.69288331, 0.53333342]\n",
      "[0.69246805, 0.5]\n",
      "[0.69472349, 0.4666667]\n",
      "[0.69322503, 0.5]\n",
      "[0.69383967, 0.30000001]\n",
      "[0.6929121, 0.43333337]\n",
      "[0.69280171, 0.4666667]\n",
      "[0.69179064, 0.53333342]\n",
      "[0.69260073, 0.50000006]\n",
      "[0.69336051, 0.53333336]\n",
      "[0.69355357, 0.53333336]\n",
      "[0.69285834, 0.56666672]\n",
      "[0.69236863, 0.53333336]\n",
      "[0.69394648, 0.50000006]\n",
      "[0.6933369, 0.5]\n",
      "[0.68901044, 0.66666675]\n",
      "[0.69331825, 0.4666667]\n",
      "[0.69216204, 0.53333336]\n",
      "[0.69199991, 0.4666667]\n",
      "[0.69275367, 0.60000008]\n",
      "[0.69259882, 0.50000006]\n",
      "[0.69354945, 0.5]\n",
      "[0.69291079, 0.46666673]\n",
      "[0.69299358, 0.53333336]\n",
      "[0.69306242, 0.56666672]\n",
      "[0.69256258, 0.56666672]\n",
      "[0.69347209, 0.4666667]\n",
      "[0.6918962, 0.56666672]\n",
      "[0.69386327, 0.40000004]\n",
      "[0.6925894, 0.53333336]\n",
      "[0.69476998, 0.33333337]\n",
      "[0.69561332, 0.4666667]\n",
      "[0.69181323, 0.5]\n",
      "[0.69461417, 0.50000006]\n",
      "[0.69326234, 0.4333334]\n",
      "[0.69379163, 0.5]\n",
      "[0.69477695, 0.40000004]\n",
      "[0.69133747, 0.56666672]\n",
      "[0.69316173, 0.53333336]\n",
      "[0.69283676, 0.4666667]\n",
      "[0.69339216, 0.5]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-eec43db625bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproblem_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/orions4-zfs/projects/lins2/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/orions4-zfs/projects/lins2/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/orions4-zfs/projects/lins2/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/orions4-zfs/projects/lins2/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/orions4-zfs/projects/lins2/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "display_step = 100\n",
    "\n",
    "with tf.Session(config=gpu_config) as sess:\n",
    "    sess.run(init)    \n",
    "#     for epoch in xrange(10):\n",
    "    for step in xrange(50000):\n",
    "        batch_x, batch_y, _ = trainset.next(batch_size)\n",
    "\n",
    "        feed_dict = {input_sequence: batch_x, target: batch_y, dropout_prob: 0}\n",
    "        sess.run([problem_loss], feed_dict=feed_dict)\n",
    "\n",
    "        if step % display_step == 0:\n",
    "            print sess.run([problem_loss, avg_accuracy], feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained word-embedding.\n",
    "vocab_size = int(4e5)\n",
    "embedding_dim = 100\n",
    "\n",
    "word_embedding = tf.Variable(tf.constant(0.0, shape=[vocab_size, embedding_dim]), trainable=False, name=\"word_embedding\")\n",
    "embedding_placeholder = tf.placeholder(tf.float32, [vocab_size, embedding_dim])\n",
    "embedding_init = word_embedding.assign(embedding_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.049107  ,  1.08360004, -0.96898001, ..., -0.35431999,\n",
       "         0.46728   ,  0.34469   ],\n",
       "       [-0.59596997, -0.022     ,  0.55533999, ...,  0.042286  ,\n",
       "        -0.3973    ,  0.42844   ],\n",
       "       [ 0.21253   , -0.094895  ,  0.53437001, ...,  0.29701   ,\n",
       "        -0.12437   ,  0.20121001],\n",
       "       ..., \n",
       "       [ 1.0632    , -0.028459  , -0.46533999, ...,  0.039003  ,\n",
       "        -1.03390002, -0.52419001],\n",
       "       [ 0.31733   , -0.20597   ,  0.13283999, ...,  0.65559   ,\n",
       "        -0.70892   ,  0.13138001],\n",
       "       [-1.00580001, -0.53103   , -0.15195   , ...,  0.20653   ,\n",
       "         0.26804   , -0.95627999]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sess = tf.Session()\n",
    "sess.run(embedding_init, feed_dict={embedding_placeholder: lala})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove model.\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "def load_glove_pretrained_model(glove_file):\n",
    "    print \"Loading glove model.\"\n",
    "    embedding = dict()\n",
    "    with open(glove_file, 'r') as f_in:\n",
    "        for line in f_in:\n",
    "            s_line = line.split()\n",
    "            word = s_line[0]\n",
    "            w_embedding = np.array([float(val) for val in s_line[1:]], dtype=np.float32)\n",
    "            embedding[word] = w_embedding\n",
    "    print \"Done.\", len(embedding), \" words loaded!\"\n",
    "    return embedding\n",
    "\n",
    "pretrained_emb_file = '/orions4-zfs/projects/lins2/Panos_Space/DATA/Language/glove.6B/glove.6B.100d.txt'\n",
    "word_dict = load_glove_pretrained_model(pretrained_emb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def embedding_dictionary_to_matrix(in_dict):\n",
    "    return np.array(in_dict.values())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
