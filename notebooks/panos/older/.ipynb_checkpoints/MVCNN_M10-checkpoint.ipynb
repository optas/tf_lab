{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-View CNN\n",
    "\n",
    "An implementation of the Multi-View CNN which learns to classify shapes according to their category.\n",
    "\n",
    "** Multi-view Convolutional Neural Networks for 3D Shape Recognition **, Hang Su, Subhransu Maji, Evangelos Kalogerakis, Erik Learned-Miller, 2015. \n",
    "[Paper](http://vis-www.cs.umass.edu/mvcnn/docs/su15mvcnn.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "\n",
    "git_path = '/Users/optas/Documents/Git_Repos/'\n",
    "sys.path.insert(0, git_path)\n",
    "\n",
    "from deep_tensor import autograph, print_status\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 1000"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (224,224)\n",
    "BATCH_SIZE = 1\n",
    "PART_VIEWS = 80\n",
    "CHANNELS = 1\n",
    "THREADS = 5\n",
    "\n",
    "GPUS = []  # Empty list implies CPU training.\n",
    "\n",
    "DATA_PATH = '/Users/optas/DATA/Shapes/Model_Net_10/Views/Phong/'\n",
    "LOG_PATH = '/Users/optas/DATA/Neural_Nets/Train_Log/MVCNN/M10/Phong/'\n",
    "MODEL_PATH = '/Users/optas/DATA/Neural_Nets/Models/MVCNN/M10/Phong/'\n",
    "\n",
    "QUEUE_EPOCH_FRACTION = 0.1\n",
    "NUM_EPOCHS_PER_DECAY = 8          # Epochs after which learning rate decays.\n",
    "LEARNING_RATE_DECAY_FACTOR = 0.1  # Learning rate decay factor.\n",
    "INITIAL_LEARNING_RATE = 0.001     # Initial learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_inferenceA(in_image):\n",
    "    \n",
    "    layer = g.conv2d(in_image, filters=96, field_size=7, stride=2, padding='SAME', name=\"conv1\", init_bias=0.0)\\\n",
    "                        .relu()\\\n",
    "                        .maxpool(kernel=(3,3), stride=(2,2))\n",
    "            \n",
    "    layer = g.conv2d(layer, filters=256, field_size=5, stride=2, padding='SAME', name=\"conv2\", init_bias=0.0)\\\n",
    "                        .relu()\\\n",
    "                        .maxpool(kernel=(3,3), stride=(2,2))\n",
    "                    \n",
    "    layer = g.conv2d(layer, filters=512, field_size=3, stride=1, padding='SAME', name=\"conv3\", init_bias=0.0)\\\n",
    "                        .relu()\n",
    "\n",
    "    layer = g.conv2d(layer, filters=512, field_size=3, stride=1, padding='SAME', name=\"conv4\", init_bias=0.0)\\\n",
    "                        .relu()\n",
    "\n",
    "    layer = g.conv2d(layer, filters=512, field_size=3, stride=1, padding='SAME', name=\"conv5\", init_bias=0.0)\\\n",
    "                        .relu()\\\n",
    "                        .maxpool(kernel=(3,3), stride=(2,2))\n",
    "\n",
    "    return layer\n",
    "    \n",
    "def compute_inferenceB(in_signal, skip_softmax = False) :\n",
    "    layer = g.fully_connected(in_signal, 4096, name=\"fc6\", init_bias=0.0)\\\n",
    "                    .relu()\\\n",
    "                    .dropout(0.5 if g.is_training else 1.0)\n",
    "                \n",
    "    layer = g.fully_connected(layer, 4096, name=\"fc7\", init_bias=0.0)\\\n",
    "                    .relu()\\\n",
    "                    .dropout(0.5 if g.is_training else 1.0)\n",
    "            \n",
    "    if (not skip_softmax) :\n",
    "        layer = g.fully_connected(layer, num_classes, name=\"fc8\", init_bias=0.0)\n",
    "                      \n",
    "    return layer\n",
    "\n",
    "def compute_3d_inference(in_images, skip_softmax = False) :\n",
    "    \n",
    "        # Reshape to just treat as an array of images.\n",
    "    in_bundle = tf.reshape(in_images.unwrap(), [-1, IMG_SIZE[1], IMG_SIZE[0], CHANNELS])\n",
    "\n",
    "        # Compute first stage of inference (treating each image independently)\n",
    "    inf = compute_inferenceA(g.wrap(in_bundle)).unwrap()\n",
    "\n",
    "        # Get the shape of the current inference tensor (from the Conv layers)\n",
    "    inf_shape = inf.get_shape().as_list()\n",
    "    \n",
    "        # Reshape the results again to be in buckets of images per solid\n",
    "    inf = tf.reshape(inf, [-1, PART_VIEWS, inf_shape[1], inf_shape[2], inf_shape[3]])\n",
    "\n",
    "        # Compute the maximum value across the views and reduce the tensor to that.\n",
    "    reduce_inf = tf.reduce_max(inf, reduction_indices=1)\n",
    "    \n",
    "        # Compute second stage of inference on the max-reduced data (each across all images for a given solid)\n",
    "    final_inf = compute_inferenceB(g.wrap(reduce_inf), skip_softmax)\n",
    "    \n",
    "    return final_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_loader(source_path, path_regex=['(.*)','.*','\\.png$']): \n",
    "        # Create a stream that walks the data files and builds a list of filenames & labels\n",
    "    files_labels = g.filename_label_stream(source_path, path_regex=path_regex, views=PART_VIEWS )\n",
    "\n",
    "        # Apply a producer to the stream (producing another stream) for pushing data.\n",
    "    producer = g.produce(files_labels, name='producer', shuffle=True, capacity=10000)\n",
    "\n",
    "        # On the first stream dimension (filenames) apply an image stream to input images\n",
    "    shapes = g.image_stream(producer[0], name='shapes_images', channels=CHANNELS, ext='png') \\\n",
    "                .resize(IMG_SIZE[0], IMG_SIZE[1]) \\\n",
    "                .image_summary()\n",
    "\n",
    "        # Get the second stream dimension as the labels.\n",
    "    labels = producer[1].summary(\"labels\")\n",
    "\n",
    "        # Merge labels and shapes back into a single stream.\n",
    "    input_data = g.merge([labels, shapes])\n",
    "\n",
    "        # Batch the output (pull the data in batches from the streams above) to produce a multi-tensor.\n",
    "    input_data = input_data.batch(name=\"batch\", batch_size=BATCH_SIZE, queue_capacity=100, threads=THREADS, shuffle=True)\n",
    "    \n",
    "    return (input_data, files_labels.label_count(), files_labels.sample_count, files_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = autograph()\n",
    "input_data, num_classes, sample_count, label_source = input_loader(DATA_PATH, path_regex=['(.*)','train','.*','\\.png$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt = g.momentum_optimizer(\"optimizer\", momentum=0.9)\\\n",
    "        .learning_rate(INITIAL_LEARNING_RATE)\\\n",
    "        .exponential_decay(rate=LEARNING_RATE_DECAY_FACTOR, \n",
    "                       step_size=(sample_count * NUM_EPOCHS_PER_DECAY)/BATCH_SIZE, staircase=True)\n",
    "        \n",
    "loss = g.softmax_loss()\n",
    "\n",
    "trainer = g.trainer(input_data[1], input_data[0], compute_3d_inference, opt, loss, gpus=GPUS)\\\n",
    "                .variable_summary()\\\n",
    "                .gradient_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 270, epoch 0, loss = 2.49 (0.1 examples/sec); 8.296 sec/batch"
     ]
    }
   ],
   "source": [
    "total_steps = 60000\n",
    "with g.session() as s:\n",
    "    s.train(trainer, total_steps, sample_count)\\\n",
    "            .summary(10, LOG_PATH, tracing=False)\\\n",
    "            .save(100, MODEL_PATH + \"/m10_phong_in_cpu.ckpt\")\\\n",
    "            .callback(10, print_status)\\\n",
    "            .run({})              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with g.session() as s:\n",
    "    s.load(MODEL_PATH + \"/m10_phong_in_cpu.ckpt\", step=200, variables=['conv1/W','conv1/b','conv2/W','conv2/b',\n",
    "                                                           'conv3/W','conv3/b','conv4/W','conv4/b',\n",
    "                                                           'conv5/W','conv5/b','fc6/W','fc6/b',\n",
    "                                                           'fc7/W','fc7/b'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot images of first batch.\n",
    "s = g.session()\n",
    "l, imgs = s.run(input_data.unwrap(),{})\n",
    "labels = [label_source.index_to_label(i) for i in l]\n",
    "for i in range(BATCH_SIZE) :\n",
    "    plt.figure(num=None, figsize=(5, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "    plt.title(labels[i])\n",
    "    plt.imshow(imgs[i,0,:,:,0], cmap = plt.get_cmap('gray'), interpolation='nearest')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = autograph()\n",
    "input_data, num_classes, sample_count, label_source = input_loader(DATA_PATH, path_regex=['(.*)','test','.*','\\.png$'])\n",
    "\n",
    "# with tf.device('/gpu:' + str(GPUS[0])) :\n",
    "with tf.device('/cpu:0'):\n",
    "    inference = compute_3d_inference(input_data[1])\n",
    "#     .unwrap()\n",
    "#     pred = tf.cast(tf.argmax(inference, dimension=1), tf.int32)\n",
    "#     equiv = tf.equal(pred, input_data[0].unwrap())\n",
    "#     accuracy = tf.reduce_sum(tf.cast(equiv, 'float'))\n",
    "    \n",
    "s = g.session().load(MODEL_PATH + \"m10_phong_in_cpu.ckpt\", step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fc8_2/Relu:0' shape=(1, 10) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference.relu().unwrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = s.run(inference.relu().unwrap(), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.11914377,  0.14545166,  0.        ,  0.        ,\n",
       "         0.10920067,  0.        ,  0.22027047,  0.0235798 ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908\n",
      "step = 907Accuracy = 0.120044052863\n"
     ]
    }
   ],
   "source": [
    "total_accuracy = 0.0\n",
    "for step in range(sample_count/BATCH_SIZE) :\n",
    "    acc = s.run(accuracy, {})\n",
    "    total_accuracy += acc\n",
    "    sys.stdout.write(\"\\rstep = %d\" % (step))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "print \"Accuracy = \" + str(total_accuracy/sample_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = autograph()\n",
    "\n",
    "input, num_classes, sample_count = input_data(DATA_PATH, path_regex=['(.*)','test','.*','\\.png$'])\n",
    "\n",
    "thumbnails = tf.slice(input[1].unwrap(), [0,0,0,0,0], [-1,1,-1,-1,-1])\n",
    "labels = input[0].unwrap()\n",
    "\n",
    "# with tf.device('/gpu:' + str(GPUS[0])) :\n",
    "with tf.device('/cpu:0'):\n",
    "    inference = compute_3d_inference(input[1], skip_softmax=True).unwrap()\n",
    "    pred = tf.cast(inference,tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = g.session()\\\n",
    "        .load(MODEL_PATH + \"/new_dg_m40_org.ckpt\", step=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_labels=None\n",
    "y=None\n",
    "\n",
    "x_thumbnails = [None] * num_classes\n",
    "\n",
    "for step in range(sample_count/BATCH_SIZE) :\n",
    "    res=s.run([labels, pred, thumbnails], {})\n",
    "    if (x_labels is None) :\n",
    "        x_labels=res[0]\n",
    "        y=res[1]\n",
    "    else:\n",
    "        x_labels=np.concatenate((x_labels,res[0]))\n",
    "        y=np.concatenate((y,res[1]))\n",
    "        \n",
    "    for i in range(0,len(res[0])) :\n",
    "        x_l = res[0][i]\n",
    "        if (x_thumbnails[x_l] is None) :\n",
    "            x_thumbnails[x_l] = res[2][i]\n",
    "        \n",
    "    sys.stdout.write(\"\\rstep = %d\" % (step))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_list = plt.cm.hsv(np.linspace(0, 1, np.max(x_labels)+1)) * 255\n",
    "colors = ['rgb('+str(int(c[0]))+','+str(int(c[1]))+','+str(int(c[2]))+')' for c in color_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data = label_scatter(y, x_labels, dim=2, color_palette=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layout = Layout(\n",
    "    showlegend=True,\n",
    "    height=600,\n",
    "    width=600,\n",
    ")\n",
    "\n",
    "fig = dict( data=plot_data, layout=layout )\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(100, 100), dpi=80, facecolor='w', edgecolor='k')\n",
    "for i in range(0, shapes.label_count()) :\n",
    "    if not (x_thumbnails[i] is None) :\n",
    "        plt.subplot(shapes.label_count(),1,i+1)\n",
    "        img = x_thumbnails[i].reshape([IMG_SIZE[1],IMG_SIZE[0],1])\n",
    "        img = np.expand_dims(img, 2)\n",
    "        img = (img/255.0) * color_list[i]\n",
    "        plt.imshow(img, cmap = plt.get_cmap('gray'), interpolation='nearest')\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
