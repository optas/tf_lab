{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 0\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook.gpu_utils import setup_one_gpu\n",
    "GPU = 0\n",
    "setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path as osp\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from general_tools.in_out.basics import unpickle_data\n",
    "from general_tools.in_out import create_dir\n",
    "from general_tools.notebook.tf import reset_tf_graph\n",
    "\n",
    "from general_tools.clustering.plt import plot_2d_embedding_in_grid_greedy_way, \\\n",
    "                                         plot_2d_embedding_in_grid_forceful\n",
    "\n",
    "\n",
    "    \n",
    "from geo_tool import Point_Cloud\n",
    "\n",
    "import tf_lab.point_clouds.in_out as pio\n",
    "\n",
    "from tf_lab.nips.shape_net import pc_loader as sn_pc_loader\n",
    "\n",
    "from tf_lab.point_clouds.point_net_ae import PointNetAutoEncoder\n",
    "from tf_lab.point_clouds.autoencoder import Configuration as Conf\n",
    "from tf_lab.point_clouds.in_out import PointCloudDataSet\n",
    "\n",
    "from tf_lab.autopredictors.scripts.virt_scan_data import plotting_default_params, pc_sampler, pc_loader\n",
    "from tf_lab.autopredictors.scripts.helper import shape_net_category_to_synth_id\n",
    "from tf_lab.autopredictors.exploration import latent_embedding_of_entire_dataset\n",
    "from tf_lab.autopredictors.evaluate import eval_model, read_saved_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "top_data_dir = top_data_dir = '/orions4-zfs/projects/lins2/Panos_Space/DATA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored in epoch 1000.\n"
     ]
    }
   ],
   "source": [
    "# load AE model\n",
    "class_name = 'chair'\n",
    "syn_id = shape_net_category_to_synth_id()[class_name]\n",
    "ae_loss = 'emd'\n",
    "ae_id = '12' # 128 bottlÎµneck\n",
    "\n",
    "ae_net_name = 'ae_farm_' + class_name + '_conv_arch_' + ae_id + '_2048pts_' + ae_loss\n",
    "ae_net_dir = osp.join(top_data_dir, 'OUT/icml/nn_models/ae_farming', ae_net_name)\n",
    "ae_conf = Conf.load(osp.join(ae_net_dir, 'configuration'))\n",
    "reset_tf_graph()\n",
    "ae = PointNetAutoEncoder(ae_net_name, ae_conf)\n",
    "\n",
    "saved_epochs = read_saved_epochs(ae_conf.train_dir)\n",
    "load_epoch = saved_epochs[-1]\n",
    "ae.restore_model(ae_conf.train_dir, load_epoch, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6778 files containing complete point clouds were found.\n"
     ]
    }
   ],
   "source": [
    "# Load Raw Point-Clouds of class\n",
    "n_pc_samples = 2048\n",
    "pclouds_path = osp.join(top_data_dir, 'Point_Clouds/Shape_Net/Core/from_manifold_meshes/centered/', str(n_pc_samples))\n",
    "pclouds_path = osp.join(pclouds_path, syn_id)\n",
    "file_names = pio.load_filenames_of_input_data(pclouds_path, '.ply')\n",
    "pclouds, model_ids, syn_ids = pio.load_crude_point_clouds(file_names=file_names, n_threads=50, loader=sn_pc_loader)\n",
    "print '%d files containing complete point clouds were found.' % (len(pclouds), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pcloud_data = PointCloudDataSet(pclouds, labels=model_ids, init_shuffle=False)\n",
    "_, latent_codes, temp_names = latent_embedding_of_entire_dataset(pcloud_data, ae, ae_conf)\n",
    "assert(np.alltrue(temp_names==model_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "top_image_dir = '/orions4-zfs/projects/lins2/Panos_Space/DATA/Meshes/Shape_Net_Core/2015_Summer_OUT/Images/'\n",
    "top_image_dir = osp.join(top_image_dir, syn_id)\n",
    "image_view_tag = 'image_p020_t337_r005.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_thumbnails = 1000\n",
    "rids = np.random.choice(range(pcloud_data.num_examples), n_thumbnails, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Find TSNE of sub-selected objects.\n",
    "seed = 42\n",
    "model = TSNE(n_components=2, random_state=seed, init='pca')\n",
    "tsne_coords = model.fit_transform(latent_codes[rids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Make a list with the file-names of all to be used images.\n",
    "image_files = []\n",
    "for i in rids:\n",
    "    image_files.append(osp.join(top_image_dir, model_ids[i], image_view_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_2d_embedding_in_grid_forceful_(tsne_coords, image_files, big_dim=13000, small_dim=400, save_file='tsne_1k_chairs_128bneck_.png');\n",
    "# plot_2d_embedding_in_grid_greedy_way(tsne_coords, image_files, big_dim=14000, small_dim=400, save_file='tsne_greedy.png');\n",
    "# plot_2d_embedding_in_grid_forceful(tsne_coords, image_files, big_dim=14000, small_dim=400, save_file='tsne_greedy.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _scale_2d_embedding(two_dim_emb):\n",
    "    two_dim_emb -= np.min(two_dim_emb, axis=0)  # scale x-y in [0,1]\n",
    "    two_dim_emb /= np.max(two_dim_emb, axis=0)\n",
    "    return two_dim_emb\n",
    "\n",
    "def read_transparent_png(filename):\n",
    "    ''' TODO: add docstring\n",
    "    SEE https://stackoverflow.com/questions/3803888/opencv-how-to-load-png-images-with-4-channels'''\n",
    "\n",
    "    image_4channel = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "    alpha_channel = image_4channel[:, :, 3]\n",
    "    rgb_channels = image_4channel[:, :, :3]\n",
    "\n",
    "    # White Background Image\n",
    "    white_background_image = np.ones_like(rgb_channels, dtype=np.uint8) * 255\n",
    "\n",
    "    # Alpha factor\n",
    "    alpha_factor = alpha_channel[:, :, np.newaxis].astype(np.float32) / 255.0\n",
    "    alpha_factor = np.concatenate((alpha_factor, alpha_factor, alpha_factor), axis=2)\n",
    "\n",
    "    # Transparent Image Rendered on White Background\n",
    "    base = rgb_channels.astype(np.float32) * alpha_factor\n",
    "    white = white_background_image.astype(np.float32) * (1 - alpha_factor)\n",
    "    final_image = base + white\n",
    "    return final_image.astype(np.uint8)\n",
    "\n",
    "\n",
    "def plot_2d_embedding_in_grid_forceful_(two_dim_emb, image_files, big_dim=2500, small_dim=200, save_file=None):\n",
    "    x = _scale_2d_embedding(two_dim_emb)\n",
    "    out_image = np.ones((big_dim, big_dim, 3), dtype='uint8') * 255\n",
    "    N = two_dim_emb.shape[0]\n",
    "    xnum = int(big_dim / float(small_dim))\n",
    "    ynum = int(big_dim / float(small_dim))\n",
    "    free = np.ones(N, dtype=np.bool)\n",
    "\n",
    "    grid_2_img = np.ones((xnum, ynum), dtype='int') * -1\n",
    "    res = float(small_dim) / float(big_dim)\n",
    "    for i in xrange(xnum):\n",
    "        for j in xrange(ynum):\n",
    "            sorted_indices = np.argsort((x[:, 0] - i * res)**2 + (x[:, 1] - j * res)**2)\n",
    "            possible = sorted_indices[free[sorted_indices]]\n",
    "\n",
    "            if len(possible) > 0:\n",
    "                picked = possible[0]\n",
    "                free[picked] = False\n",
    "                grid_2_img[i, j] = picked\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    for i in xrange(xnum):\n",
    "        for j in xrange(ynum):\n",
    "            if grid_2_img[i, j] > -1:\n",
    "                im_file = image_files[grid_2_img[i, j]]\n",
    "                \n",
    "#                 fig = cv2.imread(im_file)\n",
    "                fig = read_transparent_png(im_file)\n",
    "                fig = cv2.resize(fig, (small_dim, small_dim))\n",
    "                \n",
    "                try:\n",
    "                    out_image[i * small_dim:(i + 1) * small_dim, j * small_dim:(j + 1) * small_dim, :] = fig\n",
    "                except:\n",
    "                    print 'the code here fails. fix it.'\n",
    "                    print im_file\n",
    "                continue\n",
    "\n",
    "    if save_file is not None:\n",
    "        im = Image.fromarray(out_image)\n",
    "        im.save(save_file)\n",
    "\n",
    "    return out_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def random_samples_from_each_class(syn_ids, samples_per_class=100):\n",
    "    selected = []\n",
    "    for syn_id in np.unique(syn_ids):\n",
    "        in_class = np.where(syn_ids == syn_id)[0]\n",
    "        effective_samples = min(len(in_class), samples_per_class)\n",
    "        selected += np.ndarray.tolist(np.random.choice(in_class, effective_samples, replace=False))\n",
    "    return selected"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
