{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "from scipy import spatial\n",
    "from scipy.sparse.linalg import eigs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "git_path = '/Users/optas/Documents/Git_Repos/'\n",
    "sys.path.insert(0, git_path)\n",
    "\n",
    "from tf_lab.fundamentals import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-67659e4d7d8d>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-67659e4d7d8d>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print tensorflow.models.image.cifar10.__file__\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.models.image.cifar10 import cifar10\n",
    "cifar10.FLAGS.data_dir = '/Users/optas/DATA/Images/CIFAR_10/'\n",
    "cifar10.maybe_download_and_extract()\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pad = 'SAME'\n",
    "stddev = 5e-2\n",
    "    \n",
    "def inference_network(in_signal):\n",
    "    layer = convolutional_layer(in_signal, n_filters=64, filter_size=[5,5], stride=1, padding=pad, stddev=stddev, name='conv1')\n",
    "    layer = max_pool(relu(layer), ksize=[3,3], stride=[2,2], name='max_pool_1')\n",
    "    layer = convolutional_layer(in_signal, n_filters=64, filter_size=[5,5], stride=1, padding=pad, stddev=stddev, name='conv2')\n",
    "    layer = max_pool(relu(layer), ksize=[3,3], stride=[2,2], name='max_pool_2')\n",
    "    layer = fully_connected_layer(layer, 384, stddev=0.04, wd=0.004, init_bias=0.1, name='fc_1')\n",
    "    layer = fully_connected_layer(layer, 192, stddev=0.04, wd=0.004, init_bias=0.1, name='fc_2')\n",
    "    return fully_connected_layer(layer, NUM_CLASSES, stddev=1/102.0, init_bias=0.0, name='fc_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "2016-12-31 21:42:09.115782: step 0, loss = 11.26 (14.7 examples/sec; 8.686 sec/batch)\n",
      "2016-12-31 21:42:10.883888: step 10, loss = 10.97 (729.5 examples/sec; 0.175 sec/batch)\n",
      "2016-12-31 21:42:12.641867: step 20, loss = 10.78 (718.9 examples/sec; 0.178 sec/batch)\n",
      "2016-12-31 21:42:14.391341: step 30, loss = 10.74 (749.7 examples/sec; 0.171 sec/batch)\n",
      "2016-12-31 21:42:16.120942: step 40, loss = 10.40 (736.5 examples/sec; 0.174 sec/batch)\n",
      "2016-12-31 21:42:17.855835: step 50, loss = 10.52 (730.7 examples/sec; 0.175 sec/batch)\n",
      "2016-12-31 21:42:19.573557: step 60, loss = 10.71 (747.3 examples/sec; 0.171 sec/batch)\n",
      "2016-12-31 21:42:21.334009: step 70, loss = 10.30 (701.0 examples/sec; 0.183 sec/batch)\n",
      "2016-12-31 21:42:23.109181: step 80, loss = 10.33 (731.6 examples/sec; 0.175 sec/batch)\n",
      "2016-12-31 21:42:24.860706: step 90, loss = 10.29 (740.5 examples/sec; 0.173 sec/batch)\n",
      "2016-12-31 21:42:26.578060: step 100, loss = 9.94 (746.4 examples/sec; 0.171 sec/batch)\n",
      "2016-12-31 21:42:28.358043: step 110, loss = 9.84 (721.0 examples/sec; 0.178 sec/batch)\n",
      "2016-12-31 21:42:30.125218: step 120, loss = 9.95 (729.8 examples/sec; 0.175 sec/batch)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8f81c5614994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/optas/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/optas/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/optas/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/optas/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/optas/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import time\n",
    "\n",
    "from six.moves import xrange\n",
    "\n",
    "FLAGS = cifar10.FLAGS\n",
    "max_steps = 1000000\n",
    "batch_size = 128\n",
    "train_dir  ='/Users/optas/DATA/Neural_Nets/Train_Log/'\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    images, labels = cifar10.distorted_inputs()\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    logits = inference_network(images)\n",
    "    loss = cifar10.loss(logits, labels)\n",
    "\n",
    "    # Build a Graph that trains the model with one batch of examples and\n",
    "    # updates the model parameters.\n",
    "    train_op = cifar10.train(loss, global_step)\n",
    "\n",
    "    # Create a saver.\n",
    "    saver = tf.train.Saver(tf.all_variables())\n",
    "    \n",
    "    init = tf.initialize_all_variables()\n",
    "    # Start running operations on the Graph.\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "    sess.run(init)\n",
    "\n",
    "    # Start the queue runners.\n",
    "    tf.train.start_queue_runners(sess=sess)\n",
    "    \n",
    "    for step in xrange(max_steps):\n",
    "        start_time = time.time()\n",
    "        _, loss_value = sess.run([train_op, loss])\n",
    "        duration = time.time() - start_time\n",
    "\n",
    "        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            num_examples_per_step = batch_size\n",
    "            examples_per_sec = num_examples_per_step / duration\n",
    "            sec_per_batch = float(duration)\n",
    "\n",
    "            format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f sec/batch)')\n",
    "            print (format_str % (datetime.now(), step, loss_value, examples_per_sec, sec_per_batch))\n",
    "\n",
    "#         if step % 100 == 0:\n",
    "#             summary_str = sess.run(summary_op)\n",
    "#             summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "        # Save the model checkpoint periodically.\n",
    "#         if step % 1000 == 0 or (step + 1) == max_steps:\n",
    "#             checkpoint_path = os.path.join(train_dir, 'model.ckpt')\n",
    "#             saver.save(sess, checkpoint_path, global_step=step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6331\n",
      "precision @ 1 = 0.634\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "checkpoint_file = '/Users/optas/DATA/Neural_Nets/Train_Log/CIFAR10/TF_LAB_version/model.ckpt-72000'\n",
    "num_examples = 10000\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    images, labels = cifar10.inputs(eval_data='test')    \n",
    "    logits = inference_network(images)\n",
    "    propbs = tf.nn.softmax(logits)    \n",
    "    top_k_op = tf.nn.in_top_k(propbs, labels, 1)   \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    tr_vars = tf.trainable_variables()\n",
    "    saver = tf.train.Saver(tr_vars)\n",
    "    saver.restore(sess, checkpoint_file)\n",
    "    # Start the queue runners.\n",
    "    tf.train.start_queue_runners(sess=sess)\n",
    "    \n",
    "#     global_step = checkpoint_file.split('/')[-1].split('-')[-1]        \n",
    "    predictions = sess.run([top_k_op])\n",
    "        \n",
    "    num_iter = int(math.ceil(num_examples / batch_size))\n",
    "    true_count = 0  # Counts the number of correct predictions.\n",
    "    total_sample_count = num_iter * batch_size\n",
    "    step = 0\n",
    "    while step < num_iter:\n",
    "        predictions = sess.run([top_k_op])\n",
    "        true_count += np.sum(predictions)\n",
    "        step += 1\n",
    "\n",
    "#       # Compute precision @ 1.\n",
    "    precision = true_count / float(total_sample_count)\n",
    "    print('precision @ 1 = %.3f' % (precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.34447801, -3.29785943,  0.05256522,  5.14447784, -0.26849735,\n",
       "        0.82257384,  2.97710323, -2.84878302,  1.01652539, -4.02707672], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
