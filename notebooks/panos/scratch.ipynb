{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Cloud AutoEncoders \"Experimental\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from general_tools.in_out import create_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/optas/DATA/Point_Clouds/Shape_Net_Core/3000/no_segmentations/03001627/'\n",
    "LOG_PATH = '/Users/optas/DATA/Neural_Nets/Train_Log/Point_Cloud_AE'\n",
    "MODEL_PATH = '/Users/optas/DATA/Neural_Nets/Models/Point_Cloud_AE'\n",
    "create_dir(LOG_PATH)\n",
    "create_dir(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUEUE_EPOCH_FRACTION = 0.1\n",
    "NUM_EPOCHS_PER_DECAY = 8          # Epochs after which learning rate decays.\n",
    "LEARNING_RATE_DECAY_FACTOR = 0.1  # Learning rate decay factor.\n",
    "INITIAL_LEARNING_RATE = 0.001     # Initial learning rate.\n",
    "\n",
    "#     keep_prob = 0.5\n",
    "#     stddev = 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tf_lab.point_clouds import point_cloud_ae as pae\n",
    "from tf_lab.point_clouds.point_cloud_ae import Configuration as ae_conf\n",
    "import tf_lab.point_clouds.in_out as pio\n",
    "from tf_lab.fundamentals.loss import Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = ae_conf()\n",
    "in_signal, gt_signal = pio.in_out_placeholders(config)\n",
    "model = pae.autoencoder_with_fcs_only(in_signal, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6778 files containing  point clouds were found.\n"
     ]
    }
   ],
   "source": [
    "in_files = pio.load_filenames_of_input_data(DATA_PATH)\n",
    "\n",
    "capacity = 10000\n",
    "input_tensors = in_files\n",
    "\n",
    "data_q = tf.RandomShuffleQueue(capacity=capacity, min_after_dequeue = capacity/4, dtypes=input_tensors.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not iterable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-39c014d30c96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepoch_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mepoch_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/optas/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0minvoked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \"\"\"\n\u001b[0;32m--> 499\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'Tensor' object is not iterable.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not iterable."
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 10\n",
    "epoch_tensors = []\n",
    "for tensor in input_tensors:\n",
    "    epoch_tensors.append(tf.train.limit_epochs(tensor, num_epochs))\n",
    "\n",
    "print epoch_tensors\n",
    "# enq_op = data_q.enqueue_many(epoch_tensors)\n",
    "# qr = tf.train.QueueRunner(self.data_q, [enq_op])\n",
    "#         tf.train.add_queue_runner(qr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = Loss.l2_loss(model, gt_signal)\n",
    "optimizer = tf.train.GradientDescentOptimizer(INITIAL_LEARNING_RATE).minimize(loss)\n",
    "pclouds, names = load_crude_point_clouds(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_steps = (len(pclouds) // config.batch_size) * config.training_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "[array([[  9.89372240e-29,   9.99751389e-01,   4.25720461e-35, ...,\n",
      "          2.48523487e-04,   7.65052235e-08,   6.46529433e-19],\n",
      "       [  5.58076707e-22,   3.49713904e-23,   1.40103731e-35, ...,\n",
      "          9.08389919e-10,   1.72844185e-26,   7.37164357e-11],\n",
      "       [  9.71022601e-27,   2.51064481e-23,   0.00000000e+00, ...,\n",
      "          1.55498248e-36,   6.02137003e-15,   7.03709175e-37],\n",
      "       ..., \n",
      "       [  5.50711560e-12,   2.81982924e-19,   0.00000000e+00, ...,\n",
      "          4.71312746e-12,   1.00000000e+00,   1.39827672e-09],\n",
      "       [  9.99974370e-01,   1.99023309e-09,   4.99290294e-16, ...,\n",
      "          2.56190851e-05,   1.22772589e-14,   1.48472119e-14],\n",
      "       [  1.66505838e-24,   7.60911569e-29,   1.34719100e-33, ...,\n",
      "          2.27212929e-14,   1.00000000e+00,   5.11814809e-24]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    for step in total_steps:\n",
    "    \n",
    "        \n",
    "        \n",
    "#     # Get images and labels for CIFAR-10.\n",
    "#     images, labels = cifar10.distorted_inputs()\n",
    "#     pred = cifar_10_vgg_classifier(images)\n",
    "#     #     fc_cv, fc = test_vgg_m_conv(images, 1, g)\n",
    "#     init = tf.initialize_all_variables()        \n",
    "#     sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "#     sess.run(init)\n",
    "#     # Start the queue runners.\n",
    "#     tf.train.start_queue_runners(sess=sess)    \n",
    "#     print sess.run([pred])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.82317972  7.56947613  2.45779705 -1.21228302  5.42072678 -5.22100878\n",
      " -1.47143781  5.10664082  4.20103455 -0.52912915 -3.39429331  1.91564465\n",
      "  1.12573886 -1.36975384 -2.57543731  3.38702774 -1.90229058 -7.67551136\n",
      "  0.73936599 -1.94913518  3.53006053  0.15869325  5.00703335 -0.71717119\n",
      "  4.98837757  0.75052369  1.19316506 -1.38610315 -2.14804769 -0.78406906]\n",
      "[-4.82317972  7.56947613  2.45779705 -1.21228302  5.42072678 -5.22100878\n",
      " -1.47143781  5.10664082  4.20103455 -0.52912915 -3.39429331  1.91564465\n",
      "  1.12573886 -1.36975384 -2.57543731  3.38702774 -1.90229058 -7.67551136\n",
      "  0.73936599 -1.94913518  3.53006053  0.15869325  5.00703335 -0.71717119\n",
      "  4.98837757  0.75052369  1.19316506 -1.38610315 -2.14804769 -0.78406906]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
