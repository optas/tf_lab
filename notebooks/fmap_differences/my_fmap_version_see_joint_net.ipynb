{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = np.zeros(shape=(n_vertex, n_vertex))\n",
    "np.fill_diagonal(temp, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6449, 1)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = A.reshape(-1,1)\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csr_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-38458ee94bc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdia_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdia_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_vertex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_vertex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'csr_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "csr_matrix((A, (dia_idx, dia_idx)), shape=(n_vertex, n_vertex), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-36b8dcc49bb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marea_of_vertices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mall_areas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdia_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdia_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_vertex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_vertex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mall_areas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_areas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/optas/.local/lib/python2.7/site-packages/scipy/sparse/compressed.pyc\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m         \u001b[0m_sparsetools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_todense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# dtype = np.float32\n",
    "# n_eigs = 50\n",
    "\n",
    "# n_vertex = random_meshes[0].num_vertices\n",
    "# all_evecs = np.zeros(shape=(n_meshes, n_vertex, n_eigs), dtype=dtype)\n",
    "# all_evals = np.zeros(shape=(n_meshes, n_eigs), dtype=dtype)\n",
    "\n",
    "# for i, in_m in enumerate(random_meshes):\n",
    "#     lb = Laplace_Beltrami(in_m)\n",
    "#     all_evals[i], all_evecs[i] = lb.spectra(n_eigs)\n",
    "    \n",
    "all_areas = []\n",
    "# dia_idx = np.arange(n_vertex)\n",
    "for i, in_m in enumerate(random_meshes):    \n",
    "    A = in_m.area_of_vertices().reshape(-1)\n",
    "    temp = np.zeros(shape=(n_vertex, n_vertex))\n",
    "    \n",
    "    all_areas\n",
    "#     all_areas.append(csr_matrix((A, (dia_idx, dia_idx)), shape=(n_vertex, n_vertex), dtype=dtype))\n",
    "#     all_areas[-1] = all_areas[-1].toarray() # MAKE-dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_edges = 200\n",
    "gg = gnm_random_graph(n_meshes, n_edges)\n",
    "is_directed = False\n",
    "g = Graph(gg, is_directed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s, t = g.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-fd33a1c5b775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mall_evecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_areas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_evecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/afs/cs.stanford.edu/u/optas/.local/lib/python2.7/site-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36m__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# other * self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;31m# Don't use asarray unless we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/optas/.local/lib/python2.7/site-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;31m# scalar value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/optas/.local/lib/python2.7/site-packages/scipy/sparse/data.pyc\u001b[0m in \u001b[0;36m_mul_scalar\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_mul_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/optas/.local/lib/python2.7/site-packages/scipy/sparse/compressed.pyc\u001b[0m in \u001b[0;36m_with_data\u001b[0;34m(self, data, copy)\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \"\"\"\n\u001b[1;32m   1083\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m             return self.__class__((data,self.indices.copy(),self.indptr.copy()),\n\u001b[0m\u001b[1;32m   1085\u001b[0m                                    shape=self.shape,dtype=data.dtype)\n\u001b[1;32m   1086\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_fmaps = []\n",
    "for i, j in zip(s, t):\n",
    "    all_fmaps.append(all_evecs[j].T.dot(all_areas[j]).dot(all_evecs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph.connected_components(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "g = gnm_random_graph(n, 10, seed=None, directed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = coo_matrix((vals, (source_e, target_e)), shape=(n, n)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(g == b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feed', 'labels', 'ids']\n",
      "['feed', 'labels', 'ids']\n",
      "['feed', 'labels', 'ids']\n"
     ]
    }
   ],
   "source": [
    "# splits = prepare_train_test_val(n_shapes, in_labels, train_per, test_per, seed=seed)\n",
    "\n",
    "# if use_pc: \n",
    "#     feeds = in_pcs\n",
    "# else:\n",
    "#     feeds = in_diffs\n",
    "\n",
    "# in_data = make_data(splits, feeds, in_labels)\n",
    "\n",
    "from tf_lab.data_sets.numpy_dataset import NumpyDataset\n",
    "def make_data_mixed(in_data, in_pc, class_labels, in_diff):\n",
    "    res = dict()\n",
    "    for s in ['train', 'test', 'val']:\n",
    "        idx = in_data[s].copy()        \n",
    "        res[s] = NumpyDataset([in_pc[idx], class_labels[idx], in_diff[idx]], ['feed', 'labels', 'ids'])\n",
    "    return res\n",
    "\n",
    "in_data = make_data_mixed(splits, in_pcs, in_labels, in_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_pc = False\n",
    "arch = 'conv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18599\n"
     ]
    }
   ],
   "source": [
    "reset_tf_graph()\n",
    "\n",
    "if use_pc: \n",
    "    with tf.variable_scope('pc_based_net') as scope:\n",
    "        feed_pl = tf.placeholder(tf.float32, shape = (None, n_pc_points, 3) )\n",
    "        labels_pl = tf.placeholder(tf.int64, shape=[None])                           \n",
    "        layer = encoder_with_convs_and_symmetry_new(feed_pl, n_filters=[64, 128], b_norm=False)\n",
    "        layer = fully_connected(layer, 64, activation='relu', weights_init='xavier')\n",
    "        logits = fully_connected(layer, n_classes, activation='linear', weights_init='xavier')\n",
    "else:\n",
    "    labels_pl = tf.placeholder(tf.int64, shape=[None])\n",
    "    diff_dims = (60, 30)\n",
    "    feed_pl_1 = tf.placeholder(tf.float32, shape = (None, n_pc_points, 3) )\n",
    "    feed_pl_2 = tf.placeholder(tf.float32, shape = (None, ) + diff_dims)\n",
    "    \n",
    "    layer_pc = encoder_with_convs_and_symmetry_new(feed_pl_1, n_filters=[64, 128], b_norm=False)\n",
    "    \n",
    "    \n",
    "    layer = conv_2d(tf.expand_dims(feed_pl_2, -1), nb_filter=4, filter_size=4, activation='relu')\n",
    "    layer = max_pool_2d(layer, kernel_size=2)\n",
    "    layer = conv_2d(layer, nb_filter=4, filter_size=3, activation='relu')\n",
    "    layer = max_pool_2d(layer, kernel_size=2)\n",
    "    layer = fully_connected(layer, 6, activation='relu', weights_init='xavier')    \n",
    "    layer_diff = fully_connected(layer, 64, activation='relu', weights_init='xavier')\n",
    "    layer = tf.concat([layer_pc, layer_diff], axis=1)    \n",
    "    layer = fully_connected(layer, 32, activation='relu', weights_init='xavier')\n",
    "    logits = fully_connected(layer, n_classes, activation='linear', weights_init='xavier')\n",
    "    \n",
    "#     diff_dims = in_data['train'].feed[0].shape    \n",
    "#     with tf.variable_scope('diff_based_net') as scope:\n",
    "#         feed_pl = tf.placeholder(tf.float32, shape = (None, ) + diff_dims)\n",
    "#         labels_pl = tf.placeholder(tf.int64, shape=[None])\n",
    "    \n",
    "#         if arch == 'mlp':\n",
    "#             layer = fully_connected(feed_pl, 4, activation='relu', weights_init='xavier')\n",
    "#             layer = fully_connected(layer, 6, activation='relu', weights_init='xavier')\n",
    "#             logits = fully_connected(layer, n_classes, activation='linear', weights_init='xavier')\n",
    "\n",
    "#         elif arch == 'conv':\n",
    "#             layer = conv_2d(tf.expand_dims(feed_pl, -1), nb_filter=4, filter_size=4, activation='relu')\n",
    "#             layer = max_pool_2d(layer, kernel_size=2)\n",
    "#             layer = conv_2d(layer, nb_filter=4, filter_size=3, activation='relu')\n",
    "#             layer = max_pool_2d(layer, kernel_size=2)\n",
    "#             layer = fully_connected(layer, 12, activation='relu', weights_init='xavier')\n",
    "#             logits = fully_connected(layer, n_classes, activation='linear', weights_init='xavier')\n",
    "#         else:\n",
    "#             assert(False)\n",
    "\n",
    "print count_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(logits, axis=1)\n",
    "target_ = labels_pl\n",
    "correct_pred = tf.equal(prediction, target_)\n",
    "avg_accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "one_hot_labels = tf.one_hot(labels_pl, depth=n_classes)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_labels)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "learning_rate = 0.001\n",
    "opt = tf.train.AdamOptimizer(learning_rate)\n",
    "opt_step = opt.minimize(loss)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
