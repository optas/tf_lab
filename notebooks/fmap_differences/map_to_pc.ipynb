{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 0\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook.gpu_utils import setup_one_gpu\n",
    "GPU = 0\n",
    "setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "\n",
    "from tflearn.layers.core import fully_connected\n",
    "from tflearn.layers.conv import conv_2d\n",
    "\n",
    "from tf_lab.point_clouds.encoders_decoders import decoder_with_fc_only\n",
    "from tf_lab.external.structural_pc_losses import losses\n",
    "from general_tools.notebook.tf import reset_tf_graph\n",
    "from tf_lab.data_sets.numpy_dataset import NumpyDataset\n",
    "from geo_tool import Point_Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "\n",
    "from tf_lab.diff_maps.in_out import raw_data, produce_net_data,\\\n",
    "prep_splits_labels_for_task, produce_diff_maps, classes_of_tasks\n",
    "\n",
    "from tf_lab.diff_maps.basic_nets import pc_net, diff_mlp_net, diff_conv_net, pc_versions\n",
    "from tf_lab.diff_maps.basic_nets import Basic_Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_conv_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_mesh_dir = '/orions4-zfs/projects/optas/DATA/Meshes/SCAPE_8_poses_2/'\n",
    "gt_param_f = osp.join(top_mesh_dir, 'gt_shape_params.mat')\n",
    "n_pose_classes = helper.n_pose_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use_pc = False\n",
    "knn = 0\n",
    "arch = 'conv'\n",
    "sub_member_per_class = 50\n",
    "n_shapes = sub_member_per_class * n_pose_classes\n",
    "val_per = 0.10\n",
    "test_per = 0.15\n",
    "train_per = 1.0 - (val_per + test_per)\n",
    "n_pc_points = 1024\n",
    "task = 'regression'\n",
    "mean_norm_diffs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_data_dir = '/orions4-zfs/projects/optas/DATA/OUT/latent_diff_maps/experiments/SCAPE_8_poses_2'\n",
    "synced_bases_file = osp.join(top_data_dir, '50_extract_%d_knn_50_fmapd.mat' % (knn,) )\n",
    "n_cons = 40\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_latent_params, in_pcs, pose_labels = \\\n",
    "raw_data(top_mesh_dir, gt_param_f, sub_member_per_class, n_pc_points)\n",
    "\n",
    "n_classes = classes_of_tasks(task)\n",
    "\n",
    "diff_maps = produce_diff_maps(synced_bases_file, n_cons, n_shapes)\n",
    "\n",
    "splits, labels = \\\n",
    "prep_splits_labels_for_task(task, gt_latent_params, pose_labels, train_per, test_per, seed)\n",
    "\n",
    "net_data = produce_net_data(in_pcs, splits, labels, diff_maps, use_pc, mean_norm_diffs)\n",
    "\n",
    "#TODO mixed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_distance, approx_match, match_cost = losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try with     n_cons = 40\n",
    "def diff_reconstructor(n_cons, n_pc_points):\n",
    "    with tf.variable_scope('conv_based_reconstructor'):\n",
    "        feed_pl = tf.placeholder(tf.float32, shape=(None, n_cons, n_cons))\n",
    "        labels_pl = tf.placeholder(tf.float32, shape=(None, n_pc_points, 3))\n",
    "        layer = tf.expand_dims(feed_pl, -1)\n",
    "        layer = conv_2d(layer, nb_filter=10, filter_size=3, strides=2, activation='relu')        \n",
    "        layer = conv_2d(layer, nb_filter=10, filter_size=4, strides=2, activation='relu')\n",
    "        net_out = decoder_with_fc_only(layer, layer_sizes=[128, n_pc_points*3], b_norm=False)\n",
    "    return net_out, feed_pl, labels_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_tf_graph()\n",
    "# sess = tf.InteractiveSession()\n",
    "\n",
    "n_points = 2048\n",
    "pc_dim = 3\n",
    "n_classes = 2\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_points, pc_dim])\n",
    "y = tf.placeholder(tf.float32, [None, n_points, pc_dim])\n",
    "l = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "\n",
    "enc_filters = [64, 128, 128, 256]\n",
    "split_of_embedding = 0.5\n",
    "dim_thres = int(enc_filters[-1] * split_of_embedding)\n",
    "\n",
    "mask_neurons = [100, 100, n_points]\n",
    "decoder_neurons = [128, 256, n_points * 3]\n",
    "discriminator_neurons = [128, 256]\n",
    "gen_neurons = [128, 256]\n",
    "\n",
    "# with tf.variable_scope('encoder') as scope:    \n",
    "#     zx = encoder_with_convs_and_symmetry_new(x, n_filters=enc_filters, b_norm=False, scope=scope)\n",
    "#     zx_sim = zx[:, :dim_thres]\n",
    "#     zx_dissim = zx[:, dim_thres:]\n",
    "    \n",
    "#     zy = encoder_with_convs_and_symmetry_new(y, n_filters=enc_filters, b_norm=False, scope=scope, reuse=True)\n",
    "#     zy_sim = zy[:, :dim_thres]\n",
    "#     zy_dissim = zy[:, dim_thres:]\n",
    "    \n",
    "# with tf.variable_scope('mask_creator') as scope:\n",
    "#     mask = decoder_with_fc_only(zx, layer_sizes=mask_neurons, b_norm=False, scope=scope)\n",
    "#     mask_x_sim = tf.sigmoid(mask) >= 0.5    \n",
    "#     mask_x_dissim = tf.logical_not(mask_x_sim)    \n",
    "#     mask_x_sim = tf.tile(tf.expand_dims(mask_x_sim, 2), [1, 1, pc_dim])  # TODO d-check\n",
    "#     mask_x_sim = tf.cast(mask_x_sim, tf.float32)    \n",
    "#     mask_x_dissim = tf.tile(tf.expand_dims(mask_x_dissim, 2), [1, 1, pc_dim])  # TODO d-check\n",
    "#     mask_x_dissim = tf.cast(mask_x_dissim, tf.float32)\n",
    "        \n",
    "#     mask = decoder_with_fc_only(zy, layer_sizes=mask_neurons, b_norm=False, scope=scope, reuse=True)\n",
    "#     mask_y_sim = tf.sigmoid(mask) >= 0.5\n",
    "#     mask_y_dissim = tf.logical_not(mask_y_sim)    \n",
    "#     mask_y_sim = tf.tile(tf.expand_dims(mask_y_sim, 2), [1, 1, pc_dim])  # TODO d-check\n",
    "#     mask_y_sim = tf.cast(mask_y_sim, tf.float32)    \n",
    "#     mask_y_dissim = tf.tile(tf.expand_dims(mask_y_dissim, 2), [1, 1, pc_dim])  # TODO d-check\n",
    "#     mask_y_dissim = tf.cast(mask_y_dissim, tf.float32)\n",
    "\n",
    "# with tf.variable_scope('sim_decoder') as scope:\n",
    "#     x_sim_pred = decoder_with_fc_only(zx_sim, layer_sizes=decoder_neurons, b_norm=False, scope=scope)\n",
    "#     x_sim_pred = tf.reshape(x_sim_pred, [-1, n_points, pc_dim])\n",
    "#     y_sim_pred = decoder_with_fc_only(zy_sim, layer_sizes=decoder_neurons, b_norm=False, scope=scope, reuse=True)\n",
    "#     y_sim_pred = tf.reshape(y_sim_pred, [-1, n_points, pc_dim])\n",
    "\n",
    "# with tf.variable_scope('dissim_decoder') as scope:    \n",
    "#     x_dissim_pred = decoder_with_fc_only(zx_dissim, layer_sizes=decoder_neurons, b_norm=False, scope=scope)\n",
    "#     x_dissim_pred = tf.reshape(x_dissim_pred, [-1, n_points, pc_dim])\n",
    "#     y_dissim_pred = decoder_with_fc_only(zy_dissim, layer_sizes=decoder_neurons, b_norm=False, scope=scope, reuse=True)\n",
    "#     y_dissim_pred = tf.reshape(y_dissim_pred, [-1, n_points, pc_dim])\n",
    "    \n",
    "# with tf.variable_scope('ae_losses') as scope:\n",
    "#     x_sim_masked = tf.multiply(x, mask_x_sim)\n",
    "#     x_dissim_masked = tf.multiply(x, mask_x_dissim)    \n",
    "    \n",
    "#     y_sim_masked = tf.multiply(y, mask_y_sim)\n",
    "#     y_dissim_masked = tf.multiply(y, mask_y_dissim)\n",
    "    \n",
    "#     l1, _, s1, _ = nn_distance(x_sim_pred, y_sim_masked)\n",
    "#     l2, _, s2, _ = nn_distance(x_dissim_pred, x_dissim_masked)\n",
    "#     l3, _, s3, _ = nn_distance(y_sim_pred, x_sim_masked)\n",
    "#     l4, _, s4, _ = nn_distance(y_dissim_pred, y_dissim_masked)    \n",
    "#     ae_loss = tf.reduce_mean(l1 + l2 + l3 + l4)\n",
    "#     ae_loss += tf.reduce_mean(s1 + s2 + s3 + s4)        \n",
    "\n",
    "# with tf.variable_scope('generator') as scope:    \n",
    "#     gen_in = tf.concat([zx_sim, zy_dissim, zx_dissim], axis=1)\n",
    "#     gen_out = decoder_with_fc_only(gen_in, layer_sizes=gen_neurons + [dim_thres], b_norm=False, scope=scope)\n",
    "#     gen_out = tf.nn.relu(gen_out)\n",
    "#     gen_labels = tf.zeros_like(l)\n",
    "    \n",
    "# with tf.variable_scope('discriminator') as scope:\n",
    "#     l_sizes = discriminator_neurons + [n_classes]\n",
    "#     data_sim = tf.concat([zx_sim, zy_sim], axis=1)\n",
    "#     data_logit = decoder_with_fc_only(data_sim, layer_sizes=l_sizes, b_norm=False, scope=scope)    \n",
    "#     gen_sim = tf.concat([zx_sim, gen_out], axis=1)\n",
    "#     gen_logit = decoder_with_fc_only(gen_sim, layer_sizes=l_sizes, b_norm=False, scope=scope, reuse=True)\n",
    "    \n",
    "# with tf.variable_scope('consistency_losses'):    \n",
    "#     d_data_loss = tf.reduce_mean(tf.losses.log_loss(labels=l, predictions=tf.nn.softmax(data_logit)))\n",
    "#     d_gen_loss = tf.reduce_mean(tf.losses.log_loss(labels=gen_labels, predictions=tf.nn.softmax(gen_logit)))\n",
    "#     generator_push = -tf.reduce_mean(tf.losses.log_loss(labels=gen_labels, predictions=tf.nn.softmax(gen_logit)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
