{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 0\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook.gpu_utils import setup_one_gpu\n",
    "GPU = 0\n",
    "setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from general_tools.notebook.tf import reset_tf_graph\n",
    "from scipy.io import loadmat, savemat\n",
    "from geo_tool import Point_Cloud\n",
    "import os.path as osp\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.spatial.distance import pdist\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import hdf5storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tflearn.layers.core import fully_connected\n",
    "from tf_lab.point_clouds.encoders_decoders import encoder_with_convs_and_symmetry_new, decoder_with_fc_only\n",
    "from tf_lab.data_sets.numpy_dataset import NumpyDataset\n",
    "from tflearn.layers.conv import conv_2d\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_data_dir = '/orions4-zfs/projects/optas/DATA/OUT/latent_diff_maps/experiments/human_poses/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 8\n",
    "members_per_class = 150\n",
    "val_per = 0.05\n",
    "test_per = 0.15\n",
    "train_per = 1.0 - (val_per + test_per)\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LOAD input differences\n",
    "in_diffs = osp.join(top_data_dir, '%d_60_30_consistent_diffs.mat' % members_per_class)\n",
    "in_diffs = hdf5storage.loadmat(in_diffs)\n",
    "n_shapes = len(in_diffs['ucb'])\n",
    "diff_dims = in_diffs['ucb'][1][0].shape\n",
    "temp = np.zeros(shape=(n_shapes, ) + diff_dims )\n",
    "for i in xrange(n_shapes):\n",
    "    temp[i] = in_diffs['ucb'][i][0]\n",
    "in_diffs = temp\n",
    "in_diffs[in_diffs < 10e-6] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_labels = np.zeros(n_shapes)\n",
    "c = 0\n",
    "for i in range(n_shapes):\n",
    "    if i % members_per_class == 0:\n",
    "        c += 1\n",
    "    class_labels[i] = c\n",
    "class_labels -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cs.stanford.edu/u/optas/.local/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "all_ids = np.arange(n_shapes)\n",
    "train_ids, rest_ids = train_test_split(all_ids, stratify=class_labels, train_size=train_per, random_state=seed)\n",
    "test_ids, val_ids = train_test_split(rest_ids, stratify=class_labels[rest_ids], train_size=int(n_shapes*test_per), random_state=seed)\n",
    "# np.sum(np.logical_and(test_ids>=300,  test_ids<400))\n",
    "in_data = dict()\n",
    "in_data['train'] = train_ids\n",
    "in_data['test'] = test_ids\n",
    "in_data['val'] = val_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diff_maps', 'labels', 'ids']\n",
      "['diff_maps', 'labels', 'ids']\n",
      "['diff_maps', 'labels', 'ids']\n"
     ]
    }
   ],
   "source": [
    "for s in ['train', 'test', 'val']:\n",
    "    idx = in_data[s].copy()\n",
    "    in_data[s] = NumpyDataset([in_diffs[idx], class_labels[idx], idx], ['diff_maps', 'labels', 'ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_tf_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('diff_based_net') as scope:\n",
    "    diffs_pl = tf.placeholder(tf.float32, shape = (None, ) + diff_dims)\n",
    "    labels_pl = tf.placeholder(tf.int64, shape=[None])\n",
    "    layer = fully_connected(diffs_pl, 64, activation='relu', weights_init='xavier')\n",
    "    layer = fully_connected(layer, 64, activation='relu', weights_init='xavier')\n",
    "    logits = fully_connected(layer, n_classes, activation='linear', weights_init='xavier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(logits, axis=1)\n",
    "target_ = labels_pl\n",
    "correct_pred = tf.equal(prediction, target_)\n",
    "avg_accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "one_hot_labels = tf.one_hot(labels_pl, depth=n_classes)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_labels)\n",
    "loss = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "opt = tf.train.AdamOptimizer(learning_rate)\n",
    "opt_step = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 25\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "train_data = in_data['train']\n",
    "val_data = in_data['val']\n",
    "test_data = in_data['test']\n",
    "\n",
    "batches_for_epoch = train_data.n_examples / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.16979167] [0.16666669] [0.13333334]\n",
      "1 [0.19270834] [0.16666669] [0.15000001]\n",
      "2 [0.48541668] [0.41666669] [0.3666667]\n",
      "3 [0.40625006] [0.35000002] [0.27777779]\n",
      "4 [0.6052084] [0.55000007] [0.47222227]\n",
      "5 [0.671875] [0.56666672] [0.56666672]\n",
      "6 [0.73125005] [0.73333335] [0.65555561]\n",
      "7 [0.81875008] [0.75000006] [0.70555568]\n",
      "8 [0.88854176] [0.78333342] [0.77777779]\n",
      "9 [0.90104169] [0.83333337] [0.80000001]\n",
      "10 [0.92916673] [0.83333337] [0.85000002]\n",
      "11 [0.93020833] [0.81666672] [0.80555564]\n",
      "12 [0.95208323] [0.85000002] [0.86666673]\n",
      "13 [0.9666667] [0.91666669] [0.92222226]\n",
      "14 [0.97395837] [0.90000004] [0.9000001]\n",
      "15 [0.984375] [0.93333334] [0.92222226]\n",
      "16 [0.98541665] [0.93333334] [0.92777777]\n",
      "17 [0.98958337] [0.9333334] [0.92777777]\n",
      "18 [0.99166673] [0.95000005] [0.92222232]\n",
      "19 [0.99270844] [0.95000005] [0.9333334]\n",
      "20 [0.9937501] [0.9333334] [0.93888891]\n",
      "21 [0.9937501] [0.95000005] [0.95000005]\n",
      "22 [0.9958334] [0.95000005] [0.94999999]\n",
      "23 [0.99479175] [0.9333334] [0.95555556]\n",
      "24 [0.9979167] [0.95000005] [0.95555556]\n",
      "25 [0.99895841] [0.95000005] [0.96111119]\n",
      "26 [1.0] [0.95000005] [0.95555562]\n",
      "27 [1.0] [0.95000005] [0.95555556]\n",
      "28 [1.0] [0.9666667] [0.96111113]\n",
      "29 [1.0] [0.9666667] [0.95555556]\n",
      "30 [1.0] [0.95000005] [0.96111113]\n",
      "31 [1.0] [0.9333334] [0.95555556]\n",
      "32 [1.0] [0.9666667] [0.95555562]\n",
      "33 [1.0] [0.9666667] [0.96111113]\n",
      "34 [1.0] [0.9666667] [0.96111113]\n",
      "35 [1.0] [0.9666667] [0.96111113]\n",
      "36 [1.0] [0.9666667] [0.96111113]\n",
      "37 [1.0] [0.9666667] [0.96111119]\n",
      "38 [1.0] [0.9666667] [0.96666664]\n",
      "39 [1.0] [0.9666667] [0.96111113]\n",
      "40 [1.0] [0.9666667] [0.96111113]\n",
      "41 [1.0] [0.9666667] [0.96111113]\n",
      "42 [1.0] [0.9666667] [0.96666664]\n",
      "43 [1.0] [0.9666667] [0.96111113]\n",
      "44 [1.0] [0.9666667] [0.96666664]\n",
      "45 [1.0] [0.9666667] [0.96111113]\n",
      "46 [1.0] [0.9666667] [0.96111107]\n",
      "47 [1.0] [0.9666667] [0.9666667]\n",
      "48 [1.0] [0.9666667] [0.96666664]\n",
      "49 [1.0] [0.9666667] [0.96666664]\n",
      "50 [1.0] [0.9666667] [0.96666664]\n",
      "51 [1.0] [0.9666667] [0.96666664]\n",
      "52 [1.0] [0.9666667] [0.96666664]\n",
      "53 [1.0] [0.9666667] [0.96666664]\n",
      "54 [1.0] [0.9666667] [0.96666664]\n",
      "55 [1.0] [0.9666667] [0.96666664]\n",
      "56 [1.0] [0.9666667] [0.96666664]\n",
      "57 [1.0] [0.9666667] [0.96666664]\n",
      "58 [1.0] [0.9666667] [0.96666664]\n",
      "59 [1.0] [0.9666667] [0.9666667]\n",
      "60 [1.0] [0.9666667] [0.96666664]\n",
      "61 [1.0] [0.9666667] [0.96666664]\n",
      "62 [1.0] [0.9666667] [0.96666664]\n",
      "63 [1.0] [0.9666667] [0.9666667]\n",
      "64 [1.0] [0.9666667] [0.96666664]\n",
      "65 [1.0] [0.9666667] [0.9666667]\n",
      "66 [1.0] [0.9666667] [0.9666667]\n",
      "67 [1.0] [0.9666667] [0.96666664]\n",
      "68 [1.0] [0.9666667] [0.96666664]\n",
      "69 [1.0] [0.9666667] [0.9666667]\n",
      "70 [1.0] [0.9666667] [0.96666664]\n",
      "71 [1.0] [0.9666667] [0.96666664]\n",
      "72 [1.0] [0.9666667] [0.96666664]\n",
      "73 [1.0] [0.9666667] [0.96666664]\n",
      "74 [1.0] [0.9666667] [0.96666664]\n",
      "75 [1.0] [0.9666667] [0.96666664]\n",
      "76 [1.0] [0.9666667] [0.96666664]\n",
      "77 [1.0] [0.9666667] [0.96666664]\n",
      "78 [1.0] [0.9666667] [0.96666664]\n",
      "79 [1.0] [0.9666667] [0.96666664]\n",
      "80 [1.0] [0.9666667] [0.96666664]\n",
      "81 [1.0] [0.9666667] [0.9666667]\n",
      "82 [1.0] [0.9666667] [0.96666664]\n",
      "83 [1.0] [0.9666667] [0.96666664]\n",
      "84 [1.0] [0.9666667] [0.96666664]\n",
      "85 [1.0] [0.9666667] [0.96666664]\n",
      "86 [1.0] [0.9666667] [0.96666664]\n",
      "87 [1.0] [0.9666667] [0.96666664]\n",
      "88 [1.0] [0.9666667] [0.96666664]\n",
      "89 [1.0] [0.9666667] [0.96666664]\n",
      "90 [1.0] [0.9666667] [0.9666667]\n",
      "91 [1.0] [0.9666667] [0.96666664]\n",
      "92 [1.0] [0.9666667] [0.96666664]\n",
      "93 [1.0] [0.9666667] [0.96666664]\n",
      "94 [1.0] [0.9666667] [0.96666664]\n",
      "95 [1.0] [0.9666667] [0.9666667]\n",
      "96 [1.0] [0.9666667] [0.9666667]\n",
      "97 [1.0] [0.9666667] [0.96666664]\n",
      "98 [1.0] [0.9666667] [0.96666664]\n",
      "99 [1.0] [0.9666667] [0.96666664]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):    \n",
    "    for _ in range(batches_for_epoch):        \n",
    "        batch_d, batch_l, _ = train_data.next_batch(batch_size)\n",
    "        feed_dict = {diffs_pl:batch_d, labels_pl:batch_l}\n",
    "        sess.run([opt_step, loss, avg_accuracy], feed_dict=feed_dict)\n",
    "    \n",
    "    feed_dict = {diffs_pl:train_data.diff_maps, labels_pl:train_data.labels}\n",
    "    train_losses.append(sess.run([avg_accuracy], feed_dict=feed_dict))\n",
    "    \n",
    "    feed_dict = {diffs_pl:val_data.diff_maps, labels_pl:val_data.labels}\n",
    "    val_losses.append(sess.run([avg_accuracy], feed_dict=feed_dict))\n",
    "        \n",
    "    feed_dict = {diffs_pl:test_data.diff_maps, labels_pl:test_data.labels}\n",
    "    test_losses.append(sess.run([avg_accuracy], feed_dict=feed_dict))\n",
    "\n",
    "    print epoch, train_losses[-1], val_losses[-1], test_losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feed_dict = {diffs_pl:test_data.diff_maps, labels_pl:test_data.labels}\n",
    "# pred = sess.run(prediction, feed_dict=feed_dict)\n",
    "# missed = np.where(test_data.labels != pred)\n",
    "# pred[missed]\n",
    "# test_data.labels[missed]\n",
    "# test_data.ids[missed]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
