{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 2\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook.gpu_utils import setup_one_gpu\n",
    "GPU = 2\n",
    "setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from general_tools.notebook.tf import reset_tf_graph\n",
    "from general_tools.in_out.basics import create_dir, files_in_subdirs\n",
    "from geo_tool import Point_Cloud\n",
    "from tf_lab.in_out.basics import Data_Splitter, read_saved_epochs\n",
    "from tf_lab.point_clouds.ae_templates import mlp_architecture_ala_iclr_18, default_train_params\n",
    "from tf_lab.point_clouds.autoencoder import Configuration as Conf\n",
    "from tf_lab.point_clouds.point_net_ae import PointNetAutoEncoder\n",
    "from tf_lab.point_clouds.in_out import load_point_clouds_from_filenames, PointCloudDataSet\n",
    "from tf_lab.data_sets.shape_net import pc_loader as snc_loader\n",
    "from tf_lab.data_sets.shape_net import snc_category_to_synth_id\n",
    "from tf_lab.point_clouds.latent_gan import LatentGAN\n",
    "from tf_lab.point_clouds.generators_discriminators import latent_code_discriminator_two_layers, \\\n",
    "latent_code_generator_two_layers, latent_code_discriminator, latent_code_generator\n",
    "from tf_lab.iclr.helper import load_multiple_version_of_pcs, find_best_validation_epoch_from_train_stats\n",
    "from tf_lab.point_clouds.convenience import get_latent_codes\n",
    "from tf_lab.neural_net import MODEL_SAVER_ID\n",
    "from tf_lab.point_clouds.raw_gan_gp import RawGAN_GP\n",
    "from tf_lab.point_clouds.generators_discriminators import latent_code_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from general_tools.in_out.basics import pickle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_pc_points = 2048\n",
    "random_seed = 42\n",
    "all_classes = ['table', 'chair', 'sofa']\n",
    "#                'car', 'airplane']\n",
    "# , 'rifle']\n",
    "top_data_dir = '/orions4-zfs/projects/optas/DATA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Synthetic Data.\n",
    "all_syn_data = []\n",
    "all_syn_labels = []\n",
    "for obj_label, obj_class in enumerate(all_classes):\n",
    "    gmm_syn_data = osp.join(top_data_dir, 'OUT/iclr/synthetic_samples/gmm/gmm_emd_'+\n",
    "                             obj_class, 'bneck_128_full_32_gaussians.npz')\n",
    "    \n",
    "    syn_data = np.load(gmm_syn_data)\n",
    "    syn_data = syn_data[syn_data.keys()[0]]\n",
    "\n",
    "    all_syn_data.append(syn_data)\n",
    "    all_syn_labels.append(np.ones(len(syn_data)) * obj_label)\n",
    "\n",
    "all_syn_data = np.vstack(all_syn_data)\n",
    "all_syn_labels = np.hstack(all_syn_labels)\n",
    "\n",
    "syn_data = PointCloudDataSet(all_syn_data, labels=all_syn_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852 pclouds were loaded. They belong in 1 shape-classes.\n",
      "7232 pclouds were loaded. They belong in 1 shape-classes.\n",
      "425 pclouds were loaded. They belong in 1 shape-classes.\n",
      "679 pclouds were loaded. They belong in 1 shape-classes.\n",
      "5761 pclouds were loaded. They belong in 1 shape-classes.\n",
      "338 pclouds were loaded. They belong in 1 shape-classes.\n",
      "318 pclouds were loaded. They belong in 1 shape-classes.\n",
      "2697 pclouds were loaded. They belong in 1 shape-classes.\n",
      "158 pclouds were loaded. They belong in 1 shape-classes.\n"
     ]
    }
   ],
   "source": [
    "# # LOAD ORIGINAL DATA.\n",
    "all_original_data = []\n",
    "for obj_label, obj_class in enumerate(all_classes):\n",
    "    syn_id = snc_category_to_synth_id()[obj_class]\n",
    "    in_data = load_multiple_version_of_pcs('uniform_one', syn_id, n_classes=1)\n",
    "    all_original_data.append(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_split_from_original_data(all_original_data, split):\n",
    "    original_split_data = []\n",
    "    original_split_labels = []\n",
    "    for obj_label, obj_data in enumerate(all_original_data):\n",
    "        original_split_data.append(obj_data[split].point_clouds)\n",
    "        original_split_labels.append(np.ones(obj_data[split].num_examples) * obj_label)\n",
    "\n",
    "    original_split_data = np.vstack(original_split_data)\n",
    "    original_split_labels = np.hstack(original_split_labels)\n",
    "    pure_split_data = PointCloudDataSet(original_split_data, labels=original_split_labels,\n",
    "                                       init_shuffle=False)\n",
    "    return pure_split_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pure_train_data = extract_split_from_original_data(all_original_data, 'train')\n",
    "mixed_train_data = PointCloudDataSet(np.vstack([pure_train_data.point_clouds, syn_data.point_clouds]),\n",
    "                                     labels=np.hstack([pure_train_data.labels, syn_data.labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = len(all_classes)\n",
    "out_dir = 'OUT/icml/augmented_training_data/' + str(n_classes) + '_sn_classes'\n",
    "create_dir(osp.join(top_data_dir, out_dir))\n",
    "\n",
    "pickle_data(osp.join(top_data_dir, out_dir, 'syn_data'), syn_data)\n",
    "\n",
    "pickle_data(osp.join(top_data_dir, out_dir, 'mixed_train_data'), mixed_train_data)\n",
    "pickle_data(osp.join(top_data_dir, out_dir, 'pure_train_data'), pure_train_data)\n",
    "\n",
    "pure_test_data = extract_split_from_original_data(all_original_data, 'test')\n",
    "pickle_data(osp.join(top_data_dir, out_dir, 'pure_test_data'), pure_test_data)\n",
    "\n",
    "pure_val_data = extract_split_from_original_data(all_original_data, 'val')\n",
    "pickle_data(osp.join(top_data_dir, out_dir, 'pure_val_data'), pure_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LOOK LATER FOR GIVING AN ANSWER about the CLF of the multi-class produced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class_name = 'achlioptas_5_snc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "in_data = load_multiple_version_of_pcs('uniform_one', syn_id, n_classes=1)\n",
    "train_data = in_data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orions4-zfs/projects/optas/Git_Repos/tf_lab/point_clouds/in_out.py:38: UserWarning: Point clouds with the same model name were loaded.\n",
      "  warnings.warn('Point clouds with the same model name were loaded.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 pclouds were loaded. They belong in 5 shape-classes.\n",
      "500 pclouds were loaded. They belong in 5 shape-classes.\n"
     ]
    }
   ],
   "source": [
    "top_data_dir = '/orions4-zfs/projects/optas/DATA/'\n",
    "top_pclouds_path = osp.join(top_data_dir, 'Point_Clouds/Shape_Net/Core/from_manifold_meshes/centered/', str(n_pc_points))\n",
    "train_split = osp.join(top_data_dir, 'Point_Clouds/Shape_Net/Splits/achlioptas_snc_5_medium_size_splits/train.txt')\n",
    "val_split = osp.join(top_data_dir, 'Point_Clouds/Shape_Net/Splits/achlioptas_snc_5_medium_size_splits/val.txt')\n",
    "splitter = Data_Splitter(top_pclouds_path, data_file_ending='.ply', random_seed=random_seed)\n",
    "\n",
    "tr_files = splitter.load_splits(train_split)\n",
    "pclouds, model_ids, syn_ids = load_point_clouds_from_filenames(tr_files, n_threads=20, loader=snc_loader, verbose=True)\n",
    "train_data = PointCloudDataSet(pclouds, labels=syn_ids + '_' + model_ids)\n",
    "\n",
    "val_files = splitter.load_splits(val_split)\n",
    "pclouds, model_ids, syn_ids = load_point_clouds_from_filenames(val_files, n_threads=20, loader=snc_loader, verbose=True)\n",
    "val_data = PointCloudDataSet(pclouds, labels=syn_ids + '_' + model_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# evaluate Point-net here.\n",
    "# syn_data = osp.join(top_data_dir, 'OUT/iclr/synthetic_samples/l_w_gan/l_w_gan_achlioptas_5_snc_mlp_with_split_1pc_usampled_emd_bneck_128/epoch_2000.npz')\n",
    "# syn_data = np.load(syn_data)\n",
    "# syn_data = syn_data[syn_data.keys()[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
