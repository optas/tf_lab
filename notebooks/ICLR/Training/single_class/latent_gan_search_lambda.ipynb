{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 1\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook.gpu_utils import setup_one_gpu\n",
    "GPU = 1\n",
    "setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch not working. MMD measurement won't be available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from general_tools.notebook.tf import reset_tf_graph\n",
    "from general_tools.in_out.basics import create_dir, files_in_subdirs\n",
    "\n",
    "from geo_tool import Point_Cloud\n",
    "\n",
    "from tf_lab.in_out.basics import Data_Splitter, read_saved_epochs\n",
    "from tf_lab.point_clouds.ae_templates import mlp_architecture_ala_iclr_18, default_train_params\n",
    "\n",
    "from tf_lab.point_clouds.autoencoder import Configuration as Conf\n",
    "from tf_lab.point_clouds.point_net_ae import PointNetAutoEncoder\n",
    "\n",
    "from tf_lab.point_clouds.in_out import load_point_clouds_from_filenames, PointCloudDataSet\n",
    "from tf_lab.data_sets.shape_net import pc_loader as snc_loader\n",
    "from tf_lab.data_sets.shape_net import snc_category_to_synth_id\n",
    "\n",
    "from tf_lab.point_clouds.raw_gan import RawGAN\n",
    "from tf_lab.point_clouds.latent_gan import LatentGAN\n",
    "from tf_lab.point_clouds.generators_discriminators import latent_code_discriminator_two_layers, \\\n",
    "latent_code_generator_two_layers, latent_code_discriminator, latent_code_generator\n",
    "\n",
    "from tf_lab.iclr.helper import load_multiple_version_of_pcs, find_best_validation_epoch_from_train_stats\n",
    "from tf_lab.point_clouds.convenience import get_latent_codes\n",
    "from tf_lab.neural_net import MODEL_SAVER_ID\n",
    "\n",
    "from tf_lab.point_clouds.raw_gan_gp import RawGAN_GP\n",
    "from tf_lab.point_clouds.generators_discriminators import latent_code_generator\n",
    "\n",
    "from pcloud_benchmark.evaluate_gan import entropy_of_occupancy_grid, jensen_shannon_divergence\n",
    "from tf_lab.nips.helper import pclouds_centered_and_half_sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_pc_points = 2048\n",
    "do_training = True\n",
    "\n",
    "save_model = False\n",
    "saver_step = None\n",
    "\n",
    "save_model = False\n",
    "save_synthetic_samples = np.hstack([np.array([1,5,10]), np.arange(100, 2001, 100)])\n",
    "\n",
    "ae_loss = 'emd'\n",
    "do_lwgan = True\n",
    "\n",
    "class_name = raw_input('Give me the class type.\\n').lower()\n",
    "syn_id = snc_category_to_synth_id()[class_name]\n",
    "b_neck = int(raw_input('Give me bneck_size.\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if do_lwgan:\n",
    "    gan_tag = 'l_wgan'\n",
    "else:\n",
    "    gan_tag = 'l_gan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "special_tag = 'disc_512_1024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_wgan_chair_disc_512_1024_emd_bneck_128\n"
     ]
    }
   ],
   "source": [
    "experiment_tag = '_'.join([gan_tag, class_name, special_tag, ae_loss, 'bneck', str(b_neck)])\n",
    "print experiment_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/orions4-zfs/projects/optas/DATA/OUT/iclr/nn_models/l_wgan_chair_disc_512_1024_emd_bneck_128'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_data_dir = '/orions4-zfs/projects/optas/DATA/'\n",
    "train_dir = osp.join(top_data_dir, 'OUT/iclr/nn_models', experiment_tag)\n",
    "create_dir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data.\n",
      "/orions4-zfs/projects/optas/DATA/Point_Clouds/Shape_Net/Splits/single_class_splits/03001627/85_5_10/test.txt\n",
      "679 pclouds were loaded. They belong in 1 shape-classes.\n",
      "Loading train data.\n",
      "/orions4-zfs/projects/optas/DATA/Point_Clouds/Shape_Net/Splits/single_class_splits/03001627/85_5_10/train.txt\n",
      "5761 pclouds were loaded. They belong in 1 shape-classes.\n",
      "Loading val data.\n",
      "/orions4-zfs/projects/optas/DATA/Point_Clouds/Shape_Net/Splits/single_class_splits/03001627/85_5_10/val.txt\n",
      "338 pclouds were loaded. They belong in 1 shape-classes.\n"
     ]
    }
   ],
   "source": [
    "in_data = load_multiple_version_of_pcs('uniform_one', syn_id, n_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored in epoch 430.\n"
     ]
    }
   ],
   "source": [
    "# Load Auto-Encoder\n",
    "ae_experiment_tag = 'mlp_with_split_3pc_usampled_bnorm_on_encoder_only'\n",
    "ae_id = '_'.join(['ae', class_name, ae_experiment_tag, str(n_pc_points), 'pts', str(b_neck), 'bneck', ae_loss])\n",
    "ae_train_dir = osp.join(top_data_dir, 'OUT/iclr/nn_models/', ae_id)\n",
    "\n",
    "ae_conf = Conf.load(osp.join(ae_train_dir, 'configuration'))\n",
    "saved_epochs = read_saved_epochs(ae_conf.train_dir)\n",
    "\n",
    "_, best_epoch = find_best_validation_epoch_from_train_stats(osp.join(ae_train_dir, 'train_stats.txt'))\n",
    "\n",
    "if best_epoch % ae_conf.saver_step != 0: # Model was not saved at that epoch.\n",
    "    best_epoch += best_epoch % ae_conf.saver_step\n",
    "\n",
    "ae_conf.encoder_args['verbose'] = False\n",
    "ae_conf.decoder_args['verbose'] = False\n",
    "\n",
    "reset_tf_graph()\n",
    "ae = PointNetAutoEncoder(ae_conf.experiment_name, ae_conf)    \n",
    "ae.restore_model(ae_conf.train_dir, best_epoch, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert raw-data to latent codes.\n",
    "latent_codes = get_latent_codes(ae, in_data['train'].point_clouds)\n",
    "train_data = PointCloudDataSet(latent_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "init_lr = 0.0001\n",
    "batch_size = 50\n",
    "noise_params = {'mu':0, 'sigma': 0.2}\n",
    "noise_dim = b_neck\n",
    "max_epochs = 2000\n",
    "\n",
    "n_syn_samples = train_data.num_examples\n",
    "\n",
    "n_out = [b_neck]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reset_tf_graph()\n",
    "\n",
    "# if do_lwgan:\n",
    "    \n",
    "#     synthetic_data_out_dir = osp.join(top_data_dir, 'OUT/iclr/synthetic_samples/', experiment_tag)\n",
    "#     create_dir(synthetic_data_out_dir)\n",
    "    \n",
    "#     lam = 5\n",
    "#     beta = 0.5\n",
    "#     reset_tf_graph()\n",
    "#     gan = RawGAN_GP(experiment_tag, init_lr, lam, n_out, noise_dim, \\\n",
    "#                     latent_code_discriminator, latent_code_generator, \\\n",
    "#                     beta=beta, gen_kwargs={'layer_sizes': [64, 128], 'b_norm': False}, \n",
    "#                     disc_kwargs={'layer_sizes': [512, 1024], 'b_norm': False})\n",
    "\n",
    "# else:\n",
    "#     beta = 0.2\n",
    "#     gan = LatentGAN(experiment_tag, init_lr, n_out, noise_dim, latent_code_discriminator_two_layers,\n",
    "#                     latent_code_generator_two_layers, beta=beta, gen_kwargs={'b_norm': False}, \n",
    "#                     disc_kwargs={'b_norm': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "14\n",
      "16\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "beta = 0.5\n",
    "lam_range = [12, 14, 16, 18]\n",
    "\n",
    "for lam in lam_range:\n",
    "    print lam\n",
    "    synthetic_data_out_dir = osp.join(top_data_dir, 'OUT/iclr/synthetic_samples/', experiment_tag, 'lam_' + str(lam))\n",
    "    create_dir(synthetic_data_out_dir)\n",
    "    reset_tf_graph()\n",
    "    gan = RawGAN_GP(experiment_tag, init_lr, lam, n_out, noise_dim, \\\n",
    "                    latent_code_discriminator, latent_code_generator, \\\n",
    "                    beta=beta, gen_kwargs={'layer_sizes': [64, 128], 'b_norm': False}, \n",
    "                    disc_kwargs={'layer_sizes': [512, 1024], 'b_norm': False})\n",
    "    \n",
    "    if do_training:\n",
    "        for _ in range(max_epochs):\n",
    "            loss, duration = gan._single_epoch_train(train_data, batch_size, noise_params)\n",
    "            epoch = int(gan.sess.run(gan.epoch.assign_add(tf.constant(1.0))))\n",
    "#             print epoch, loss\n",
    "\n",
    "            if save_model and (epoch % saver_step == 0 or epoch <= 5):\n",
    "                checkpoint_path = osp.join(train_dir, MODEL_SAVER_ID)\n",
    "                gan.saver.save(gan.sess, checkpoint_path, global_step=gan.epoch)\n",
    "\n",
    "            if epoch in save_synthetic_samples:\n",
    "                syn_latent_data = gan.generate(n_syn_samples, noise_params)\n",
    "                syn_data = ae.decode(syn_latent_data)\n",
    "                np.savez(osp.join(synthetic_data_out_dir, 'epoch_' + str(epoch)), syn_data)\n",
    "#                 for k in range(2):\n",
    "#                     Point_Cloud(syn_data[k]).plot()\n",
    "\n",
    "#             train_stats.append((epoch,) + loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if do_plotting:\n",
    "    x = range(len(train_stats))\n",
    "    d_loss = [t[1] for t in train_stats]\n",
    "    g_loss = [t[2] for t in train_stats]\n",
    "    plt.plot(x, d_loss, '--')\n",
    "    plt.plot(x, g_loss)\n",
    "    plt.title('Latent GAN training. (%s, %s)' %(class_name, ae_loss))\n",
    "    plt.legend(['Discriminator', 'Generator'], loc=0)\n",
    "    \n",
    "    plt.tick_params(axis='x', which='both', bottom='off', top='off')\n",
    "    plt.tick_params(axis='y', which='both', left='off', right='off')\n",
    "    \n",
    "    plt.xlabel('Epochs.') \n",
    "    plt.ylabel('Loss.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voxel_resolution = 28\n",
    "cmp_in_sphere = True\n",
    "train_data_ = pclouds_centered_and_half_sphere(in_data['train'].point_clouds)\n",
    "_, train_grid_var = entropy_of_occupancy_grid(train_data_, voxel_resolution, in_sphere=cmp_in_sphere)\n",
    "test_data_ = pclouds_centered_and_half_sphere(in_data['test'].point_clouds)\n",
    "_, test_grid_var = entropy_of_occupancy_grid(test_data_, voxel_resolution, in_sphere=cmp_in_sphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "NB-GAN 1 0.13294844311 0.1317307377\n",
      "NB-GAN 5 0.108942214483 0.108522532868\n",
      "NB-GAN 10 0.0748141189945 0.0762263513816\n",
      "NB-GAN 100 0.0133718704793 0.0163459607066\n",
      "NB-GAN 200 0.0107807016904 0.0142246924581\n",
      "NB-GAN 300 0.00807118503727 0.0120968935511\n",
      "NB-GAN 400 0.00769829028966 0.0115881442461\n",
      "NB-GAN 500 0.0074620278497 0.0111868022626\n",
      "NB-GAN 600 0.00579280407089 0.0102500333158\n",
      "NB-GAN 700 0.00656208540935 0.0105997457625\n",
      "NB-GAN 800 0.00685257320906 0.0107173614015\n",
      "NB-GAN 900 0.00586731716399 0.00977160209375\n",
      "NB-GAN 1000 0.00572275026351 0.00967685611126\n",
      "NB-GAN 1100 0.00605097122248 0.00952648436176\n",
      "NB-GAN 1200 0.00626838847251 0.00991693202356\n",
      "NB-GAN 1300 0.00578518583373 0.00991424122403\n",
      "NB-GAN 1400 0.00583857190168 0.00936841504813\n",
      "NB-GAN 1500 0.00618681490407 0.0100646229363\n",
      "NB-GAN 1600 0.00546620620937 0.00942216913886\n",
      "NB-GAN 1700 0.00554477154071 0.00912126164651\n",
      "NB-GAN 1800 0.00592461656829 0.00950283204591\n",
      "NB-GAN 1900 0.0063379943466 0.009460697158\n",
      "NB-GAN 2000 0.00528060198034 0.00931912670195\n",
      "14\n",
      "NB-GAN 1 0.15067832985 0.147546020026\n",
      "NB-GAN 5 0.0786101543931 0.0790974385051\n",
      "NB-GAN 10 0.075175668492 0.0769342505988\n",
      "NB-GAN 100 0.0130446891559 0.0161369860076\n",
      "NB-GAN 200 0.0109475895682 0.0149473602019\n",
      "NB-GAN 300 0.00950929230144 0.0134257563107\n",
      "NB-GAN 400 0.00778692234613 0.011407073884\n",
      "NB-GAN 500 0.00896701593467 0.012257851222\n",
      "NB-GAN 600 0.00643334434414 0.0103072242079\n",
      "NB-GAN 700 0.00699836744548 0.0108121045353\n",
      "NB-GAN 800 0.00619438681391 0.00995403328915\n",
      "NB-GAN 900 0.00546531760894 0.00983050717954\n",
      "NB-GAN 1000 0.00590736158093 0.0101619736753\n",
      "NB-GAN 1100 0.00656744111152 0.010326643977\n",
      "NB-GAN 1200 0.00617123238287 0.00996170706031\n",
      "NB-GAN 1300 0.00570811068521 0.00953841529992\n",
      "NB-GAN 1400 0.00586726996481 0.00985108264367\n",
      "NB-GAN 1500 0.00562869222665 0.00906376178912\n",
      "NB-GAN 1600 0.00492011572864 0.00877825788369\n",
      "NB-GAN 1700 0.00564684206609 0.0097997292234\n",
      "NB-GAN 1800 0.00523547682056 0.00921720979857\n",
      "NB-GAN 1900 0.00519643147634 0.00911669899429\n",
      "NB-GAN 2000 0.00557853130097 0.00901355456272\n",
      "16\n",
      "NB-GAN 1 0.171393393157 0.168719097467\n",
      "NB-GAN 5 0.0849237077748 0.0861551981315\n",
      "NB-GAN 10 0.0769411116276 0.0787868334455\n",
      "NB-GAN 100 0.0145168904274 0.0170841814945\n",
      "NB-GAN 200 0.0107773658128 0.0144500726096\n",
      "NB-GAN 300 0.00925671841313 0.0128424881488\n",
      "NB-GAN 400 0.00876241845919 0.0124957434993\n",
      "NB-GAN 500 0.00715754660603 0.0112029118934\n",
      "NB-GAN 600 0.00665041614518 0.0106490879641\n",
      "NB-GAN 700 0.006271355344 0.0104777969065\n",
      "NB-GAN 800 0.00582744390998 0.0100821788677\n",
      "NB-GAN 900 0.0058820665657 0.00976352116196\n",
      "NB-GAN 1000 0.00621266947186 0.00986845003314\n",
      "NB-GAN 1100 0.00528847568093 0.00910110634995\n",
      "NB-GAN 1200 0.00529386417306 0.00935134462754\n",
      "NB-GAN 1300 0.00512405675238 0.00918882617158\n",
      "NB-GAN 1400 0.00577390698878 0.00959701250049\n",
      "NB-GAN 1500 0.0054485847155 0.0096964307946\n",
      "NB-GAN 1600 0.00496492989547 0.00893297755138\n",
      "NB-GAN 1700 0.00616419678557 0.00979768005597\n",
      "NB-GAN 1800 0.00534699657404 0.00920425091647\n",
      "NB-GAN 1900 0.00570205979874 0.00935240355482\n",
      "NB-GAN 2000 0.00597552240083 0.00969058946969\n",
      "18\n",
      "NB-GAN 1 0.189329117179 0.187336580529\n",
      "NB-GAN 5 0.138217029516 0.139758446543\n",
      "NB-GAN 10 0.0852327985301 0.0863264846661\n",
      "NB-GAN 100 0.0123739810208 0.0160711706276\n",
      "NB-GAN 200 0.0120767094277 0.015455858927\n",
      "NB-GAN 300 0.0093731956275 0.0132419795111\n",
      "NB-GAN 400 0.00747332339276 0.0112860123574\n",
      "NB-GAN 500 0.00729783722263 0.0108888599681\n",
      "NB-GAN 600 0.00724387167527 0.0106588946132\n",
      "NB-GAN 700 0.00587733349664 0.00962638658059\n",
      "NB-GAN 800 0.00581271751776 0.00970393597052\n",
      "NB-GAN 900 0.00565968375631 0.00979480703676\n",
      "NB-GAN 1000 0.00635935374315 0.00984393573219\n",
      "NB-GAN 1100 0.00683363685831 0.010460025673\n",
      "NB-GAN 1200 0.00600166851467 0.00981122240992\n",
      "NB-GAN 1300 0.00520801547845 0.00908869220684\n",
      "NB-GAN 1400 0.00569477733669 0.00953737072978\n",
      "NB-GAN 1500 0.00622994962062 0.00996840360786\n",
      "NB-GAN 1600 0.00611328617977 0.00993832507687\n",
      "NB-GAN 1700 0.00541658773976 0.00940555918506\n",
      "NB-GAN 1800 0.0051458732462 0.00947099795325\n",
      "NB-GAN 1900 0.00571686090374 0.00948411918571\n",
      "NB-GAN 2000 0.0060538907003 0.0097929621921\n"
     ]
    }
   ],
   "source": [
    "for lam in lam_range:\n",
    "    print lam\n",
    "    synthetic_data_out_dir = osp.join(top_data_dir, 'OUT/iclr/synthetic_samples/', experiment_tag, 'lam_' + str(lam))\n",
    "    \n",
    "    for epoch in save_synthetic_samples:\n",
    "        in_f = osp.join(synthetic_data_out_dir, 'epoch_' + str(epoch) + '.npz')\n",
    "        our_data = np.load(in_f)\n",
    "        our_data = our_data[our_data.keys()[0]]\n",
    "        our_data = pclouds_centered_and_half_sphere(our_data)    \n",
    "        _, our_grid_var = entropy_of_occupancy_grid(our_data, voxel_resolution, in_sphere=cmp_in_sphere)\n",
    "        jsd_epoch_train = jensen_shannon_divergence(our_grid_var, train_grid_var)\n",
    "        jsd_epoch_test = jensen_shannon_divergence(our_grid_var, test_grid_var)    \n",
    "        print 'NB-GAN', epoch, jsd_epoch_train, jsd_epoch_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
