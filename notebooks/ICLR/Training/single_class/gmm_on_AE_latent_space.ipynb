{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 0\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook.gpu_utils import setup_one_gpu\n",
    "GPU = 0\n",
    "setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch not working. MMD measurement won't be available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import mixture\n",
    "\n",
    "from geo_tool import Point_Cloud\n",
    "\n",
    "from general_tools.notebook.tf import reset_tf_graph\n",
    "from general_tools.in_out.basics import create_dir\n",
    "\n",
    "from tf_lab.in_out.basics import Data_Splitter, read_saved_epochs\n",
    "from tf_lab.point_clouds.ae_templates import mlp_architecture_ala_iclr_18, default_train_params\n",
    "from tf_lab.point_clouds.autoencoder import Configuration as Conf\n",
    "from tf_lab.point_clouds.point_net_ae import PointNetAutoEncoder\n",
    "from tf_lab.point_clouds.in_out import load_point_clouds_from_filenames, PointCloudDataSet\n",
    "from tf_lab.point_clouds.convenience import reconstruct_pclouds, get_latent_codes\n",
    "\n",
    "from tf_lab.data_sets.shape_net import pc_loader as snc_loader\n",
    "from tf_lab.data_sets.shape_net import snc_category_to_synth_id\n",
    "from tf_lab.nips.helper import pclouds_centered_and_half_sphere\n",
    "from tf_lab.iclr.helper import load_multiple_version_of_pcs, find_best_validation_epoch_from_train_stats\n",
    "\n",
    "from pcloud_benchmark.evaluate_gan import entropy_of_occupancy_grid, jensen_shannon_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib inline\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "top_data_dir = '/orions4-zfs/projects/optas/DATA'\n",
    "class_name = 'chair'\n",
    "syn_id = snc_category_to_synth_id()[class_name]\n",
    "n_pc_points = 2048\n",
    "n_pc_versions = 3 # load ae trained with that many versions of PCs\n",
    "voxel_resolution = 28\n",
    "cmp_in_sphere = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data.\n",
      "/orions4-zfs/projects/optas/DATA/Point_Clouds/Shape_Net/Splits/single_class_splits/03001627/85_5_10/test.txt\n",
      "679 pclouds were loaded. They belong in 1 shape-classes.\n",
      "Loading train data.\n",
      "/orions4-zfs/projects/optas/DATA/Point_Clouds/Shape_Net/Splits/single_class_splits/03001627/85_5_10/train.txt\n",
      "5761 pclouds were loaded. They belong in 1 shape-classes.\n",
      "Loading val data.\n",
      "/orions4-zfs/projects/optas/DATA/Point_Clouds/Shape_Net/Splits/single_class_splits/03001627/85_5_10/val.txt\n",
      "338 pclouds were loaded. They belong in 1 shape-classes.\n"
     ]
    }
   ],
   "source": [
    "in_data = load_multiple_version_of_pcs('uniform_one', syn_id, n_classes=1)\n",
    "train_data = in_data['train'].point_clouds\n",
    "test_data = in_data['test'].point_clouds\n",
    "\n",
    "# Prepare GT for JSD comparisons\n",
    "gt_train_data = pclouds_centered_and_half_sphere(train_data)\n",
    "gt_test_data = pclouds_centered_and_half_sphere(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, train_grid_var = entropy_of_occupancy_grid(gt_train_data, voxel_resolution, in_sphere=cmp_in_sphere)\n",
    "train_grid_var += 1\n",
    "\n",
    "_, test_grid_var = entropy_of_occupancy_grid(gt_test_data, voxel_resolution, in_sphere=cmp_in_sphere)\n",
    "test_grid_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae_loss = 'chamfer'\n",
    "b_necks = [128, 256]\n",
    "cov_types = ['full']\n",
    "full_n_clusters = [12, 14, 16]\n",
    "# full_n_clusters = [15, 17, 18, 19, 20]\n",
    "diag_n_clusters = [2, 4, 6, 8, 10, 12, 14, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_an_auto_encoder(b_neck, ae_loss, n_pc_versions, n_pc_points=2048):\n",
    "    # Load Auto-Encoder\n",
    "    \n",
    "    ae_experiment_tag = 'mlp_with_split_' + str(n_pc_versions) + 'pc_usampled_bnorm_on_encoder_only'\n",
    "\n",
    "    ae_id = '_'.join(['ae', class_name, ae_experiment_tag, str(n_pc_points), 'pts', str(b_neck), 'bneck', ae_loss])\n",
    "    \n",
    "    ae_train_dir = osp.join(top_data_dir, 'OUT/iclr/nn_models/', ae_id)\n",
    "    ae_conf = Conf.load(osp.join(ae_train_dir, 'configuration'))\n",
    "    \n",
    "    val_error, best_epoch = find_best_validation_epoch_from_train_stats(osp.join(ae_train_dir, 'train_stats.txt'))\n",
    "        \n",
    "    if best_epoch % ae_conf.saver_step != 0:\n",
    "        best_epoch += best_epoch % ae_conf.saver_step\n",
    "\n",
    "    ae_conf.encoder_args['verbose'] = False\n",
    "    ae_conf.decoder_args['verbose'] = False\n",
    "\n",
    "    reset_tf_graph()\n",
    "    ae = PointNetAutoEncoder(ae_conf.experiment_name, ae_conf)\n",
    "    ae.restore_model(ae_conf.train_dir, best_epoch, verbose=True)\n",
    "    return ae\n",
    "\n",
    "def jsd_on_reconstructed_data(ae_model, pclouds, cmp_grid_var, voxel_resolution, cmp_in_sphere):\n",
    "    recon, _ = reconstruct_pclouds(ae_model, pclouds, batch_size=100)\n",
    "    recon = pclouds_centered_and_half_sphere(recon)\n",
    "    _, recon_grid_var = entropy_of_occupancy_grid(recon, voxel_resolution, in_sphere=cmp_in_sphere)\n",
    "    recon_grid_var += 1\n",
    "    return jensen_shannon_divergence(recon_grid_var, cmp_grid_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored in epoch 490.\n",
      "bneck size: 128\n",
      "Train-Test JSD of the AE-decoded data: 0.0187125541936 0.02083304752\n",
      "full 12 0.0210072940229 0.024661735538 -3994511.48619 -4664519.95944\n",
      "full 14 0.0209798193459 0.0241189138689 -3915769.66441 -4697447.32633\n",
      "full 16 0.0204943885502 0.0237265109537 -3824222.41814 -4717569.26876\n",
      "Model restored in epoch 500.\n",
      "bneck size: 256\n",
      "Train-Test JSD of the AE-decoded data: 0.0183122861793 0.020093400088\n",
      "full 12 0.0206991891001 0.0235051755183 -6903476.4561 -9552606.55035\n",
      "full 14 0.0210930908708 0.0242374984359 -6523038.32507 -9613691.2115\n",
      "full 16 0.0207186018536 0.0238218711497 -6129024.40855 -9661200.08716\n"
     ]
    }
   ],
   "source": [
    "for b_neck in b_necks:\n",
    "    ae_model = load_an_auto_encoder(b_neck, ae_loss, n_pc_versions)\n",
    "    latent_codes = get_latent_codes(ae_model, train_data)\n",
    "    \n",
    "    print 'bneck size:', b_neck\n",
    "    j1 = jsd_on_reconstructed_data(ae_model, train_data, train_grid_var, voxel_resolution, cmp_in_sphere)\n",
    "    j2 = jsd_on_reconstructed_data(ae_model, test_data,  test_grid_var,  voxel_resolution, cmp_in_sphere)\n",
    "    \n",
    "    print 'Train-Test JSD of the AE-decoded data:', j1, j2\n",
    "    \n",
    "    for cov_t in cov_types:\n",
    "        if cov_t == 'diag':\n",
    "            choose_from = diag_n_clusters\n",
    "        else: \n",
    "            choose_from = full_n_clusters\n",
    "        \n",
    "        for n_cluster in choose_from:    \n",
    "            gmm = mixture.GaussianMixture(n_cluster, cov_t)\n",
    "            gmm.fit(latent_codes)\n",
    "            sample_codes = gmm.sample(len(latent_codes))[0]\n",
    "            gmm_pcs = ae_model.decode(sample_codes)\n",
    "            gmm_pcs = pclouds_centered_and_half_sphere(gmm_pcs)\n",
    "            _, gmm_grid_var = entropy_of_occupancy_grid(gmm_pcs, voxel_resolution, in_sphere=cmp_in_sphere)\n",
    "            gmm_grid_var += 1\n",
    "\n",
    "            tr_jsd = jensen_shannon_divergence(gmm_grid_var, train_grid_var)\n",
    "            te_jsd = jensen_shannon_divergence(gmm_grid_var, test_grid_var)\n",
    "            print cov_t, n_cluster, tr_jsd, te_jsd, gmm.bic(latent_codes), gmm.aic(latent_codes)            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
