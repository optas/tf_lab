{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 2\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook import gpu_utils\n",
    "GPU = 2\n",
    "gpu_utils.setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import tf_lab.point_clouds.in_out as pio\n",
    "\n",
    "from tf_lab.point_clouds.in_out import load_point_clouds_from_filenames, PointCloudDataSet\n",
    "from tf_lab.point_clouds.point_net_ae import PointNetAutoEncoder\n",
    "from tf_lab.point_clouds.autoencoder import Configuration as Conf\n",
    "from tf_lab.in_out.basics import read_saved_epochs\n",
    "\n",
    "from tf_lab.data_sets.model_net import pc_loader, classes_to_integers\n",
    "from tf_lab.data_sets.pc_utils import pclouds_with_zero_mean_in_unit_sphere\n",
    "\n",
    "\n",
    "from geo_tool import Point_Cloud\n",
    "\n",
    "from general_tools.notebook.tf import reset_tf_graph\n",
    "from general_tools.in_out.basics import create_dir, delete_files_in_directory, files_in_subdirs\n",
    "from general_tools.classification.evaluations import average_per_class\n",
    "from general_tools.simpletons import sort_dict_by_key, sort_dict_by_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iclr_optimized_paratemers(loss, model_net, dual=False):    \n",
    "    if loss == 'chamfer':\n",
    "        epoch_to_load = 1000\n",
    "        if model_net == '40': # ignores dual\n",
    "            svm_params = (0.25, 0.4, False, 'squared_hinge')     # Acc = 84.5\n",
    "        elif model_net == '10':\n",
    "            if dual:\n",
    "                svm_params = (0.2, 3, True, 'hinge')             # Max Acc = 96.1\n",
    "            else:\n",
    "                svm_params = (0.05, 0.2, False, 'squared_hinge') # Acc = 95.40\n",
    "    \n",
    "    if loss == 'emd':\n",
    "        epoch_to_load = 1100\n",
    "        if model_net == '40':\n",
    "            if dual:\n",
    "                svm_params = (0.09, 0.5, True, 'hinge')          # Max Acc = 84.1, (stable)\n",
    "            else:\n",
    "                svm_params = (0.07, 3, False, 'squared_hinge')   # Acc = 83.7\n",
    "\n",
    "        elif model_net == '10':\n",
    "            if dual:\n",
    "                svm_params = (0.15, 0.1, True, 'hinge')          # Max Acc = 95.9\n",
    "            else:\n",
    "                svm_params = (0.02, 3, False, 'squared_hinge')   # Acc = 95.46\n",
    "\n",
    "\n",
    "    return svm_params, epoch_to_load    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_pc_samples = 2048\n",
    "put_in_usphere = True\n",
    "model_net = '40'\n",
    "ae_loss = 'chamfer'\n",
    "do_verification = True\n",
    "solve_dual = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "top_data_dir = '/orions4-zfs/projects/optas/DATA/OUT/iclr/nn_models/all_snc/'\n",
    "experiment_name = 'no_conv_deeper_snc_rotated2048pts_' + ae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              allow_gpu_growth: False\n",
      "                    batch_size: 50\n",
      "                 consistent_io: None\n",
      "                         debug: False\n",
      "                       decoder: decoder_with_fc_only\n",
      "                  decoder_args: {'b_norm': True, 'layer_sizes': [1024, 2048, 6144]}\n",
      "                       encoder: encoder_with_convs_and_symmetry_new\n",
      "                  encoder_args: {'filter_sizes': [1, 1, 1, 1], 'n_filters': [128, 128, 256, 512], 'b_norm': True, 'strides': [1, 1, 1, 1]}\n",
      "               experiment_name: no_conv_deeper_snc_rotated2048pts_chamfer\n",
      "                 gauss_augment: None\n",
      "                  is_denoising: False\n",
      "               latent_vs_recon: 1.0\n",
      "                 learning_rate: 0.0005\n",
      "                          loss: chamfer\n",
      "             loss_display_step: 1\n",
      "                       n_input: [2048, 3]\n",
      "                      n_output: [2048, 3]\n",
      "                           n_z: None\n",
      "             saver_max_to_keep: None\n",
      "                    saver_step: 10\n",
      "                     train_dir: /orions4-zfs/projects/optas/DATA/OUT/iclr/nn_models/all_snc/no_conv_deeper_snc_rotated2048pts_chamfer\n",
      "               training_epochs: 2000\n",
      "                      z_rotate: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dir = osp.join(top_data_dir, experiment_name)\n",
    "conf = Conf.load(osp.join(train_dir, 'configuration'))\n",
    "\n",
    "## NEW for adaptable b_norm parameter is encoder_with_conv_symmetry \n",
    "# conf.encoder_args['b_norm'] = [conf.encoder_args['b_norm']]\n",
    "# conf.decoder_args['b_norm'] = [conf.decoder_args['b_norm']]\n",
    "##\n",
    "\n",
    "if conf.train_dir != train_dir: # added to address moving training-folder to other location\n",
    "    conf.train_dir = train_dir\n",
    "    conf.save(osp.join(conf.train_dir, 'configuration'))\n",
    "\n",
    "print conf\n",
    "conf.n_output = conf.n_input\n",
    "conf.allow_gpu_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(c, intercept, dual, svm_loss), epoch_to_load = iclr_optimized_paratemers(ae_loss, model_net, solve_dual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'bool' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-6212be37cd25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreset_tf_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointNetAutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msaved_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_saved_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlast_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_epochs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdo_verification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/orions4-zfs/projects/optas/Git_Repos/tf_lab/point_clouds/point_net_ae.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, configuration, graph)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottleneck_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/orions4-zfs/projects/optas/Git_Repos/tf_lab/point_clouds/encoders_decoders.py\u001b[0m in \u001b[0;36mencoder_with_convs_and_symmetry_new\u001b[0;34m(in_signal, n_filters, filter_sizes, strides, b_norm, spn, non_linearity, regularizer, weight_decay, symmetry, dropout_prob, pool, pool_sizes, scope, reuse, padding, verbose, closing, conv_op)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mfilter_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplicate_parameter_for_all_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplicate_parameter_for_all_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mb_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplicate_parameter_for_all_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mb_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mdropout_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplicate_parameter_for_all_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/orions4-zfs/projects/optas/Git_Repos/tf_lab/fundamentals/utils.pyc\u001b[0m in \u001b[0;36mreplicate_parameter_for_all_layers\u001b[0;34m(parameter, n_layers)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreplicate_parameter_for_all_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'bool' has no len()"
     ]
    }
   ],
   "source": [
    "reset_tf_graph()\n",
    "ae = PointNetAutoEncoder(experiment_name, conf)\n",
    "saved_epochs = read_saved_epochs(conf.train_dir)\n",
    "last_epoch = saved_epochs[-1]\n",
    "if do_verification:\n",
    "    last_epoch = epoch_to_load\n",
    "ae.restore_model(conf.train_dir, last_epoch, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_net_dir = '/orions4-zfs/projects/optas/DATA/Point_Clouds/Model_Net_' + model_net + '/from_manifold/'\n",
    "model_net_dir = osp.join(model_net_dir, str(n_pc_samples))\n",
    "\n",
    "search_pattern = '(.*)train(.*)\\.ply$'\n",
    "train_pc_files = sorted([f for f in files_in_subdirs(model_net_dir, search_pattern)])\n",
    "\n",
    "search_pattern = '(.*)test(.*)\\.ply$'\n",
    "test_pc_files = sorted([f for f in files_in_subdirs(model_net_dir, search_pattern)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9843 pclouds were loaded. They belong in 40 shape-classes.\n",
      "2468 pclouds were loaded. They belong in 40 shape-classes.\n"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "n_threads = 22\n",
    "\n",
    "pc, model_names, labels = load_point_clouds_from_filenames(train_pc_files, n_threads, pc_loader, verbose)\n",
    "\n",
    "if put_in_usphere:\n",
    "    pc = pclouds_with_zero_mean_in_unit_sphere(pc)\n",
    "\n",
    "train_data = PointCloudDataSet(pc, labels=labels, init_shuffle=False)\n",
    "\n",
    "pc_, model_names_, labels_ = load_point_clouds_from_filenames(test_pc_files, n_threads, pc_loader, verbose)\n",
    "\n",
    "if put_in_usphere:\n",
    "    pc_ = pclouds_with_zero_mean_in_unit_sphere(pc_)\n",
    "\n",
    "test_data = PointCloudDataSet(pc_, labels=labels_, init_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_feed, train_latent, train_classes = ae.embedding_at_tensor(train_data, conf, tensor_name='bottleneck')\n",
    "cids = classes_to_integers(int(model_net), train_classes)[1]\n",
    "\n",
    "test_feed, test_latent, test_classes = ae.embedding_at_tensor(test_data, conf, tensor_name='bottleneck')\n",
    "cids_ = classes_to_integers(int(model_net), test_classes)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8450465116279069\n"
     ]
    }
   ],
   "source": [
    "if do_verification:\n",
    "    print c, svm_loss, intercept, dual\n",
    "    lsvc = LinearSVC(C=c, loss=svm_loss, intercept_scaling=intercept, dual=dual, random_state=42)\n",
    "    lsvc.fit(train_latent, cids)                    \n",
    "    y_pred = lsvc.predict(test_latent)    \n",
    "    score = average_per_class(y_pred, cids_)[0]\n",
    "    print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.1 False squared_hinge\n",
      "0.94876744186\n",
      "0.01 0.1 True hinge\n",
      "0.936627906977\n",
      "0.01 0.1 True squared_hinge\n",
      "0.949930232558\n",
      "0.01 0.2 False squared_hinge\n",
      "0.949930232558\n",
      "0.01 0.2 True hinge\n",
      "0.937627906977\n",
      "0.01 0.2 True squared_hinge\n",
      "0.94876744186\n",
      "0.01 0.4 False squared_hinge\n",
      "0.949930232558\n",
      "0.01 0.4 True hinge\n",
      "0.937627906977\n",
      "0.01 0.4 True squared_hinge\n",
      "0.949930232558\n",
      "0.01 0.5 False squared_hinge\n",
      "0.949930232558\n",
      "0.01 0.5 True squared_hinge\n",
      "0.949930232558\n",
      "0.01 1 False squared_hinge\n",
      "0.94876744186\n",
      "0.01 1 True hinge\n",
      "0.937627906977\n"
     ]
    }
   ],
   "source": [
    "all_scores = dict()\n",
    "\n",
    "intercept_scaling_space = [0.1, 0.2, 0.4, 0.5, 1, 2, 3, 4]\n",
    "\n",
    "c_space = [0.01, 0.02, 0.05, 0.07, 0.08, 0.09,\n",
    "           0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, \n",
    "           0.45, 0.50]\n",
    "\n",
    "dual_space = [False, True]\n",
    "\n",
    "loss_space = ['hinge', 'squared_hinge']\n",
    "\n",
    "for c in c_space:\n",
    "    for intercept in intercept_scaling_space:\n",
    "        for dual in dual_space:\n",
    "            for loss in loss_space:\n",
    "                try:                    \n",
    "                    lsvc = LinearSVC(C=c, loss=loss, intercept_scaling=intercept, dual=dual, random_state=42)\n",
    "                    lsvc.fit(train_latent, cids)\n",
    "                    print c, intercept, dual, loss\n",
    "                    y_pred = lsvc.predict(test_latent)    \n",
    "                    score = average_per_class(y_pred, cids_)[0]\n",
    "                    print score\n",
    "                    key = (c, intercept, dual, loss)\n",
    "                    all_scores[key] = score\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "best_responses = sort_dict_by_val(all_scores, reverse=True)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FROM NIPS\n",
    "# USING ALL ShapeNetCore DATA : ~57K models.\n",
    "# Training at (max) 2K epochs.\n",
    "\n",
    "# EMD, 2K, model_net_40\n",
    "# 1.0 3 False squared_hinge\n",
    "# 0.844814259486\n",
    "# 1.0 3 True squared_hinge\n",
    "# 0.844814259486\n",
    "\n",
    "# EMD, 2K, model_net_10\n",
    "# 0.4 2 True hinge\n",
    "# 0.953279069767\n",
    "\n",
    "\n",
    "# Chamfer, 2K model_net_40\n",
    "# 0.3 4 False squared_hinge\n",
    "# 0.856074051408\n",
    "# 0.3 4 True squared_hinge\n",
    "# 0.856074051408\n",
    "# 0.6 1 False squared_hinge\n",
    "# 0.856264075887\n",
    "# 0.3 4 False squared_hinge\n",
    "# 0.856074051408\n",
    "# 0.6 1 False squared_hinge\n",
    "# 0.856264075887\n",
    "# 0.6 1 True squared_hinge\n",
    "# 0.856264075887\n",
    "# 0.7 1 False squared_hinge\n",
    "# 0.856764075887\n",
    "\n",
    "# Chamfer, 2K model_net_10\n",
    "# 0.9 4 True hinge\n",
    "# 0.950790697674\n",
    "# 0.950790697674\n",
    "# 0.8 0.5 False squared_hinge\n",
    "\n",
    "# 1.0 4 True hinge\n",
    "# 0.950790697674\n",
    "# 1.0 3 True hinge\n",
    "# 0.950790697674\n",
    "# 0.9 4 True hinge\n",
    "# 0.950790697674\n",
    "\n",
    "# 0.7 4 True hinge\n",
    "# 0.950790697674\n",
    "\n",
    "\n",
    "# With WU 7 Classes:\n",
    "\n",
    "# M10, CD, 2K epochs\n",
    "# 0.4 4 True hinge\n",
    "# 0.95176744186\n",
    "\n",
    "# M40, CD, 2K epochs\n",
    "# 1.0 1 True hinge\n",
    "# 0.84410495716\n",
    "\n",
    "# M10, EMD, ~2.5K epochs\n",
    "# about 0.94\n",
    "\n",
    "# M40, EMD, ~2.5K epochs\n",
    "# about 0.83\n",
    "\n",
    "# all_flower_pots = test_feed[np.array(cids_) == 15]\n",
    "# for i in range(len(all_flower_pots)):\n",
    "#     Point_Cloud(all_flower_pots[i]).plot()\n",
    "    \n",
    "# y_pred = lsvc.predict(test_latent)\n",
    "# gt_labels = np.array(cids_)\n",
    "\n",
    "# scores_per_class = []\n",
    "\n",
    "# for c in np.unique(gt_labels):\n",
    "#     if c == 15:\n",
    "#         scores_per_class.append(0.5)    \n",
    "#         continue\n",
    "#     index_c = gt_labels == c\n",
    "#     n_class = float(np.sum(index_c))\n",
    "#     s = np.sum(gt_labels[index_c] == y_pred[index_c])\n",
    "#     s /= n_class\n",
    "#     scores_per_class.append(s)\n",
    "# print np.mean(scores_per_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
