{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 0\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook import gpu_utils\n",
    "GPU = 0\n",
    "gpu_utils.setup_one_gpu(GPU)\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from general_tools.notebook.tf import reset_tf_graph\n",
    "\n",
    "import tf_lab.point_clouds.in_out as pio\n",
    "\n",
    "from tf_lab.point_clouds.in_out import load_point_clouds_from_filenames, PointCloudDataSet\n",
    "from tf_lab.point_clouds.point_net_ae import PointNetAutoEncoder\n",
    "from tf_lab.point_clouds.autoencoder import Configuration as Conf\n",
    "\n",
    "from tf_lab.in_out.basics import read_saved_epochs\n",
    "                                                  \n",
    "from general_tools.in_out.basics import create_dir, delete_files_in_directory, files_in_subdirs\n",
    "\n",
    "from geo_tool import Point_Cloud\n",
    "\n",
    "from tf_lab.data_sets.model_net import pc_loader, classes_to_integers\n",
    "from tf_lab.nips.helper import average_per_class, pclouds_with_zero_mean_in_unit_sphere\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from general_tools.simpletons import sort_dict_by_key, sort_dict_by_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iclr_optimized_paratemers(loss):    \n",
    "    if loss == 'chamfer':\n",
    "        epoch_to_load = 1000\n",
    "    if loss == 'emd':\n",
    "        epoch_to_load = 1100\n",
    "    return None, epoch_to_load    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_pc_samples = 2048\n",
    "put_in_usphere = True\n",
    "model_net = '40'\n",
    "ae_loss = 'chamfer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "top_data_dir = '/orions4-zfs/projects/optas/DATA/OUT/iclr/nn_models/all_snc/'\n",
    "experiment_name = 'no_conv_deeper_snc_rotated2048pts_' + ae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              allow_gpu_growth: False\n",
      "                    batch_size: 50\n",
      "                 consistent_io: None\n",
      "                         debug: False\n",
      "                       decoder: decoder_with_fc_only\n",
      "                  decoder_args: {'b_norm': True, 'layer_sizes': [1024, 2048, 6144]}\n",
      "                       encoder: encoder_with_convs_and_symmetry_new\n",
      "                  encoder_args: {'filter_sizes': [1, 1, 1, 1], 'n_filters': [128, 128, 256, 512], 'b_norm': True, 'strides': [1, 1, 1, 1]}\n",
      "               experiment_name: no_conv_deeper_snc_rotated2048pts_chamfer\n",
      "                 gauss_augment: None\n",
      "                  is_denoising: False\n",
      "               latent_vs_recon: 1.0\n",
      "                 learning_rate: 0.0005\n",
      "                          loss: chamfer\n",
      "             loss_display_step: 1\n",
      "                       n_input: [2048, 3]\n",
      "                      n_output: [2048, 3]\n",
      "                           n_z: None\n",
      "             saver_max_to_keep: None\n",
      "                    saver_step: 10\n",
      "                     train_dir: /orions4-zfs/projects/optas/DATA/OUT/iclr/nn_models/all_snc/no_conv_deeper_snc_rotated2048pts_chamfer\n",
      "               training_epochs: 2000\n",
      "                      z_rotate: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dir = osp.join(top_data_dir, experiment_name)\n",
    "conf = Conf.load(osp.join(train_dir, 'configuration'))\n",
    "print conf\n",
    "conf.n_output = conf.n_input\n",
    "conf.allow_gpu_growth = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epoch_to_load = iclr_optimized_paratemers(ae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored in epoch 2000.\n"
     ]
    }
   ],
   "source": [
    "reset_tf_graph()\n",
    "ae = PointNetAutoEncoder(experiment_name, conf)\n",
    "saved_epochs = read_saved_epochs(conf.train_dir)\n",
    "last_epoch = saved_epochs[-1]\n",
    "ae.restore_model(conf.train_dir, last_epoch, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_net_dir = '/orions4-zfs/projects/optas/DATA/Point_Clouds/Model_Net_' + model_net + '/from_manifold/'\n",
    "model_net_dir = osp.join(model_net_dir, str(n_pc_samples))\n",
    "\n",
    "search_pattern = '(.*)train(.*)\\.ply$'\n",
    "train_pc_files = sorted([f for f in files_in_subdirs(model_net_dir, search_pattern)])\n",
    "\n",
    "search_pattern = '(.*)test(.*)\\.ply$'\n",
    "test_pc_files = sorted([f for f in files_in_subdirs(model_net_dir, search_pattern)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9843 pclouds were loaded. They belong in 40 shape-classes.\n",
      "2468 pclouds were loaded. They belong in 40 shape-classes.\n"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "n_threads = 22\n",
    "\n",
    "pc, model_names, labels = load_point_clouds_from_filenames(train_pc_files, n_threads, pc_loader, verbose)\n",
    "\n",
    "if put_in_usphere:\n",
    "    pc = pclouds_with_zero_mean_in_unit_sphere(pc)\n",
    "\n",
    "train_data = PointCloudDataSet(pc, labels=labels, init_shuffle=False)\n",
    "\n",
    "pc_, model_names_, labels_ = load_point_clouds_from_filenames(test_pc_files, n_threads, pc_loader, verbose)\n",
    "\n",
    "if put_in_usphere:\n",
    "    pc_ = pclouds_with_zero_mean_in_unit_sphere(pc_)\n",
    "\n",
    "test_data = PointCloudDataSet(pc_, labels=labels_, init_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check reconstruction by diff centerings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_feed, train_latent, train_classes = ae.embedding_at_tensor(train_data, conf, tensor_name='bottleneck')\n",
    "cids = classes_to_integers(int(model_net), train_classes)[1]\n",
    "\n",
    "test_feed, test_latent, test_classes = ae.embedding_at_tensor(test_data, conf, tensor_name='bottleneck')\n",
    "cids_ = classes_to_integers(int(model_net), test_classes)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tf_lab.data_sets.numpy_dataset import NumpyDataset\n",
    "train_data = NumpyDataset([train_latent, np.array(cids)])\n",
    "test_data = NumpyDataset([test_latent, np.array(cids_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tflearn import is_training\n",
    "from tf_lab.fundamentals.inspect import count_trainable_parameters\n",
    "from tf_lab.neural_net import Neural_Net\n",
    "from tf_lab.point_clouds.encoders_decoders import decoder_with_fc_only\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = 40\n",
    "learning_rate = 0.001\n",
    "vector_dim = 512\n",
    "\n",
    "class Vector_CLF(Neural_Net):\n",
    "    def __init__(self, name, graph=None):\n",
    "#         if graph is None:\n",
    "#             graph = tf.get_default_graph()\n",
    "        \n",
    "        Neural_Net.__init__(self, name, None)\n",
    "\n",
    "        self.x = tf.placeholder(tf.float32, (None, vector_dim))\n",
    "        self.gt = tf.placeholder(tf.int32, (None))\n",
    "\n",
    "        self.logits = decoder_with_fc_only(self.x, [1024, 512, n_classes], b_norm=True, dropout_prob=[0.5, 0.5, 0])\n",
    "        self.prediction = tf.argmax(self.logits, axis=1)\n",
    "\n",
    "        self.correct_pred = tf.equal(self.prediction, tf.cast(self.gt, tf.int64))\n",
    "        self.avg_accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))\n",
    "        self._create_loss_optimizer()\n",
    "\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "\n",
    "        # Initializing the tensor flow variables\n",
    "        self.init = tf.global_variables_initializer()\n",
    "\n",
    "        # Launch the session\n",
    "        self.sess = tf.Session(config=config)\n",
    "        self.sess.run(self.init)\n",
    "    \n",
    "    def _create_loss_optimizer(self):        \n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits, labels=self.gt)\n",
    "        self.loss = tf.reduce_mean(loss)\n",
    "#         tf.summary.scalar('Classification_loss', self.loss)\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.loss)\n",
    "\n",
    "    def partial_fit(self, X, GT):\n",
    "        '''Trains the model with mini-batches of input data.'''\n",
    "        try:\n",
    "            is_training(True, session=self.sess)\n",
    "            _, loss, logits = self.sess.run((self.optimizer, self.loss, self.logits), feed_dict={self.x: X, self.gt: GT})\n",
    "            is_training(False, session=self.sess)\n",
    "        except Exception:\n",
    "            raise\n",
    "        finally:\n",
    "            is_training(False, session=self.sess)\n",
    "        return logits, loss\n",
    "\n",
    "    def predict(self, X, gt_labels=None):\n",
    "        feed_dict = {self.x: X}\n",
    "        if gt_labels is None:\n",
    "            avg_acc = tf.no_op()\n",
    "        else:\n",
    "            avg_acc = self.avg_accuracy\n",
    "            feed_dict[self.gt] = gt_labels\n",
    "        return self.sess.run((self.prediction, avg_acc), feed_dict)\n",
    "\n",
    "    def _single_epoch_train(self, train_data, batch_size):\n",
    "        n_examples = train_data.n_examples\n",
    "        epoch_loss = 0.        \n",
    "        n_batches = int(n_examples / batch_size)\n",
    "        start_time = time.time()\n",
    "        # Loop over all batches\n",
    "        for _ in xrange(n_batches):\n",
    "            batch_i, labels = train_data.next_batch(batch_size)\n",
    "            _, loss = self.partial_fit(batch_i, labels)\n",
    "\n",
    "            # Compute average loss\n",
    "            epoch_loss += loss\n",
    "        epoch_loss /= n_batches\n",
    "        duration = time.time() - start_time\n",
    "        return epoch_loss, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_tf_graph()\n",
    "clf = Vector_CLF('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.062531923259874542, 1.7847938537597656)\n",
      "0.976531 0.859805\n",
      "(0.06190380633556835, 1.295799970626831)\n",
      "0.976938 0.860616\n",
      "(0.054138447502829916, 1.3072359561920166)\n",
      "0.978055 0.867099\n",
      "(0.067146938576895215, 1.219006061553955)\n",
      "0.977649 0.864262\n",
      "(0.059018158986724967, 1.486772060394287)\n",
      "0.978258 0.859805\n",
      "(0.07031675940557687, 1.3078110218048096)\n",
      "0.976633 0.863452\n",
      "(0.060385478445452313, 1.216399908065796)\n",
      "0.982322 0.858185\n",
      "(0.061291447655316821, 1.4210388660430908)\n",
      "0.982322 0.867504\n",
      "(0.05246154479421105, 1.3487420082092285)\n",
      "0.982728 0.867504\n",
      "(0.063613839183781981, 1.2750539779663086)\n",
      "0.978563 0.845624\n",
      "(0.062163215150762043, 1.2512822151184082)\n",
      "0.978563 0.857374\n",
      "(0.054963578955313112, 1.4084961414337158)\n",
      "0.982322 0.865073\n",
      "(0.060470356416475142, 1.3152120113372803)\n",
      "0.977446 0.846839\n",
      "(0.058256224364431917, 1.3509268760681152)\n",
      "0.97074 0.852107\n",
      "(0.056364882806297013, 1.3783769607543945)\n",
      "0.979681 0.861831\n",
      "(0.054810388634255754, 1.3417470455169678)\n",
      "0.981713 0.858185\n",
      "(0.05413667466527098, 1.1922690868377686)\n",
      "0.979274 0.864668\n",
      "(0.056553954076810686, 1.4283530712127686)\n",
      "0.982017 0.864262\n",
      "(0.065123705264081108, 1.3875229358673096)\n",
      "0.977446 0.850486\n",
      "(0.059573867363018951, 1.2279560565948486)\n",
      "0.983236 0.860616\n",
      "(0.055336679998376617, 1.4576690196990967)\n",
      "0.983236 0.868314\n",
      "(0.050605277808226302, 1.3125488758087158)\n",
      "0.980087 0.86872\n",
      "(0.058836980696710547, 1.3166439533233643)\n",
      "0.977242 0.861021\n",
      "(0.06009917776427013, 1.2664110660552979)\n",
      "0.982627 0.874797\n",
      "(0.058782587824531884, 1.3818409442901611)\n",
      "0.980189 0.861426\n",
      "(0.060992786659008577, 1.290168046951294)\n",
      "0.981611 0.863047\n",
      "(0.060714730016450037, 1.2066700458526611)\n",
      "0.980493 0.864263\n",
      "(0.058705835524775395, 1.4261510372161865)\n",
      "0.978868 0.850891\n",
      "(0.055346378375305698, 1.3463850021362305)\n",
      "0.980392 0.861831\n",
      "(0.063731240018327931, 1.2427151203155518)\n",
      "0.975109 0.86953\n",
      "(0.063331720483969248, 1.3879659175872803)\n",
      "0.982322 0.865073\n",
      "(0.0594016865426817, 1.4050021171569824)\n",
      "0.983643 0.859805\n",
      "(0.058274390445000546, 1.2214510440826416)\n",
      "0.9809 0.861426\n",
      "(0.060259995442739099, 1.3380451202392578)\n",
      "0.981713 0.865478\n",
      "(0.057889147004562817, 1.2482459545135498)\n",
      "0.983745 0.867504\n",
      "(0.059610011443324694, 1.2824680805206299)\n",
      "0.9809 0.860616\n",
      "(0.059247044410452018, 1.2417690753936768)\n",
      "0.9809 0.865073\n",
      "(0.057951118153512803, 1.4503839015960693)\n",
      "0.981916 0.856969\n",
      "(0.05677727800829583, 1.2552270889282227)\n",
      "0.979884 0.861426\n",
      "(0.049911765565820117, 1.2114448547363281)\n",
      "0.9809 0.861021\n",
      "(0.060153156233837407, 1.3936429023742676)\n",
      "0.976734 0.865478\n",
      "(0.057588398559624804, 1.2870118618011475)\n",
      "0.978258 0.856969\n",
      "(0.059727470325163512, 1.3302350044250488)\n",
      "0.978055 0.849271\n",
      "(0.059606274174127193, 1.2856488227844238)\n",
      "0.982017 0.864263\n",
      "(0.059603520730814458, 1.436295986175537)\n",
      "0.9809 0.850486\n",
      "(0.061409951989510457, 1.2442858219146729)\n",
      "0.978868 0.853323\n",
      "(0.064034890149463425, 1.4740209579467773)\n",
      "0.9809 0.860616\n",
      "(0.053668981923172918, 1.2386360168457031)\n",
      "0.981103 0.864668\n",
      "(0.055863242759725686, 1.262355089187622)\n",
      "0.981713 0.861426\n",
      "(0.055961729493437633, 1.2328088283538818)\n",
      "0.979884 0.865478\n",
      "(0.053800838135838587, 1.411834955215454)\n",
      "0.973483 0.860211\n",
      "(0.055760267798845867, 1.2837929725646973)\n",
      "0.984252 0.862237\n",
      "(0.055135944520826548, 1.2539470195770264)\n",
      "0.982525 0.865478\n",
      "(0.05893500745343995, 1.4510059356689453)\n",
      "0.98283 0.865073\n",
      "(0.061461365663527265, 1.364365816116333)\n",
      "0.981408 0.864668\n",
      "(0.049324477025502529, 1.2635598182678223)\n",
      "0.979681 0.853323\n",
      "(0.055274147284632945, 1.345128059387207)\n",
      "0.978563 0.85778\n",
      "(0.056060327155508426, 1.3925271034240723)\n",
      "0.984354 0.867099\n",
      "(0.060519389207391736, 1.2273211479187012)\n",
      "0.98029 0.851297\n",
      "(0.056737530358225985, 1.3214168548583984)\n",
      "0.981509 0.864262\n",
      "(0.054711417516881161, 1.4043998718261719)\n",
      "0.981509 0.85859\n",
      "(0.05362764573258072, 1.3299369812011719)\n",
      "0.978665 0.866288\n",
      "(0.0509188671599912, 1.2764859199523926)\n",
      "0.982221 0.865073\n",
      "(0.053419389770299731, 1.451935052871704)\n",
      "0.980189 0.862642\n",
      "(0.057764095683672412, 1.2775177955627441)\n",
      "0.982119 0.863452\n",
      "(0.065211710432480197, 1.3200640678405762)\n",
      "0.981713 0.866694\n",
      "(0.060767791679423609, 1.3860599994659424)\n",
      "0.983033 0.860211\n",
      "(0.058648715970850057, 1.3638880252838135)\n",
      "0.979579 0.851296\n",
      "(0.06122131302796259, 1.2175509929656982)\n",
      "0.984964 0.858995\n",
      "(0.058498794723145321, 1.4737699031829834)\n",
      "0.983338 0.873177\n",
      "(0.051596398389309038, 1.3114078044891357)\n",
      "0.982932 0.865073\n",
      "(0.051450760145933007, 1.2447500228881836)\n",
      "0.984557 0.87034\n",
      "(0.06148106220168803, 1.4261059761047363)\n",
      "0.97836 0.859805\n",
      "(0.052978416660245824, 1.368116855621338)\n",
      "0.983033 0.861021\n",
      "(0.054060018310449279, 1.2486989498138428)\n",
      "0.97775 0.856969\n",
      "(0.059014274266534203, 1.3436510562896729)\n",
      "0.981509 0.861426\n",
      "(0.052098429470788687, 1.4530730247497559)\n",
      "0.979782 0.865073\n",
      "(0.050754069926499924, 1.2587530612945557)\n",
      "0.981611 0.861831\n",
      "(0.052675208465875679, 1.3779950141906738)\n",
      "0.979681 0.862237\n",
      "(0.055624461863475035, 1.361541986465454)\n",
      "0.983033 0.860616\n",
      "(0.058544495900586836, 1.3406040668487549)\n",
      "0.983033 0.858995\n",
      "(0.056482057468442967, 1.1953718662261963)\n",
      "0.980493 0.863857\n",
      "(0.057551531860312657, 1.438169002532959)\n",
      "0.981916 0.856969\n",
      "(0.058933430113734642, 1.3343150615692139)\n",
      "0.981306 0.851296\n",
      "(0.058271989860685963, 1.2388570308685303)\n",
      "0.979173 0.862642\n",
      "(0.05685914681846637, 1.484375)\n",
      "0.982119 0.862642\n",
      "(0.061755860164673639, 1.5417900085449219)\n",
      "0.980189 0.852917\n",
      "(0.056166347802250778, 1.291003942489624)\n",
      "0.979579 0.857779\n",
      "(0.053207560732832407, 1.3354589939117432)\n",
      "0.981103 0.867504\n",
      "(0.05257200499003449, 1.4276649951934814)\n",
      "0.981916 0.861426\n",
      "(0.055111569494403406, 1.2545959949493408)\n",
      "0.985878 0.866694\n",
      "(0.059887066294322722, 1.3495450019836426)\n",
      "0.978665 0.864668\n",
      "(0.060776299204824642, 1.4045820236206055)\n",
      "0.979681 0.851702\n",
      "(0.054582868175276994, 1.3474540710449219)\n",
      "0.980697 0.85778\n",
      "(0.059014129028619952, 1.2316620349884033)\n",
      "0.983338 0.854943\n",
      "(0.057527635940255561, 1.4736900329589844)\n",
      "0.985472 0.860616\n",
      "(0.051619929037955516, 1.272317886352539)\n",
      "0.980697 0.862642\n",
      "(0.052080299095868379, 1.2524449825286865)\n",
      "0.981001 0.865073\n",
      "(0.056331131873089267, 1.4638340473175049)\n",
      "0.982728 0.865478\n",
      "(0.051942680831119532, 1.3632330894470215)\n",
      "0.982322 0.861426\n",
      "(0.05314202031164611, 1.2354958057403564)\n",
      "0.982119 0.860616\n",
      "(0.056722719903128951, 1.3505208492279053)\n",
      "0.982729 0.867504\n",
      "(0.052882222094922327, 1.3876779079437256)\n",
      "0.983541 0.873582\n",
      "(0.054347415204333352, 1.2429170608520508)\n",
      "0.981103 0.858995\n",
      "(0.063741139048052356, 1.4512038230895996)\n",
      "0.982932 0.856159\n",
      "(0.057472792910815841, 1.3293299674987793)\n",
      "0.981611 0.857374\n",
      "(0.058102776945778881, 1.3212559223175049)\n",
      "0.984049 0.864262\n",
      "(0.053382934744669389, 1.2147870063781738)\n",
      "0.98344 0.862237\n",
      "(0.050835504691943298, 1.4355218410491943)\n",
      "0.979579 0.8594\n",
      "(0.054116165386607906, 1.2772209644317627)\n",
      "0.981103 0.858185\n",
      "(0.048755332888745492, 1.2066459655761719)\n",
      "0.982017 0.854943\n",
      "(0.054583615317527319, 1.4451429843902588)\n",
      "0.984862 0.854538\n",
      "(0.051642882667971318, 1.3729748725891113)\n",
      "0.983745 0.854943\n",
      "(0.052700155221308317, 1.290390968322754)\n",
      "0.982932 0.864263\n",
      "(0.052599828551898764, 1.431663990020752)\n",
      "0.981713 0.863857\n",
      "(0.048882046339639024, 1.337878942489624)\n",
      "0.983033 0.860616\n",
      "(0.049944152771340851, 1.2370989322662354)\n",
      "0.981611 0.866288\n",
      "(0.055973664584227513, 1.4451282024383545)\n",
      "0.982728 0.873987\n",
      "(0.052570837891389784, 1.3305628299713135)\n",
      "0.983033 0.861426\n",
      "(0.050413098540846066, 1.2940568923950195)\n",
      "0.984151 0.855348\n",
      "(0.055483590628552647, 1.2297790050506592)\n",
      "0.984659 0.867099\n",
      "(0.049833682625571134, 1.4678990840911865)\n",
      "0.986183 0.857779\n",
      "(0.05320318122376564, 1.278770923614502)\n",
      "0.979985 0.84684\n",
      "(0.05234199941422011, 1.2461249828338623)\n",
      "0.982932 0.860211\n",
      "(0.055395769656217675, 1.4613819122314453)\n",
      "0.982424 0.86872\n",
      "(0.053400600496536998, 1.3228158950805664)\n",
      "0.982221 0.867099\n",
      "(0.055928155327244301, 1.2827990055084229)\n",
      "0.981713 0.856564\n",
      "(0.053120089486973096, 1.3223259449005127)\n",
      "0.981205 0.85859\n",
      "(0.050713780579306852, 1.4409308433532715)\n",
      "0.980798 0.858995\n",
      "(0.059872086686723655, 1.3304669857025146)\n",
      "0.982729 0.861426\n",
      "(0.054620492431259125, 1.4495439529418945)\n",
      "0.983846 0.862642\n",
      "(0.050112674263429503, 1.3357141017913818)\n",
      "0.986691 0.867504\n",
      "(0.054173341825157782, 1.3017637729644775)\n",
      "0.982932 0.866694\n",
      "(0.044598073217179152, 1.2423100471496582)\n",
      "0.984862 0.860211\n",
      "(0.057707943643825796, 1.5080349445343018)\n",
      "0.986386 0.870745\n",
      "(0.057706491775188253, 1.2518408298492432)\n",
      "0.980697 0.854943\n",
      "(0.054928128718195378, 1.2573599815368652)\n",
      "0.986081 0.872366\n",
      "(0.049569565790636483, 1.37980318069458)\n",
      "0.98344 0.868314\n",
      "(0.055957398356570466, 1.330312967300415)\n",
      "0.982322 0.862236\n",
      "(0.051895155525072574, 1.2288291454315186)\n",
      "0.981306 0.860211\n",
      "(0.056236660291502559, 1.4369518756866455)\n",
      "0.98537 0.864262\n",
      "(0.056436835872532079, 1.3733699321746826)\n",
      "0.98476 0.864668\n",
      "(0.04963645512209635, 1.250666856765747)\n",
      "0.98283 0.872366\n",
      "(0.047037183313050818, 1.4618120193481445)\n",
      "0.985065 0.867504\n",
      "(0.053684503667719416, 1.3346409797668457)\n",
      "0.985776 0.85859\n",
      "(0.049103163645426953, 1.2710509300231934)\n",
      "0.982525 0.861021\n",
      "(0.059689496243218128, 1.3297669887542725)\n",
      "0.982627 0.857374\n",
      "(0.055423277132367547, 1.405487060546875)\n",
      "0.984862 0.860211\n",
      "(0.056709257352441471, 1.252608060836792)\n",
      "0.983033 0.856159\n",
      "(0.047055461376843667, 1.3050780296325684)\n",
      "0.985573 0.861426\n",
      "(0.048972137858592238, 1.3864078521728516)\n",
      "0.983135 0.867504\n",
      "(0.04802291646982277, 1.3123819828033447)\n",
      "0.982729 0.852107\n",
      "(0.053484804587372183, 1.263779878616333)\n",
      "0.981408 0.859805\n",
      "(0.061439027712794442, 1.4346039295196533)\n",
      "0.980798 0.870745\n",
      "(0.054895064534488183, 1.368170976638794)\n",
      "0.980087 0.863857\n",
      "(0.054048307086174772, 1.2426080703735352)\n",
      "0.981103 0.850891\n",
      "(0.047450907104613013, 1.4335949420928955)\n",
      "0.983541 0.856969\n",
      "(0.050627994152707786, 1.315537929534912)\n",
      "0.984964 0.856159\n",
      "(0.046069357729200941, 1.3323688507080078)\n",
      "0.982322 0.860211\n",
      "(0.050652640373077797, 1.3287711143493652)\n",
      "0.984862 0.867099\n",
      "(0.048631722977674777, 1.4138071537017822)\n",
      "0.987097 0.861831\n",
      "(0.044582090582591674, 1.243717908859253)\n",
      "0.981713 0.867909\n",
      "(0.054314954249112278, 1.3274831771850586)\n",
      "0.984557 0.86872\n",
      "(0.052259486465006874, 1.4241390228271484)\n",
      "0.982322 0.87034\n",
      "(0.053362914053984557, 1.3713581562042236)\n",
      "0.982729 0.854133\n",
      "(0.05213535752231184, 1.2712669372558594)\n",
      "0.987707 0.866694\n",
      "(0.054830469088765495, 1.4486839771270752)\n",
      "0.984354 0.866694\n",
      "(0.044545805926924115, 1.3262062072753906)\n",
      "0.986488 0.865073\n",
      "(0.047133653019602428, 1.2336440086364746)\n",
      "0.98476 0.867504\n",
      "(0.04711650654585077, 1.4239039421081543)\n",
      "0.982525 0.865073\n",
      "(0.049187063193186283, 1.3207170963287354)\n",
      "0.983846 0.855348\n",
      "(0.048852696724958261, 1.2958080768585205)\n",
      "0.984049 0.859805\n",
      "(0.049614830059593315, 1.4432170391082764)\n",
      "0.98476 0.868314\n",
      "(0.04929924547631883, 1.371906042098999)\n",
      "0.982627 0.861831\n",
      "(0.051130059793501215, 1.2268590927124023)\n",
      "0.982627 0.86872\n",
      "(0.051122128144999474, 1.4268178939819336)\n",
      "0.979884 0.856159\n",
      "(0.048210892563493334, 1.2777609825134277)\n",
      "0.979579 0.863857\n",
      "(0.05114263257520197, 1.346801996231079)\n",
      "0.98283 0.857374\n",
      "(0.046733175277263304, 1.2143561840057373)\n",
      "0.982525 0.865478\n",
      "(0.051328149642729991, 1.5125460624694824)\n",
      "0.984659 0.867099\n",
      "(0.051202272325136453, 1.2749848365783691)\n",
      "0.983541 0.863857\n",
      "(0.050454372873028494, 1.3266241550445557)\n",
      "0.985167 0.858185\n",
      "(0.043932585335248721, 1.4019770622253418)\n",
      "0.984151 0.865883\n",
      "(0.049354546641923812, 1.3665270805358887)\n",
      "0.985065 0.867099\n",
      "(0.0441404228681955, 1.2021520137786865)\n",
      "0.984354 0.861021\n",
      "(0.051659144837722867, 1.4471039772033691)\n",
      "0.982017 0.863452\n",
      "(0.050144530435559595, 1.37070894241333)\n",
      "0.984151 0.860616\n",
      "(0.047326825791821403, 1.2401008605957031)\n",
      "0.982627 0.86953\n",
      "(0.047005159867100646, 1.461587905883789)\n",
      "0.982525 0.856969\n",
      "(0.048039470988293698, 1.320713996887207)\n",
      "0.984964 0.861021\n",
      "(0.048240087202801228, 1.2743492126464844)\n",
      "0.987402 0.86953\n",
      "(0.055527541030029652, 1.4455029964447021)\n",
      "0.985776 0.858995\n",
      "(0.052279434509858093, 1.3321731090545654)\n",
      "0.983948 0.854133\n",
      "(0.042656941711264114, 1.2084181308746338)\n",
      "0.9873 0.85778\n",
      "(0.048852413528651113, 1.4506850242614746)\n",
      "0.985675 0.861831\n",
      "(0.049623670516480999, 1.3248710632324219)\n",
      "0.98283 0.861426\n",
      "(0.050620373420426815, 1.3172950744628906)\n",
      "0.983745 0.864668\n",
      "(0.048669691324680665, 1.4231758117675781)\n",
      "0.984049 0.8594\n",
      "(0.048519892320488298, 1.429015874862671)\n",
      "0.984049 0.867909\n",
      "(0.050800489725031872, 1.2512590885162354)\n",
      "0.980697 0.856969\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "for i in range(200):\n",
    "    print clf._single_epoch_train(train_data, batch_size)\n",
    "    print clf.predict(train_data.a, train_data.b)[1], clf.predict(test_data.a, test_data.b)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
