{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from geo_tool import Point_Cloud\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "from tf_lab.external.structural_pc_losses import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_distance, approx_match, match_cost = losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_pcs = '/orions4-zfs/projects/optas/DATA/OUT/iclr/synthetic_samples/voxel_based/gmm/ae_chair_sn_vox_data_32_voxels_64_bneck/samples_with_lcc.npz'\n",
    "# all_pcs = np.load(all_pcs)\n",
    "# all_pcs = all_pcs[all_pcs.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_pc_1 = 100000\n",
    "n_pc_2 = 100000\n",
    "pc_1 = tf.Variable(np.random.randn(50, n_pc_1, 3).astype('float32'))\n",
    "pc_2 = tf.Variable(np.random.randn(50, n_pc_2, 3).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match = approx_match(pc_1, pc_2)\n",
    "emd_loss = match_cost(pc_1, pc_2, match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_p1_p2, _, cost_p2_p1, _ = nn_distance(pc_1, pc_2)\n",
    "cd_loss = tf.reduce_mean(cost_p1_p2) + tf.reduce_mean(cost_p2_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = sess.run(cd_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009552474"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's make a big AE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tf_lab.point_clouds.autoencoder import Configuration as Conf\n",
    "from tf_lab.point_clouds.point_net_ae import PointNetAutoEncoder\n",
    "from tf_lab.point_clouds.ae_templates import mlp_architecture_ala_iclr_18, default_train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "from general_tools.notebook.tf import reset_tf_graph\n",
    "from general_tools.in_out import create_dir\n",
    "from general_tools.in_out.basics import create_dir, delete_files_in_directory, files_in_subdirs\n",
    "\n",
    "from geo_tool import Point_Cloud\n",
    "\n",
    "from tf_lab.in_out.basics import Data_Splitter\n",
    "from tf_lab.point_clouds.ae_templates import mlp_architecture_ala_iclr_18, default_train_params\n",
    "\n",
    "from tf_lab.point_clouds.autoencoder import Configuration as Conf\n",
    "from tf_lab.point_clouds.point_net_ae import PointNetAutoEncoder\n",
    "\n",
    "from tf_lab.point_clouds.in_out import load_point_clouds_from_filenames, PointCloudDataSet\n",
    "from tf_lab.data_sets.shape_net import pc_loader as snc_loader\n",
    "from tf_lab.data_sets.shape_net import snc_category_to_synth_id\n",
    "\n",
    "from tf_lab.iclr.helper import load_multiple_version_of_pcs, find_best_validation_epoch_from_train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class_name = 'chair'\n",
    "# syn_id = snc_category_to_synth_id()[class_name]\n",
    "# in_data = load_multiple_version_of_pcs('uniform_one' ,syn_id, n_classes=1, n_pc_points=n_pc_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    batch_size: 1\n",
      "                 consistent_io: None\n",
      "                         debug: False\n",
      "                       decoder: decoder_with_fc_only\n",
      "                  decoder_args: {'b_norm_finish': False, 'verbose': True, 'b_norm': False, 'layer_sizes': [256, 256, 300000]}\n",
      "                       encoder: encoder_with_convs_and_symmetry_new\n",
      "                  encoder_args: {'filter_sizes': [1], 'n_filters': [64, 128, 128, 256, 128], 'verbose': True, 'b_norm': True, 'strides': [1]}\n",
      "                 gauss_augment: None\n",
      "                  is_denoising: False\n",
      "               latent_vs_recon: 1.0\n",
      "                 learning_rate: 0.0005\n",
      "                          loss: chamfer\n",
      "             loss_display_step: 1\n",
      "                       n_input: [100000, 3]\n",
      "                      n_output: [100000, 3]\n",
      "                           n_z: None\n",
      "             saver_max_to_keep: None\n",
      "                    saver_step: None\n",
      "                     train_dir: skata\n",
      "               training_epochs: 500\n",
      "                      z_rotate: False\n",
      "\n",
      "Building Encoder\n",
      "encoder_conv_layer_0 conv params =  256 bnorm params =  128\n",
      "Tensor(\"experiment_test_2/Relu:0\", shape=(?, 100000, 64), dtype=float32)\n",
      "output size: 6400000 \n",
      "\n",
      "encoder_conv_layer_1 conv params =  8320 bnorm params =  256\n",
      "Tensor(\"experiment_test_2/Relu_1:0\", shape=(?, 100000, 128), dtype=float32)\n",
      "output size: 12800000 \n",
      "\n",
      "encoder_conv_layer_2 conv params =  16512 bnorm params =  256\n",
      "Tensor(\"experiment_test_2/Relu_2:0\", shape=(?, 100000, 128), dtype=float32)\n",
      "output size: 12800000 \n",
      "\n",
      "encoder_conv_layer_3 conv params =  33024 bnorm params =  512\n",
      "Tensor(\"experiment_test_2/Relu_3:0\", shape=(?, 100000, 256), dtype=float32)\n",
      "output size: 25600000 \n",
      "\n",
      "encoder_conv_layer_4 conv params =  32896 bnorm params =  256\n",
      "Tensor(\"experiment_test_2/Relu_4:0\", shape=(?, 100000, 128), dtype=float32)\n",
      "output size: 12800000 \n",
      "\n",
      "Tensor(\"experiment_test_2/Max:0\", shape=(?, 128), dtype=float32)\n",
      "Building Decoder\n",
      "decoder_fc_0 FC params =  33024 Tensor(\"experiment_test_2/Relu_5:0\", shape=(?, 256), dtype=float32)\n",
      "output size: 256 \n",
      "\n",
      "decoder_fc_1 FC params =  65792 Tensor(\"experiment_test_2/Relu_6:0\", shape=(?, 256), dtype=float32)\n",
      "output size: 256 \n",
      "\n",
      "decoder_fc_2 FC params =  77100000 Tensor(\"experiment_test_2/decoder_fc_2/BiasAdd:0\", shape=(?, 300000), dtype=float32)\n",
      "output size: 300000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_pc_points = 100000\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "train_params = default_train_params()\n",
    "bneck = 128\n",
    "experiment_id = 'test'\n",
    "train_dir = 'skata'\n",
    "create_dir(train_dir)\n",
    "reset_tf_graph()  \n",
    "\n",
    "encoder, decoder, enc_args, dec_args = mlp_architecture_ala_iclr_18(n_pc_points, bneck)\n",
    "loss = 'chamfer'\n",
    "conf = Conf(n_input = [n_pc_points, 3],\n",
    "            loss = loss,\n",
    "                training_epochs = 500,\n",
    "                batch_size = 1,\n",
    "                denoising = False,\n",
    "                learning_rate = train_params['learning_rate'],\n",
    "                train_dir = train_dir,\n",
    "                loss_display_step = 1,\n",
    "                saver_step = None,\n",
    "                z_rotate = False,\n",
    "                encoder = encoder,\n",
    "                decoder = decoder,\n",
    "                encoder_args = enc_args,\n",
    "                decoder_args = dec_args\n",
    "               )\n",
    "print conf\n",
    "conf.experiment_name = 'experiment_' + str(experiment_id)\n",
    "#     conf.held_out_step = 5\n",
    "#     conf.save(osp.join(train_dir, 'configuration'))\n",
    "ae = PointNetAutoEncoder(conf.experiment_name, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.random.randn(4*batch_size, n_pc_points, 3).astype('float32')\n",
    "train_data = PointCloudDataSet(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.030748368785716594, 15.788946866989136)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae._single_epoch_train(train_data, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
