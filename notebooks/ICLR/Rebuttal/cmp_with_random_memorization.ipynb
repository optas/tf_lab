{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 0\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook.gpu_utils import setup_one_gpu\n",
    "GPU = 0\n",
    "setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "from tf_lab.iclr.evaluator import Evaluator\n",
    "from general_tools.in_out.basics import files_in_subdirs\n",
    "from tf_lab.iclr.helper import stored_synthetic_samples, top_evaluation_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class_name = 'chair'\n",
    "\n",
    "do_jsd = True\n",
    "do_mmd = False\n",
    "do_cov = False\n",
    "\n",
    "mmd_loss = 'chamfer'\n",
    "\n",
    "skip = ['train', 'test']\n",
    "\n",
    "boost_samples = 3\n",
    "n_reps = 3\n",
    "subsample = True # new - for rebuttal to get entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if do_jsd:\n",
    "    boost_samples = 1\n",
    "else:\n",
    "    boost_samples = boost_samples\n",
    "assert(np.sum([do_cov, do_jsd, do_mmd]) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "evaluator = Evaluator(class_name)\n",
    "evaluator.load_gt_data()\n",
    "if do_jsd:\n",
    "    evaluator.prepare_gt_grid_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if do_mmd:\n",
    "    func_ = evaluator.compute_mmd    \n",
    "elif do_cov:\n",
    "    func_ = evaluator.compute_coverage    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = '/orions4-zfs/projects/optas/DATA/OUT/iclr/evaluations/gt_data/chair_train.npz'\n",
    "sample_files = [train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chair_train\n",
      "train 0.0\n",
      "test 0.010702205945\n",
      "val 0.0156324837713\n",
      "chair_train\n",
      "train 0.0\n",
      "test 0.0100690436088\n",
      "val 0.0167675473155\n",
      "chair_train\n",
      "train 0.0\n",
      "test 0.0102530717837\n",
      "val 0.0186365192882\n"
     ]
    }
   ],
   "source": [
    "trials_res = []\n",
    "for _ in range(n_reps):\n",
    "    for sample_file in sample_files:\n",
    "        evaluator.prepare_sample_data(sample_file, boost_samples)\n",
    "        \n",
    "        if not subsample: # new for rebuttal\n",
    "            evaluator.sample_data['test'] = evaluator.sample_data['train']\n",
    "            evaluator.sample_data['val'] = evaluator.sample_data['train']\n",
    "        \n",
    "        sample_name = osp.basename(sample_file)[:-len('.npz')]\n",
    "        \n",
    "        print sample_name\n",
    "\n",
    "        if do_jsd:\n",
    "            res = evaluator.compute_jsd()\n",
    "        else:            \n",
    "            res = func_(loss=mmd_loss, sample_estimator=False, skip=skip)\n",
    "            \n",
    "        trials_res.append(res)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.015632483771256034, 0.016767547315504672, 0.018636519288238063]\n",
      "0.0170121834583\n"
     ]
    }
   ],
   "source": [
    "split = 'val'\n",
    "avgs = []\n",
    "for i in range(n_reps):\n",
    "    avgs.append(np.mean(trials_res[i][split]))\n",
    "print avgs\n",
    "print np.mean(avgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
