{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from helper import find_best_model_in_metric_file  \n",
    "import matplotlib.pylab as plt\n",
    "from collections import  defaultdict\n",
    "from general_tools.simpletons import sort_dict_by_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_sample_dir = '/orions4-zfs/projects/optas/DATA/OUT/iclr/synthetic_samples/'\n",
    "top_evaluation_dir = '/orions4-zfs/projects/optas/DATA/OUT/iclr/evaluations/synthetic_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stored_synthetic_samples(class_name):\n",
    "    sample_dir = {'l_gan_emd': osp.join(top_sample_dir, 'l_gan/l_gan_' + class_name + '_mlp_with_split_1pc_usampled_bnorm_on_encoder_only_emd_bneck_128'),\n",
    "                  'l_gan_chamfer': osp.join(top_sample_dir, 'l_gan/l_gan_' + class_name + '_mlp_with_split_1pc_usampled_bnorm_on_encoder_only_chamfer_bneck_128'),\n",
    "                  'l_w_gan_small': osp.join(top_sample_dir, 'l_w_gan/l_w_gan_'+ class_name + '_mlp_with_split_1pc_usampled_bnorm_on_encoder_only_emd_bneck_128_lgan_arch'),\n",
    "                  'l_w_gan_large': osp.join(top_sample_dir, 'l_w_gan/l_w_gan_'+ class_name + '_mlp_with_split_1pc_usampled_bnorm_on_encoder_only_emd_bneck_128_lgan_arch_double_neurons'),\n",
    "                  'r_gan': osp.join(top_sample_dir, 'r_gan/r_gan_' + class_name + '_mlp_disc_4_fc_gen_raw_gan_2048_pts'),\n",
    "                  'gmm': osp.join(top_sample_dir, 'gmm/gmm_emd_' + class_name)\n",
    "                 }\n",
    "    \n",
    "    return sample_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_evaluation_file(in_file):\n",
    "    all_lines = []\n",
    "    res = dict()\n",
    "    with open(in_file, 'r') as fin:\n",
    "        for line in fin:\n",
    "            l = line.rstrip()\n",
    "            if len(l) > 0:\n",
    "                all_lines.append(l)\n",
    "    return all_lines\n",
    "\n",
    "def tokenize_evaluation_data(in_lines, metric):\n",
    "    current_model = None\n",
    "    data_dict = defaultdict(dict)\n",
    "    \n",
    "    def model_name(model):\n",
    "        if model.startswith('epoch'):\n",
    "            return int(model[len('epoch_'):])\n",
    "\n",
    "        elif model.endswith('gaussians'):\n",
    "            tok = model.split('_')\n",
    "            cov_type = tok[-3]\n",
    "            n_gaussians = tok[-2]\n",
    "            return cov_type + '_' + n_gaussians\n",
    "            \n",
    "    for line in in_lines:\n",
    "        token = line.split()\n",
    "        if token[0] not in ['train', 'test', 'val']:\n",
    "            current_model = model_name(token[0])        # Varying epoch or n_gaussians \n",
    "        else:\n",
    "            if 'mmd' in metric.lower():       \n",
    "                split, metric_value, metric_std = token # split - mean - std\n",
    "            else:\n",
    "                split, metric_value = token\n",
    "                metric_std = 0\n",
    "                \n",
    "            metric_value = float(metric_value)\n",
    "            metric_std = float(metric_std)\n",
    "            data_dict[split][current_model] = (metric_value, metric_std)            \n",
    "    return data_dict\n",
    "    \n",
    "    \n",
    "def find_best_model_in_metric_file(in_file, metric, sort_by='test', report=['train', 'test', 'val']):    \n",
    "    all_lines = read_evaluation_file(in_file)\n",
    "    data_dict = tokenize_evaluation_data(all_lines, metric)\n",
    "    stats = data_dict[sort_by]\n",
    "    best_model = sorted([(stats[s][0], stats[s][1], s) for s in stats.keys()])[0]\n",
    "    res = dict()\n",
    "    for s in report:\n",
    "        res[s] = (best_model[2], data_dict[s][best_model[2]])        \n",
    "    return res\n",
    "\n",
    "def stats_per_epoch_or_n_clusters(data_dict, split='train'):\n",
    "    d = data_dict[split]\n",
    "    x = []\n",
    "    y = []\n",
    "    e = []\n",
    "    for key, val in sort_dict_by_key(d):\n",
    "        x.append(key)\n",
    "        y.append(val[0])\n",
    "        e.append(val[1])\n",
    "    return x, y, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_name = 'chair'\n",
    "exp_dict = stored_synthetic_samples(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collect_data_for_all_experiments(metric):\n",
    "    data_col = dict()\n",
    "    for key in exp_dict.keys(): \n",
    "        exp_name = osp.basename(exp_dict[key]) \n",
    "        in_file = osp.join(top_evaluation_dir, class_name, metric, exp_name + '.txt')\n",
    "        all_lines = read_evaluation_file(in_file)\n",
    "        data_col[key] = tokenize_evaluation_data(all_lines, metric)\n",
    "    return data_col\n",
    "    \n",
    "boost_5 = collect_data_for_all_experiments('mmd_chamfer_all_gt_boost_sample_5')\n",
    "emd_40_200 = collect_data_for_all_experiments('mmd_emd_10_samples_40gt_200_synthetic')\n",
    "jsd_data = collect_data_for_all_experiments('jsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "l_w_gan_large\n",
      "best epoch 2000\n",
      "mmd_chamfer_all_gt_boost_sample_5 test 0.0016\n",
      "cd_boost_5 0.0016 0.0009\n",
      "emd_40_200 0.142 0.004\n",
      "jsd 0.0150\n",
      "mmd_chamfer_all_gt_boost_sample_5 val 0.0018\n",
      "cd_boost_5 0.0018 0.0010\n",
      "emd_40_200 0.141 0.005\n",
      "jsd 0.0213\n",
      "\n",
      "gmm\n",
      "best epoch full_40\n",
      "mmd_chamfer_all_gt_boost_sample_5 test 0.0016\n",
      "cd_boost_5 0.0016 0.0008\n",
      "emd_40_200 0.141 0.003\n",
      "jsd 0.0132\n",
      "mmd_chamfer_all_gt_boost_sample_5 val 0.0017\n",
      "cd_boost_5 0.0017 0.0009\n",
      "emd_40_200 0.143 0.003\n",
      "jsd 0.0188\n",
      "\n",
      "r_gan\n",
      "best epoch 1350\n",
      "mmd_chamfer_all_gt_boost_sample_5 test 0.0018\n",
      "cd_boost_5 0.0018 0.0011\n",
      "emd_40_200 0.168 0.004\n",
      "jsd 0.1888\n",
      "mmd_chamfer_all_gt_boost_sample_5 val 0.0019\n",
      "cd_boost_5 0.0019 0.0011\n",
      "emd_40_200 0.170 0.003\n",
      "jsd 0.1906\n",
      "\n",
      "l_gan_chamfer\n",
      "best epoch 300\n",
      "mmd_chamfer_all_gt_boost_sample_5 test 0.0017\n",
      "cd_boost_5 0.0017 0.0011\n",
      "emd_40_200 0.133 0.004\n",
      "jsd 0.0393\n",
      "mmd_chamfer_all_gt_boost_sample_5 val 0.0020\n",
      "cd_boost_5 0.0020 0.0014\n",
      "emd_40_200 0.132 0.004\n",
      "jsd 0.0433\n",
      "\n",
      "l_w_gan_small\n",
      "best epoch 1700\n",
      "mmd_chamfer_all_gt_boost_sample_5 test 0.0017\n",
      "cd_boost_5 0.0017 0.0009\n",
      "emd_40_200 0.141 0.005\n",
      "jsd 0.0164\n",
      "mmd_chamfer_all_gt_boost_sample_5 val 0.0019\n",
      "cd_boost_5 0.0019 0.0012\n",
      "emd_40_200 0.138 0.004\n",
      "jsd 0.0229\n",
      "\n",
      "l_gan_emd\n",
      "best epoch 200\n",
      "mmd_chamfer_all_gt_boost_sample_5 test 0.0019\n",
      "cd_boost_5 0.0019 0.0012\n",
      "emd_40_200 0.138 0.003\n",
      "jsd 0.0288\n",
      "mmd_chamfer_all_gt_boost_sample_5 val 0.0021\n",
      "cd_boost_5 0.0021 0.0014\n",
      "emd_40_200 0.137 0.002\n",
      "jsd 0.0336\n"
     ]
    }
   ],
   "source": [
    "sort_by_metric = 'mmd_chamfer_all_gt_boost_sample_5'\n",
    "metric_eval_at = ['test', 'val']\n",
    "legend_names = []\n",
    "\n",
    "for key in exp_dict.keys():\n",
    "    print \n",
    "    print key\n",
    "    exp_name = osp.basename(exp_dict[key]) \n",
    "    in_file = osp.join(top_evaluation_dir, class_name, sort_by_metric, exp_name + '.txt')\n",
    "    best_model = find_best_model_in_metric_file(in_file, sort_by_metric, sort_by='test', report=['test', 'val'])\n",
    "    best_id = best_model['test'][0]\n",
    "    \n",
    "    print 'best epoch', best_id        \n",
    "    for split in metric_eval_at:\n",
    "        print metric, split, '%.4f'%(best_model[split][1][0], )\n",
    "        \n",
    "        if split in boost_5[key]:\n",
    "            st = boost_5[key][split][best_id]\n",
    "            print 'cd_boost_5 %.4f %.4f' % (st[0], st[1])\n",
    "        \n",
    "        if split in emd_40_200[key]:\n",
    "            st = emd_40_200[key][split][best_id]\n",
    "            print 'emd_40_200 %.3f %.3f' %(st[0] / float(2048), st[1] / float(2048))\n",
    "        \n",
    "        if split in jsd_data[key]:\n",
    "            st = jsd_data[key][split][best_id]\n",
    "            print 'jsd %.4f' %(st[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#         if 'gan' in exp_name:\n",
    "#             legend_names.append(key)\n",
    "#             x, y, e = stats_per_epoch_or_n_clusters(data_dict, split='test')\n",
    "#             plt.plot(x, y)\n",
    "#             plt.errorbar(x, y, yerr=e, fmt='-o')    \n",
    "#     except:\n",
    "#         pass\n",
    "#     plt.legend(legend_names)\n",
    "#     plt.title('MMD via EMD:10-40-200 on Test')\n",
    "#     plt.title('MMD via CD :5x_boost, Test')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
