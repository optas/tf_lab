{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os.path as osp\n",
    "import time\n",
    "\n",
    "from scipy.stats import entropy\n",
    "from general_tools.simpletons import iterate_in_chunks\n",
    "\n",
    "from tf_lab.external.Chamfer_EMD_losses.tf_nndistance import nn_distance\n",
    "from tf_lab.external.Chamfer_EMD_losses.tf_approxmatch import approx_match, match_cost\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minimum_mathing_distance(sample_pcs, ref_pcs, batch_size, normalize=False, sess=None, verbose=False, use_sqrt=False, use_EMD=False):\n",
    "    ''' normalize (boolean): if True the Chamfer distance between two point-clouds is the average of matched\n",
    "                             point-distances. Alternatively, is their sum.\n",
    "    '''\n",
    "    s = time.time()\n",
    "    if normalize:\n",
    "        reducer = tf.reduce_mean\n",
    "    else:\n",
    "        reducer = tf.reduce_sum\n",
    "\n",
    "    if sess is None:\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        sess = tf.Session(config=config)\n",
    "\n",
    "    n_ref, n_pc_points, pc_dim = ref_pcs.shape\n",
    "    _, n_pc_points_s, pc_dim_s = sample_pcs.shape\n",
    "\n",
    "    if n_pc_points != n_pc_points_s or pc_dim != pc_dim_s:\n",
    "        raise ValueError('Incompatible Point-Clouds.')\n",
    "\n",
    "    # TF Graph Operations\n",
    "    ref_pl = tf.placeholder(tf.float32, shape=(1, n_pc_points, pc_dim))\n",
    "    sample_pl = tf.placeholder(tf.float32, shape=(None, n_pc_points, pc_dim))\n",
    "\n",
    "#     repeat_times = tf.shape(sample_pl)[0]   # slower- could be used to use entire set of samples.\n",
    "    repeat_times = batch_size\n",
    "    ref_repeat = tf.tile(ref_pl, [repeat_times, 1, 1])\n",
    "    ref_repeat = tf.reshape(ref_repeat, [repeat_times, n_pc_points, pc_dim])\n",
    "\n",
    "    if not use_EMD:\n",
    "        ref_to_s, _, s_to_ref, _ = nn_distance(ref_repeat, sample_pl)\n",
    "\n",
    "        if use_sqrt:\n",
    "            ref_to_s = tf.sqrt(ref_to_s)\n",
    "            s_to_ref = tf.sqrt(s_to_ref)\n",
    "\n",
    "        chamfer_dist_batch = reducer(ref_to_s, 1) + reducer(s_to_ref, 1)\n",
    "    else:\n",
    "        match = approx_match(ref_repeat, sample_pl)\n",
    "        chamfer_dist_batch = reducer(match_cost(ref_repeat, sample_pl, match))\n",
    "\n",
    "    best_in_batch = tf.reduce_min(chamfer_dist_batch)   # Best distance, of those that were matched to single ref pc.\n",
    "    print time.time()-s\n",
    "    matched_dists = []\n",
    "    for i in xrange(n_ref):\n",
    "        best_in_all_batches = []\n",
    "        if verbose and i % 50 == 0:\n",
    "            print i\n",
    "        for sample_chunk in iterate_in_chunks(sample_pcs, batch_size):\n",
    "            if len(sample_chunk) != batch_size:\n",
    "                continue\n",
    "            feed_dict = {ref_pl: np.expand_dims(ref_pcs[i], 0), sample_pl: sample_chunk}\n",
    "            b = sess.run(best_in_batch, feed_dict=feed_dict)\n",
    "            best_in_all_batches.append(b)\n",
    "\n",
    "        matched_dists.append(np.min(best_in_all_batches))\n",
    "\n",
    "    mmd = np.mean(matched_dists)\n",
    "    sess.close()\n",
    "    return mmd, matched_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.random.randn(100, 2048, 3)\n",
    "b = np.random.randn(100, 2048, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0418698787689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7030.9985,\n",
       " [6985.9863,\n",
       "  7057.9023,\n",
       "  7506.1123,\n",
       "  6847.8872,\n",
       "  7092.9609,\n",
       "  7093.8433,\n",
       "  7016.083,\n",
       "  6828.1416,\n",
       "  7064.2026,\n",
       "  7064.2549,\n",
       "  7090.9551,\n",
       "  7193.2124,\n",
       "  6991.4473,\n",
       "  7210.5063,\n",
       "  7040.8296,\n",
       "  6946.7637,\n",
       "  7059.5664,\n",
       "  6902.0117,\n",
       "  6844.4365,\n",
       "  6846.5977,\n",
       "  6935.8066,\n",
       "  7035.7363,\n",
       "  7070.8657,\n",
       "  7258.5732,\n",
       "  7195.7227,\n",
       "  6931.6025,\n",
       "  7140.8228,\n",
       "  6960.124,\n",
       "  7052.2197,\n",
       "  6952.4004,\n",
       "  6794.0679,\n",
       "  7360.8062,\n",
       "  7001.1997,\n",
       "  6977.5947,\n",
       "  6973.3037,\n",
       "  7047.3091,\n",
       "  7049.1719,\n",
       "  7033.8516,\n",
       "  6993.2773,\n",
       "  7025.46,\n",
       "  7158.8623,\n",
       "  6870.4238,\n",
       "  7018.7314,\n",
       "  7057.2939,\n",
       "  7042.9062,\n",
       "  7088.4648,\n",
       "  6913.9189,\n",
       "  6997.7402,\n",
       "  6946.5645,\n",
       "  7050.0186,\n",
       "  7168.9268,\n",
       "  7239.6753,\n",
       "  6932.8857,\n",
       "  7014.0449,\n",
       "  6781.6182,\n",
       "  7123.126,\n",
       "  7291.2974,\n",
       "  6900.0908,\n",
       "  6990.958,\n",
       "  7014.8999,\n",
       "  6950.6646,\n",
       "  7166.1533,\n",
       "  7204.5195,\n",
       "  7126.0498,\n",
       "  6969.6074,\n",
       "  7170.2051,\n",
       "  7153.6201,\n",
       "  6890.3726,\n",
       "  6840.1475,\n",
       "  6939.8008,\n",
       "  7041.8682,\n",
       "  6823.1279,\n",
       "  6933.084,\n",
       "  7059.9092,\n",
       "  6968.498,\n",
       "  6966.4517,\n",
       "  7009.998,\n",
       "  7072.96,\n",
       "  7171.9238,\n",
       "  6877.5747,\n",
       "  7284.8193,\n",
       "  6978.8486,\n",
       "  6900.7793,\n",
       "  7063.0581,\n",
       "  7028.6064,\n",
       "  6970.6899,\n",
       "  6982.5991,\n",
       "  7053.3032,\n",
       "  7001.9243,\n",
       "  7248.1182,\n",
       "  7064.6099,\n",
       "  6873.9473,\n",
       "  6962.3271,\n",
       "  6971.6816,\n",
       "  7143.9053,\n",
       "  7053.8706,\n",
       "  6887.2837,\n",
       "  6960.3589,\n",
       "  7007.7593,\n",
       "  7248.7402])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size, normalize=False, sess=None, verbose=False, use_sqrt=False, use_EMD=False):\n",
    "minimum_mathing_distance(a, b, 10, use_EMD=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
