{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 1\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook.gpu_utils import setup_one_gpu\n",
    "GPU = 1\n",
    "setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "from tf_lab.iclr.evaluator import Evaluator\n",
    "from general_tools.in_out.basics import files_in_subdirs\n",
    "from tf_lab.iclr.helper import stored_synthetic_samples, top_evaluation_dir\n",
    "from geo_tool import Point_Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class_name = 'chair'\n",
    "do_mmd = True\n",
    "do_cov = True\n",
    "sample_metrics = False\n",
    "mmd_loss = 'emd'\n",
    "boost_samples = 3\n",
    "skip = ['test', 'train']\n",
    "n_repeats = 3\n",
    "report_gmm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "top_syn_dir = '/orions4-zfs/projects/optas/DATA/OUT/iclr/synthetic_samples/voxel_based/'\n",
    "\n",
    "sample_files = []\n",
    "\n",
    "gmm_tags = ['ae_chair_phuoc_data_64_voxels_64_bneck', \n",
    "            'ae_chair_sn_vox_data_32_voxels_64_bneck']\n",
    "\n",
    "if report_gmm:\n",
    "    for tag in gmm_tags:\n",
    "        sample_files.append(osp.join(top_syn_dir, 'gmm', tag, 'samples.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = Evaluator(class_name)\n",
    "evaluator.load_gt_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/orions4-zfs/projects/optas/DATA/OUT/iclr/synthetic_samples/gmm/gmm_emd_chair/bneck_128_full_32_gaussians.npz\n",
      "val 132.675 31.7877\n",
      "val 0.644970414201 0.0\n",
      "val 132.749 30.8023\n",
      "val 0.704142011834 0.0\n",
      "val 132.585 30.0806\n",
      "val 0.668639053254 0.0\n",
      "132.669657389\n",
      "0.67258382643\n"
     ]
    }
   ],
   "source": [
    "for sample_file in sample_files:\n",
    "    print sample_file\n",
    "    mmd_scores = []\n",
    "    cov_scores = []\n",
    "    for _ in range(n_repeats):        \n",
    "        evaluator.prepare_sample_data(sample_file, boost_samples)\n",
    "\n",
    "        if 'phuoc' in sample_file:\n",
    "            # Phuoc rotated -90 compared to GT.\n",
    "            for k, v in evaluator.sample_data.iteritems():\n",
    "                temp = np.zeros_like(v)\n",
    "                for i in xrange(len(v)):\n",
    "                    temp[i] = Point_Cloud(v[i]).rotate_z_axis_by_degrees(-90).points\n",
    "                evaluator.sample_data[k] = temp\n",
    "\n",
    "        if do_mmd:\n",
    "            score = evaluator.compute_mmd(loss=mmd_loss, sample_estimator=sample_metrics, skip=skip)\n",
    "            mmd_scores.append(score)\n",
    "\n",
    "        if do_cov:\n",
    "            score = evaluator.compute_coverage(loss=mmd_loss, sample_estimator=sample_metrics, skip=skip)\n",
    "            cov_scores.append(score)\n",
    "    \n",
    "    for score_type in [mmd_scores, cov_scores]:\n",
    "        if len(score_type) > 0:\n",
    "            total = 0.0\n",
    "            for s in score_type:\n",
    "                total += np.mean(s['val'])\n",
    "            print total / len(score_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
