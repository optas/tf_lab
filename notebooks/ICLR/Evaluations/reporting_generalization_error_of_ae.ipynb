{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 0\n"
     ]
    }
   ],
   "source": [
    "from general_tools.notebook.gpu_utils import setup_one_gpu\n",
    "GPU = 0\n",
    "setup_one_gpu(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from general_tools.notebook.tf import reset_tf_graph\n",
    "from general_tools.in_out import create_dir\n",
    "\n",
    "from geo_tool import Point_Cloud\n",
    "\n",
    "from tf_lab.point_clouds.ae_templates import mlp_architecture_ala_iclr_18, default_train_params\n",
    "from tf_lab.point_clouds.autoencoder import Configuration as Conf\n",
    "from tf_lab.point_clouds.point_net_ae import PointNetAutoEncoder\n",
    "from tf_lab.point_clouds.convenience import reconstruct_pclouds\n",
    "\n",
    "from tf_lab.data_sets.shape_net import snc_category_to_synth_id\n",
    "from tf_lab.iclr.helper import load_multiple_version_of_pcs, find_best_validation_epoch_from_train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me the class type: chair\n"
     ]
    }
   ],
   "source": [
    "top_data_dir = '/orions4-zfs/projects/optas/DATA/'\n",
    "\n",
    "experiment_tag =  'mlp_with_split_1pc_usampled_bnorm_on_encoder_only_v2'\n",
    "\n",
    "n_pc_points = 2048\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "loss = 'emd'\n",
    "\n",
    "class_name = raw_input('Give me the class type: ').lower()\n",
    "\n",
    "syn_id = snc_category_to_synth_id()[class_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data.\n",
      "/orions4-zfs/projects/optas/DATA/Point_Clouds/Shape_Net/Splits/single_class_splits/03001627/85_5_10/test.txt\n",
      "679 pclouds were loaded. They belong in 1 shape-classes.\n",
      "Loading train data.\n",
      "/orions4-zfs/projects/optas/DATA/Point_Clouds/Shape_Net/Splits/single_class_splits/03001627/85_5_10/train.txt\n",
      "5761 pclouds were loaded. They belong in 1 shape-classes.\n",
      "Loading val data.\n",
      "/orions4-zfs/projects/optas/DATA/Point_Clouds/Shape_Net/Splits/single_class_splits/03001627/85_5_10/val.txt\n",
      "338 pclouds were loaded. They belong in 1 shape-classes.\n"
     ]
    }
   ],
   "source": [
    "in_data = load_multiple_version_of_pcs('uniform_one', syn_id, n_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 148.091099666 148.581416426 135.641225093 470\n",
      "8 130.597838543 132.221149136 112.592633653 500\n",
      "16 111.417881892 113.98936259 97.2969486453 450\n",
      "32 103.846909427 106.220607662 92.3266792873 380\n",
      "64 98.4956156714 101.752321684 87.586505921 450\n",
      "128 98.7875973402 102.042568269 88.5168912676 425\n",
      "256 98.6771176581 100.740916964 88.5448542831 405\n",
      "512 102.962270342 104.733981642 93.5644253289 495\n"
     ]
    }
   ],
   "source": [
    "bneck_list = [4, 8, 16, 32, 64, 128, 256, 512]\n",
    "\n",
    "for bneck in bneck_list:\n",
    "    experiment_id = '_'.join(['ae', class_name, experiment_tag, str(n_pc_points), 'pts', str(bneck), 'bneck', loss])\n",
    "    train_dir = osp.join(top_data_dir, 'OUT/iclr/nn_models/', experiment_id)\n",
    "    conf = Conf.load(osp.join(train_dir, 'configuration'))\n",
    "    \n",
    "    val_error, best_epoch = find_best_validation_epoch_from_train_stats(osp.join(train_dir, 'train_stats.txt'))\n",
    "    \n",
    "    if best_epoch % conf.saver_step != 0: # Model was not saved at that epoch: use next bigger epoch.\n",
    "        epoch_to_load = best_epoch + (best_epoch % conf.saver_step)\n",
    "    else:\n",
    "        epoch_to_load = best_epoch\n",
    "    \n",
    "    conf.encoder_args['verbose'] = False\n",
    "    conf.decoder_args['verbose'] = False    \n",
    "    reset_tf_graph()\n",
    "    ae = PointNetAutoEncoder(conf.experiment_name, conf)    \n",
    "    ae.restore_model(conf.train_dir, epoch_to_load, verbose=False)\n",
    "    _, l_val = reconstruct_pclouds(ae, in_data['val'].point_clouds, batch_size=100)    \n",
    "    _, l_test = reconstruct_pclouds(ae, in_data['test'].point_clouds, batch_size=100)\n",
    "    _, l_train = reconstruct_pclouds(ae, in_data['train'].point_clouds, batch_size=100)\n",
    "    print bneck, l_val, l_test, l_train, best_epoch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
